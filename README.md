---
abstract: |
  File RIASSUNTO.md non trovato.
---

# INTRODUZINOE ALLA TESI

Questa tesi esamina il rapporto paradossale tra intelligenza artificiale e ambiente attraverso la lente sociologica della teoria della modernizzazione ecologica. L'AI viene contemporaneamente presentata come strumento essenziale per la transizione ecologica e identificata come fonte crescente di pressione ambientale, incarnando una contraddizione fondamentale della modernità contemporanea.

La domanda di ricerca centrale è: in che modo l'intelligenza artificiale può essere analizzata sociologicamente come strumento di transizione ecologica nella prospettiva della modernizzazione ecologica? Attraverso un'analisi critica della letteratura scientifica, la tesi adotta un approccio dialettico che confronta due narrative opposte.

Il Capitolo 1 delinea il quadro teorico della modernizzazione ecologica, distinguendo tra versioni "deboli" orientate al mercato e versioni "forti" basate su governance democratica e giustizia ambientale. Il Capitolo 2 documenta le applicazioni dell'AI per la sostenibilità: ottimizzazione delle reti energetiche, monitoraggio climatico, agricoltura di precisione. Il Capitolo 3 rovescia la prospettiva, analizzando l'impronta ecologica dell'infrastruttura computazionale: consumi energetici crescenti, dipendenza da combustibili fossili, paradosso di Jevons.

La tesi conclude che l'AI può contribuire alla transizione ecologica solo attraverso una modernizzazione "forte e riflessiva" che superi la fiducia ingenua nell'efficienza tecnologica, riconosca le contraddizioni del capitalismo digitale e promuova governance democratica, trasparenza ambientale e giustizia distributiva. Il contributo originale risiede nell'applicazione sistematica della teoria della modernizzazione ecologica all'analisi sociologica dell'intelligenza artificiale.

# CAPITOLO 1 - QUADRO TEORICO: LA MODERNIZZAZIONE ECOLOGICA NELL'ERA DIGITALE

## 1.1 La teoria della modernizzazione ecologica: fondamenti

### 1.1.1 Origini e presupposti teorici

La teoria della modernizzazione ecologica (EMT, *Ecological Modernization Theory*) emerge nei primi anni Ottanta del XX secolo come risposta sociologica alla crescente consapevolezza dei problemi ambientali nelle società industriali avanzate. A differenza delle prospettive neomalthusiane e delle teorie dei "limiti dello sviluppo" che dominavano il dibattito ecologista degli anni Settanta, la EMT propone una visione radicalmente diversa: le crisi ambientali non richiedono necessariamente una de-industrializzazione o una decrescita economica, ma possono essere superate *attraverso* la modernizzazione stessa, intesa come innovazione tecnologica e riforma istituzionale [Mol & Spaargaren, 2000].

I fondatori di questo approccio – il sociologo tedesco Joseph Huber e i sociologi olandesi Arthur Mol e Gert Spaargaren – sviluppano la EMT in esplicita opposizione alle correnti ambientaliste radicali. Come osservano [Spaargaren & Mol, 1992], la teoria si propone di superare quello che definiscono il "flirt con l'ecologia" (*coquetting with ecology*) di molta sociologia ambientale dell'epoca, che secondo loro rischiava di cadere in forme di determinismo biologico o in visioni anti-moderne. Il punto di partenza è che "le società industriali moderne possono superare le crisi ecologiche non abbandonando ma anzi intensificando il processo di modernizzazione" [Mol, 2010].

La EMT condivide con la teoria della modernizzazione classica un'impalcatura concettuale di derivazione struttural-funzionalista parsonsiana, che include processi come la differenziazione funzionale, la razionalizzazione e l'individualizzazione [Foster, 2012; Seippel, 2000]. Tuttavia, se ne distingue per l'enfasi specifica sulla dimensione ecologica: l'assunto centrale è che "gli interessi ambientali sono stati progressivamente incorporati nelle relazioni sociali, nelle istituzioni e nelle pratiche quotidiane" [Mol, 2010]. In altre parole, la logica ecologica sta diventando parte integrante del funzionamento delle società moderne, non un elemento esterno o antagonista.

Questa prospettiva si fonda su tre presupposti teorici fondamentali. Primo, la EMT adotta quello che i critici chiamano il "paradigma dell'esenzione umana" (*human exemptionalist paradigm*), secondo cui l'umanità non è vincolata in modo deterministico dalle leggi naturali ma può modellare attivamente il proprio rapporto con l'ambiente [Foster, 2012]. Secondo, la teoria presuppone la compatibilità di fondo tra crescita economica capitalista e sostenibilità ambientale, a patto che vengano introdotte le necessarie innovazioni tecnologiche e riforme istituzionali [Mol, 2002]. Terzo, la EMT mantiene una visione teleologica del progresso: le società tendono "naturalmente" verso forme sempre più avanzate di integrazione della razionalità ecologica, guidate da élite illuminate – esperti scientifici, policy-maker, imprese innovative – più che da movimenti sociali dal basso [McLaughlin, 2012].

Come sottolinea [Ewing, 2017], la teoria della modernizzazione ecologica è essenzialmente un approccio *"green capitalist"* alla sociologia ambientale: "mantiene le caratteristiche centrali del sistema-mondo capitalista" e non vede la necessità di mettere in discussione le logiche fondamentali di profitto e crescita. Questa scelta teorica, come vedremo, ha implicazioni profonde sia per le potenzialità esplicative della EMT sia per le sue prescrizioni politiche.

### 1.1.2 Concetti chiave della EMT

La teoria della modernizzazione ecologica si articola attorno a quattro concetti fondamentali che costituiscono il suo nucleo analitico.

**Efficienza ecologica e disaccoppiamento.** Il concetto centrale della EMT è che l'innovazione tecnologica possa produrre un *disaccoppiamento* (*decoupling*) tra crescita economica e degradazione ambientale. Attraverso processi produttivi più efficienti, energie rinnovabili, economia circolare e dematerializzazione, diventa teoricamente possibile aumentare il PIL riducendo simultaneamente le emissioni di CO2, il consumo di risorse e la produzione di rifiuti [Mol & Spaargaren, 2000]. La metafora ricorrente nella letteratura della EMT è quella del "bruco industriale sporco" che si trasforma nella "farfalla ecologica" grazie alla super-industrializzazione tecnologica [citato in Ewing, 2017]. L'obiettivo non è produrre meno, ma produrre meglio – con maggiore efficienza ecologica.

**Razionalità ecologica.** La EMT introduce il concetto di "razionalità ecologica" come una logica autonoma che progressivamente si integra nelle istituzioni economiche e politiche moderne [Mol, 2002]. Secondo questa prospettiva, i criteri ambientali – riduzione delle emissioni, conservazione delle risorse, minimizzazione dei rifiuti – non restano confinati al dominio dei movimenti ambientalisti o delle agenzie di regolazione, ma vengono "incorporati" (*embedded*) nelle logiche decisionali delle imprese, dei mercati finanziari, delle amministrazioni pubbliche [Spaargaren et al., 2000]. La sostenibilità diventa una razionalità economica, non solo un vincolo etico. 

Tuttavia, come riconoscono gli stessi teorici della EMT, questa razionalità ecologica non deve essere intesa come prioritaria rispetto ad altre razionalità: essa può integrarsi nel sistema economico solo "quando i criteri, gli strumenti e i concetti ambientali vengono riformulati per adattarsi alle logiche dei mercati moderni" [Mol et al., 2009]. Questa subordinazione della razionalità ecologica a quella economica, come vedremo nella sezione 1.2, rappresenta uno dei principali punti critici della teoria.

**Governance ambientale multi-attore.** La EMT ridefinisce il ruolo degli attori nella transizione ecologica. A differenza dell'ambientalismo tradizionale, che enfatizza il ruolo dello Stato come regolatore e dei movimenti sociali come agenti di cambiamento, la modernizzazione ecologica attribuisce importanza crescente ai meccanismi di mercato, alle dinamiche economiche e agli attori privati [Mol, 2010]. Le imprese non sono viste come antagoniste dell'ambiente ma come potenziali protagoniste dell'innovazione verde, incentivate da vantaggi competitivi, reputazionali ed economici. Similmente, i consumatori "verdi" e le ONG ambientaliste diventano attori chiave nel "greening" dei processi produttivi e dei consumi. Lo Stato assume un ruolo di *facilitatore* più che di controllore diretto, creando le condizioni istituzionali per la modernizzazione ecologica attraverso incentivi, standard volontari e partnership pubblico-private [Spaargaren et al., 2000].

**Innovazione tecnologica come motore del cambiamento.** Al centro della EMT vi è una fiducia esplicita nel potenziale dell'innovazione tecnologica per risolvere i problemi ambientali. La tecnologia non è vista come la causa della crisi ecologica – come sostenevano molte correnti dell'ambientalismo radicale – ma come la *soluzione* [Mol & Spaargaren, 2000]. Dalle energie rinnovabili ai sistemi di cattura del carbonio, dall'agricoltura di precisione all'economia circolare basata su nuovi materiali, la EMT identifica nella ricerca scientifica e nello sviluppo tecnologico il principale percorso verso la sostenibilità. Questa enfasi sulla "razionalizzazione ecologica della produzione e del consumo" [Spaargaren & Mol, 1992] attraverso strumenti tecnico-scientifici costituisce il tratto distintivo della teoria.

In sintesi, la modernizzazione ecologica prospetta un percorso di transizione ecologica che passa attraverso il potenziamento – non il superamento – delle istituzioni e dei meccanismi della modernità industriale. Come sintetizza [Mol, 2002], la EMT "presume le dinamiche capitaliste e i rapporti di produzione e non vede la necessità di metterli in discussione per superare i problemi ecologici". Questa prospettiva si colloca quindi in netta antitesi rispetto agli approcci critici della sociologia ambientale – dall'ecologia politica marxiana alla decrescita – che vedono invece nel sistema capitalista stesso la radice strutturale della crisi ambientale.

## 1.2 Dibattiti e critiche alla modernizzazione ecologica

### 1.2.1 La distinzione tra EMT "debole" e "forte"

All'interno del dibattito sulla modernizzazione ecologica si è progressivamente consolidata una distinzione fondamentale tra due versioni della teoria: una versione "debole" (*weak*) e una versione "forte" (*strong*). Questa distinzione, emersa nel corso degli anni Novanta, riflette tensioni profonde sugli obiettivi, i mezzi e gli attori della transizione ecologica.

La **EMT "debole"** o "tecno-corporatista" rappresenta la variante dominante nella pratica politica e nell'applicazione della teoria. Questa versione si caratterizza per una fiducia pressoché illimitata nei meccanismi di mercato, nell'innovazione tecnologica guidata dalle imprese e in soluzioni *win-win* che conciliano profitto economico e sostenibilità ambientale senza richiedere trasformazioni strutturali profonde [Mol & Spaargaren, 2000]. Come sintetizza [Ewing, 2017], la EMT debole "presume le dinamiche capitaliste e i rapporti di produzione capitalistici e non vede la necessità di metterli in discussione per superare i problemi ecologici". In questa prospettiva, lo Stato assume un ruolo limitato di facilitatore, creando incentivi per l'innovazione verde ma lasciando alle forze di mercato e alle decisioni aziendali la guida del cambiamento. Le politiche preferite sono strumenti volontari, certificazioni ambientali, partnership pubblico-private e incentivi fiscali piuttosto che regolamentazioni stringenti o interventi redistributivi.

La **EMT "forte"** o "riflessiva", al contrario, enfatizza la necessità di una trasformazione più radicale che vada oltre la mera efficienza tecnologica. Questa versione riconosce che la modernizzazione ecologica richiede cambiamenti istituzionali profondi, partecipazione democratica estesa e una ridefinizione delle priorità economiche che metta in discussione l'imperativo della crescita illimitata [Mol & Spaargaren, 2000]. La EMT forte attribuisce maggiore importanza ai movimenti sociali, alla società civile e ai processi deliberativi nella definizione delle politiche ambientali. Riconosce inoltre che la giustizia sociale e la giustizia ambientale sono interconnesse, e che soluzioni puramente tecniche rischiano di riprodurre o aggravare disuguaglianze esistenti.

Nonostante questa distinzione teorica, la letteratura sulla modernizzazione ecologica è stata dominata dalla versione "debole", che ha esercitato maggiore influenza sia negli ambienti accademici sia nei circoli di policy [Ewing, 2017]. Questa predominanza non è casuale: come vedremo, le prescrizioni della EMT debole sono più facilmente compatibili con gli interessi delle élite economiche e politiche, e quindi incontrano minore resistenza istituzionale. Tuttavia, è proprio questa compatibilità con lo *status quo* capitalistico che costituisce, secondo i critici, la principale debolezza teorica ed empirica della teoria.

### 1.2.2 Le critiche alla modernizzazione ecologica

La teoria della modernizzazione ecologica è stata oggetto di critiche sostanziali da parte della sociologia ambientale critica, che possono essere raggruppate in tre categorie principali: critiche metodologiche ed epistemologiche, critiche politico-economiche e critiche empiriche.

**Critiche metodologiche ed epistemologiche.** I critici hanno evidenziato importanti debolezze nel metodo scientifico adottato dalla EMT. Primo, la teoria mostra una preferenza marcata per studi di caso qualitativi rispetto ad analisi quantitative su larga scala, limitando così la capacità di identificare pattern generali e di valutare gli effettivi outcome ecologici della modernizzazione [Ewing, 2017]. Secondo, i teorici della EMT tendono a difendere le proprie tesi utilizzando controesempi individuali per respingere ipotesi alternative, ignorando le evidenze quantitative più ampie che documentano le conseguenze ambientali negative della modernizzazione capitalista [Dunlap & Marshall, 2007]. Terzo, la EMT ridefinisce selettivamente il proprio oggetto di studio, concentrandosi su problemi ambientali "convenzionali" e localizzati (come l'inquinamento industriale o la gestione dei rifiuti) piuttosto che su crisi globali come il cambiamento climatico, la perdita di biodiversità o l'acidificazione degli oceani [Mol, 2002].

Come nota [Ewing, 2017], queste scelte metodologiche non sono neutrali: "La EMT trascura le ricerche quantitative di ampia scala che sostengono la maggior parte della letteratura critica in sociologia ambientale, privilegiando ricerche qualitative su casi individuali che non considerano le conseguenze complessive dello sviluppo capitalistico". Questa tendenza consente alla teoria di mantenere un ottimismo eco-modernista anche di fronte a evidenze crescenti di deterioramento ambientale.

**Critiche politico-economiche: la subordinazione della razionalità ecologica.** La critica più penetrante alla EMT riguarda il suo concetto chiave di "razionalità ecologica". Come abbiamo visto nella sezione precedente, la teoria sostiene che i criteri ambientali possono essere integrati nelle logiche economiche moderne. Tuttavia, i teorici della EMT riconoscono esplicitamente che questa razionalità ecologica deve rimanere *subordinata* alla razionalità economica: "i criteri ambientali possono integrarsi nei mercati moderni solo quando vengono riformulati per adattarsi alle logiche dei mercati stessi" [Mol et al., 2009].

Questa subordinazione genera una contraddizione teorica fondamentale. [Ewing, 2017] la esprime in modo efficace: "La razionalità ecologica come definita dai teorici della EMT è teoricamente incoerente e intrinsecamente contraddittoria, poiché dovrebbe essere simultaneamente (1) crescentemente indipendente dalla razionalità economica, e (2) in ultima analisi subordinata ad essa, nonostante la divergenza e la potenziale ostilità della seconda verso la prima". Quando i criteri di profitto e crescita entrano in conflitto con gli obiettivi ecologici – come accade sistematicamente in un'economia capitalista – la razionalità ecologica viene inevitabilmente sacrificata [Foster, 2012].

Questa dinamica si manifesta concretamente attraverso il meccanismo delle *esternalità ambientali*: le imprese, costrette a massimizzare il profitto per sopravvivere alla competizione di mercato, scaricano i costi sociali e ecologici della produzione sulla collettività piuttosto che internalizzarli [Ewing, 2017]. Le ricerche empiriche hanno documentato come la finanziarizzazione dell'economia abbia *intensificato* questi processi nelle ultime decadi, riducendo ulteriormente la capacità delle imprese di adottare innovazioni ecologiche che potrebbero limitare la redditività a breve termine.

**Il paradosso di Jevons e l'effetto rimbalzo.** Una critica empirica cruciale alla EMT riguarda quello che gli economisti chiamano il "paradosso di Jevons" o "effetto rimbalzo" (*rebound effect*). Questo fenomeno, identificato dall'economista britannico William Stanley Jevons nel XIX secolo, descrive come i guadagni di efficienza possano paradossalmente portare a un *aumento* – e non a una diminuzione – del consumo totale di risorse [@Luccioni2025Rebound].

Il meccanismo è il seguente: quando una tecnologia diventa più efficiente, i suoi costi d'uso diminuiscono, rendendo il suo utilizzo più conveniente e accessibile. Questo può portare a tre tipi di effetti rimbalzo [@Luccioni2025Rebound]:

1. **Effetto rimbalzo diretto**: l'efficienza riduce il costo d'uso, stimolando un maggiore utilizzo della stessa tecnologia. Ad esempio, un'automobile più efficiente costa meno per chilometro percorso, incentivando a guidare di più.

2. **Effetto rimbalzo indiretto**: il risparmio economico ottenuto grazie all'efficienza viene speso per consumare altri beni o servizi ad alta intensità energetica. Il denaro risparmiato con l'auto efficiente può finanziare un volo aereo.

3. **Effetto rimbalzo sistemico**: l'efficienza stimola la crescita economica complessiva, aumentando la domanda di risorse a livello macro-economico. Settori interi dell'economia possono espandersi grazie alle nuove tecnologie efficienti.

Numerosi studi empirici hanno documentato effetti rimbalzo significativi in diversi settori: l'efficienza energetica nell'industria automobilistica non ha ridotto il consumo totale di carburante a causa dell'aumento del numero di veicoli e dei chilometri percorsi; l'efficienza nell'illuminazione LED ha portato a un incremento dell'illuminazione urbana; le tecnologie agricole più efficienti hanno stimolato l'espansione delle superfici coltivate [Rolnick et al., 2022; Kaack et al., 2022].

Come osserva [Ewing, 2017], gli argomenti della EMT sull'eco-efficienza "tendono a trascurare il paradosso di Jevons, per cui i vantaggi economici derivanti dall'efficienza (ottenuti attraverso la riduzione dei costi delle risorse dovuta all'aumento dell'efficienza produttiva) generano spesso un aumento dell'uso delle risorse". Questo fenomeno mina radicalmente l'assunto centrale della modernizzazione ecologica: che l'efficienza tecnologica da sola possa garantire il disaccoppiamento tra crescita economica e impatto ambientale.

**Ignoranza delle relazioni core-periphery e giustizia ambientale.** Un'ulteriore critica fondamentale concerne l'incapacità della EMT di considerare adeguatamente le dinamiche di potere nel sistema-mondo capitalista. La teoria riconosce formalmente che le nazioni, le corporation transnazionali e le istituzioni economiche globali del "centro" (core) hanno un potere decisionale sproporzionato e tendono a trascurare le nazioni e le popolazioni della "periferia" [Mol, 2002]. Tuttavia, la EMT non sviluppa un'analisi sistematica di come queste asimmetrie di potere compromettano le sue stesse prescrizioni [Ewing, 2017].

Il risultato è che le soluzioni della modernizzazione ecologica rischiano di riprodurre e aggravare le disuguaglianze ambientali. Le innovazioni "verdi" sviluppate nei paesi ricchi spesso esternalizzano i costi ambientali verso i paesi poveri attraverso catene globali di produzione, estrazione di risorse e smaltimento di rifiuti. Come sottolinea [Ewing, 2017], "l'esclusione di diverse comunità e delle loro prospettive dalle nostre discussioni politiche e scientifiche è una questione di giustizia ambientale", poiché le relazioni dominanti natura-società sono spesso "dannose per determinate comunità umane, principalmente i poveri e le persone di colore".

### 1.2.3 Perché usare comunque la EMT per analizzare l'AI

Date queste critiche sostanziali, ci si potrebbe domandare: perché adottare la teoria della modernizzazione ecologica come framework principale per analizzare il rapporto tra intelligenza artificiale e ambiente? La risposta risiede in tre considerazioni fondamentali.

**Primo, la EMT rimane il framework più sviluppato per analizzare transizioni tecnologiche orientate alla sostenibilità.** Nonostante i suoi limiti, la teoria della modernizzazione ecologica offre concetti analitici – efficienza ecologica, governance multi-attore, razionalità ecologica, innovazione tecnologica – che sono particolarmente adatti a comprendere come l'AI viene presentata, legittimata e implementata nel discorso pubblico e nelle politiche ambientali contemporanee. Come vedremo nei capitoli successivi, le narrative dominanti sull'AI rispecchiano esattamente la logica della EMT: l'idea che la crisi climatica possa essere affrontata attraverso maggiore innovazione tecnologica, efficienza ottimizzata e soluzioni win-win tra economia e ambiente.

**Secondo, utilizzare la EMT "criticamente" permette di evidenziare le contraddizioni del caso AI.** Applicare la teoria della modernizzazione ecologica all'intelligenza artificiale non significa accettarne acriticamente le presupposizioni. Al contrario, il caso dell'AI costituisce un *test empirico* particolarmente illuminante dei limiti della EMT. L'AI incarna perfettamente il paradosso centrale della modernizzazione ecologica: è simultaneamente una tecnologia con potenziale trasformativo per la sostenibilità E un sistema ad altissima intensità energetica, materiale e idrica. Questo paradosso manifesta plasticamente le contraddizioni teoriche che i critici hanno identificato nella EMT.

In particolare, l'AI permette di osservare concretamente il paradosso di Jevons in azione. Come documenteremo nel Capitolo 3, i guadagni di efficienza computazionale nell'AI hanno portato non a una riduzione ma a un'*espansione* massiccia dei modelli, delle applicazioni e del consumo totale di risorse [@Luccioni2025Rebound]. L'AI for climate (Capitolo 2) e l'AI as climate problem (Capitolo 3) coesistono, rivelando l'incoerenza della razionalità ecologica quando subordinata a logiche di profitto e crescita.

**Terzo, adottare una prospettiva di EMT "forte" e riflessiva consente un'analisi più completa.** Come precisato nella sezione 1.2.1, non tutte le versioni della modernizzazione ecologica sono equivalenti. Questa tesi si posiziona esplicitamente nella tradizione della **EMT forte e riflessiva**, che riconosce:

- La necessità di trasformazioni istituzionali profonde, non solo innovazioni tecniche
- L'importanza della partecipazione democratica e della giustizia sociale
- I limiti del mercato come meccanismo di governance ambientale
- La centralità delle asimmetrie di potere globali nelle dinamiche ambientali

Adottare questa prospettiva significa utilizzare la EMT come "lente analitica" per comprendere le narrative dominanti sull'AI, mantenendo al contempo uno sguardo critico informato dalle prospettive dell'ecologia politica, della teoria dei sistemi-mondo e della società del rischio [@Beck1992; Foster, 2012; Ewing, 2017]. Questo approccio consente di evitare sia il tecno-ottimismo acritico sia il tecno-fatalismo, riconoscendo le possibilità *e* i pericoli dell'AI in relazione alla crisi climatica.

In sintesi, la teoria della modernizzazione ecologica – utilizzata criticamente e nella sua versione "forte" – fornisce il framework più adatto per comprendere sociologicamente il fenomeno dell'AI ambientale. Non perché la teoria sia priva di problemi, ma proprio perché le sue contraddizioni interne rispecchiano le contraddizioni del caso empirico che stiamo studiando. L'AI, come la EMT stessa, promette di conciliare crescita economica e sostenibilità ecologica. Verificare se questa promessa può essere mantenuta – e a quali condizioni – costituisce l'obiettivo centrale di questa tesi.

## 1.3 Dalla modernizzazione industriale alla modernizzazione informazionale

### 1.3.1 La "governance informazionale" dell'ambiente

Uno degli sviluppi più significativi della teoria della modernizzazione ecologica è stato il riconoscimento del ruolo crescente delle tecnologie dell'informazione nella ristrutturazione della governance ambientale. Questo passaggio è stato teorizzato in modo sistematico da Arthur Mol nel suo lavoro fondamentale *Environmental Reform in the Information Age* (2008), dove propone il concetto di **modernizzazione ecologica informazionale**.

L'intuizione centrale è che le tecnologie dell'informazione e della comunicazione (ICT) non rappresentano semplicemente un ulteriore settore economico da "verdizzare", ma costituiscono uno *strumento trasformativo* che modifica profondamente le modalità attraverso cui le società contemporanee possono governare i problemi ambientali. In altre parole, il passaggio dalla società industriale alla società dell'informazione implica anche una trasformazione nelle logiche e negli strumenti della governance ecologica.

Secondo questa prospettiva, le tecnologie digitali rendono possibili tre cambiamenti fondamentali nella governance ambientale:

**Primo, trasparenza e monitoraggio in tempo reale.** Le ICT consentono la raccolta, l'elaborazione e la diffusione di dati ambientali con una granularità, velocità e scala senza precedenti. Sensori distribuiti sul territorio, satelliti per l'osservazione della Terra, reti di monitoraggio della qualità dell'aria e dell'acqua generano flussi continui di informazioni che possono essere accessibili a molteplici attori – istituzioni pubbliche, imprese, ONG, cittadini. Questa "trasparenza informazionale" crea nuove forme di accountability: le emissioni inquinanti, i consumi energetici, lo sfruttamento delle risorse naturali diventano quantificabili, tracciabili e comunicabili pubblicamente. La visibilità genera pressione per il cambiamento [Kaack et al., 2022].

**Secondo, partecipazione e democratizzazione della conoscenza ambientale.** Le piattaforme digitali abbassano le barriere all'accesso e alla produzione di conoscenza ecologica. Citizen science, app di monitoraggio ambientale partecipativo, database aperti sui flussi materiali ed energetici: tutte queste innovazioni ampliano il numero e la diversità degli attori che possono contribuire alla governance ambientale. La conoscenza ecologica non è più monopolio di esperti e istituzioni centralizzate, ma si distribuisce attraverso reti più ampie e inclusive.

**Terzo, ottimizzazione e gestione adattiva.** Le tecnologie digitali permettono forme di governo ambientale più "intelligenti" e responsive. Sistemi di gestione energetica che si adattano in tempo reale ai pattern di domanda, logistica ottimizzata per ridurre gli sprechi, agricoltura di precisione che minimizza l'uso di acqua e fertilizzanti: questi esempi illustrano come l'informazione possa tradursi in efficienza ecologica attraverso meccanismi di feedback rapidi e controllo fine-grained.

In sintesi, la modernizzazione ecologica informazionale sostiene che il passaggio dalla produzione industriale materiale ai flussi informativi digitali possa alleggerire il carico ambientale dell'economia. Piuttosto che muovere atomi, la società dell'informazione muove bit – riducendo teoricamente il metabolismo materiale ed energetico dei processi produttivi. Questa "dematerializzazione" rappresenta una delle promesse centrali della transizione digitale [Kaack et al., 2022].

Tuttavia, come vedremo nel Capitolo 3, queste promesse si scontrano con la materialità concreta dell'infrastruttura digitale stessa: i data center, le reti di telecomunicazione, i dispositivi che rendono possibile la società dell'informazione hanno un'impronta ecologica tutt'altro che immateriale.

### 1.3.2 L'AI come caso di studio di modernizzazione ecologica informazionale

L'intelligenza artificiale rappresenta l'ultima frontiera – e forse la più potente – della modernizzazione ecologica informazionale. Mentre le ICT tradizionali si limitavano a raccogliere, trasmettere e visualizzare dati, l'AI introduce capacità qualitativ

amente nuove: **predizione, ottimizzazione automatica, riconoscimento di pattern complessi e decisione autonoma**.

L'AI può essere considerata una **General Purpose Technology (GPT)** – una tecnologia a uso generale comparabile storicamente all'elettricità, al motore a combustione interna o a Internet stesso [Rolnick et al., 2022]. Le GPT si caratterizzano per tre proprietà: (1) pervasività: possono essere applicate a un'ampia gamma di settori e attività; (2) miglioramento continuo: la loro performance aumenta nel tempo attraverso innovazioni incrementali; (3) capacità di generare innovazioni complementari: stimolano lo sviluppo di nuove tecnologie e processi organizzativi.

Nel contesto ambientale, l'AI estende radicalmente le possibilità della governance informazionale:

**Monitoraggio ambientale automatizzato su scala planetaria.** Mentre i sistemi ICT tradizionali richiedono interpretazione umana dei dati, l'AI può analizzare autonomamente enormi volumi di immagini satellitari, dati meteorologici, registrazioni acustiche della biodiversità. Come documenteremo nel Capitolo 2, l'AI permette di rilevare deforestazione in tempo quasi-reale, identificare automaticamente specie animali e vegetali, prevedere alluvioni con giorni di anticipo in bacini idrografici mai monitorati prima [Rolnick et al., 2022]. La scala e la velocità di questa "sorveglianza ecologica" automatizzata non hanno precedenti.

**Ottimizzazione di sistemi complessi.** L'AI eccelle nella gestione di sistemi con molteplici variabili interdipendenti – esattamente il tipo di complessità che caratterizza le sfide ambientali contemporanee. Reti elettriche che integrano fonti rinnovabili intermittenti, supply chain globali che devono minimizzare le emissioni, edifici che adattano automaticamente riscaldamento e illuminazione ai pattern di occupazione: in tutti questi casi, l'AI può trovare soluzioni ottimali che sfuggirebbero alla capacità computazionale umana [Kaack et al., 2022].

**Accelerazione della ricerca scientifica.** L'AI sta trasformando il processo di scoperta scientifica in domini cruciali per la transizione ecologica. Machine learning può esplorare lo spazio di miliardi di possibili materiali per identificare candidati promettenti per batterie più efficienti, celle solari più performanti, sistemi di cattura del carbonio più economici. Ciò che prima richiedeva anni di sperimentazione in laboratorio può ora essere simulato computazionalmente in settimane o mesi [Rolnick et al., 2022].

Questa duplice natura dell'AI – tecnologia informazionale E tecnologia trasformativa a uso generale – la rende un caso di studio particolarmente rilevante per la teoria della modernizzazione ecologica. L'AI incarna in forma concentrata tutte le promesse e le contraddizioni della modernizzazione ecologica informazionale.

Da un lato, l'AI sembra realizzare il sogno della EMT di una governance ambientale resa razionale, efficiente e precisa attraverso l'informazione e la tecnologia. Dall'altro, come vedremo, l'AI è essa stessa un sistema ad altissima intensità energetica, materiale e idrica – rivelando i limiti dell'idea di "dematerializzazione" digitale.

### 1.3.3 Il gap nella letteratura: EMT e AI

Nonostante l'evidente rilevanza dell'intelligenza artificiale per le dinamiche ambientali contemporanee, esiste un **gap significativo** nella letteratura sociologica riguardo all'applicazione sistematica della teoria della modernizzazione ecologica all'AI. Questa assenza è particolarmente notevole se consideriamo che:

1. La sociologia ambientale ha sviluppato framework sofisticati per analizzare le tecnologie industriali (chimica, nucleare, biotecnologie) ma ha mostrato scarso interesse teorico sistematico per le tecnologie digitali e computazionali.

2. La EMT è stata applicata a diverse transizioni tecnologiche – dall'energia alle biotecnologie, dall'agricoltura ai trasporti – ma l'AI è rimasta sostanzialmente ai margini di questo dibattito teorico.

3. Gli studi sull'impatto ambientale dell'AI sono finora dominati da prospettive tecnico-ingegneristiche (computer science, environmental engineering) o economiche, mentre manca una riflessione sociologica approfondita sul rapporto tra AI, istituzioni, governance e transizione ecologica.

Come osservano [Kaack et al., 2022], la letteratura sull'AI e ambiente tende a concentrarsi su due aspetti relativamente separati: da un lato, le *applicazioni* dell'AI per la mitigazione climatica (AI for climate); dall'altro, i *costi energetici* dell'addestramento dei modelli (AI's carbon footprint). Manca però un'analisi sociologica integrata che consideri:

- Come l'AI si inserisce nei processi di modernizzazione ecologica delle società contemporanee
- Quali forme di governance ambientale l'AI rende possibili o impossibili
- Come le logiche economiche e istituzionali modellano lo sviluppo e l'applicazione dell'AI in direzione ecologica o anti-ecologica
- Quali sono gli effetti sistemici e di lungo periodo dell'integrazione dell'AI nei sistemi produttivi, energetici e sociali

Un contributo parziale in questa direzione viene dal recente lavoro di [@Luccioni2025Rebound], che applica esplicitamente il concetto di "paradosso di Jevons" – discusso dalla sociologia ambientale critica – al caso dell'intelligenza artificiale. Gli autori dimostrano come i guadagni di efficienza computazionale nell'AI portino paradossalmente a un aumento del consumo totale di risorse attraverso effetti rimbalzo diretti, indiretti e sistemici. Questo studio rappresenta uno dei primi tentativi di connettere teoria sociologica ambientale e fenomeno AI in modo sistematico.

Tuttavia, l'applicazione della teoria della modernizzazione ecologica all'AI rimane in larga parte un terreno inesplorato. Questa tesi si propone di contribuire a colmare questo gap, utilizzando il framework della EMT – nella sua versione "forte" e critica – per analizzare sociologicamente il paradosso dell'AI: una tecnologia che promette di essere lo strumento della transizione ecologica, ma che è al contempo una delle forze più materialmente intensive dell'economia digitale contemporanea.

### 1.3.4 Framework analitico per i capitoli successivi

Sulla base della discussione teorica condotta finora, questa tesi adotta il seguente framework analitico per i capitoli successivi:

**Capitolo 2** esamina l'AI attraverso la lente della modernizzazione ecologica informazionale nella sua forma più ottimista. Documentiamo come l'AI venga presentata e utilizzata come strumento di governance ambientale, analizzando le sue applicazioni nella transizione energetica, nel monitoraggio climatico e nella gestione delle risorse naturali. Interpretiamo queste applicazioni come esempi di razionalità ecologica mediata dall'informazione: l'AI permette di rendere visibile l'invisibile (emissioni, deforestazione, biodiversità), di ottimizzare processi complessi (reti energetiche, supply chain), di prevedere eventi futuri (condizioni meteo, alluvioni). 

In questa prospettiva, l'AI appare come l'incarnazione più avanzata della promessa della EMT: superare i problemi ambientali attraverso maggiore modernizzazione tecnologica, efficienza e governance informazionale.

**Capitolo 3** rovescia la prospettiva, analizzando criticamente l'impronta ecologica dell'AI stessa. Esaminiamo i consumi energetici, idrici e materiali dell'infrastruttura computazionale, documentando come l'AI sia tutt'altro che "immateriale". Applichiamo il concetto di paradosso di Jevons per mostrare come i guadagni di efficienza nell'AI portino a un aumento del consumo totale (effetto rimbalzo). Utilizziamo le critiche alla EMT discusse nella sezione 1.2 per interpretare questo paradosso: la subordinazione della razionalità ecologica a quella economica, l'ignoranza delle dinamiche di profitto e crescita, la mancata considerazione degli effetti sistemici.

In questa prospettiva critica, l'AI rivela i limiti strutturali della modernizzazione ecologica "debole": la fiducia ingenua nell'efficienza tecnologica, la sottovalutazione delle contraddizioni del capitalismo, l'illusione della dematerializzazione digitale.

Questo approccio dialettico – tesi (Cap. 2) e antitesi (Cap. 3) – ci permetterà nelle **Conclusioni** di sviluppare una sintesi: una valutazione sociologicamente informata del ruolo effettivo e potenziale dell'AI nella transizione ecologica, che riconosca sia le possibilità sia i pericoli, individuando le condizioni istituzionali, economiche e politiche sotto cui l'AI potrebbe contribuire a una modernizzazione ecologica "forte" e riflessiva piuttosto che riprodurre le contraddizioni del capitalismo verde.

# CAPITOLO 2 - L'INTELLIGENZA ARTIFICIALE COME ALLEATA DELLA TRANSIZIONE ECOLOGICA

## 2.1 Introduzione: AI for Green

L'intelligenza artificiale viene presentata come strumento potenzialmente trasformativo per affrontare la crisi climatica: ottimizzazione di sistemi energetici, monitoraggio di ecosistemi, previsione di disastri naturali, accelerazione della ricerca scientifica verso la sostenibilità.

Questo capitolo esamina l'AI come *alleata* della transizione ecologica, documentando le applicazioni che [@vanWynsberghe2021SustainableAI] definisce "AI for sustainability" – sistemi specificatamente orientati a ridurre emissioni, proteggere ecosistemi e facilitare l'adattamento climatico.

### 2.1.1 Mitigazione e adattamento: le due strategie

La letteratura sulla crisi climatica distingue tradizionalmente tra due approcci complementari [@Rolnick2022TacklingClimate]:

**Mitigazione** (*mitigation*) si riferisce alle azioni volte a *ridurre* le emissioni di gas serra e quindi a limitare l'entità del riscaldamento globale futuro. La mitigazione richiede trasformazioni nei sistemi energetici (transizione alle rinnovabili), nei trasporti (elettrificazione, riduzione dell'attività di viaggio), negli edifici (efficienza energetica), nell'industria (riduzione delle emissioni di processo, economia circolare) e nell'uso del suolo (protezione delle foreste, agricoltura sostenibile). L'obiettivo dichiarato dagli accordi internazionali – in particolare l'Accordo di Parigi del 2015 – è di limitare il riscaldamento globale ben al di sotto dei 2°C rispetto ai livelli preindustriali, puntando idealmente a 1,5°C.

**Adattamento** (*adaptation*) si riferisce invece alle azioni volte a *prepararsi* alle conseguenze del cambiamento climatico che sono ormai inevitabili, anche negli scenari più ottimisti di mitigazione. L'adattamento richiede investimenti nella resilienza delle infrastrutture, nella gestione dei disastri naturali (alluvioni, siccità, incendi), nella sicurezza alimentare e idrica, nella protezione delle popolazioni vulnerabili. L'adattamento non è un'alternativa alla mitigazione, ma un suo necessario complemento: anche limitando il riscaldamento a 1,5-2°C, il pianeta subirà impatti significativi che richiederanno risposte adeguate.

L'intelligenza artificiale offre potenziali contributi in entrambe le direzioni. Come documenteremo nelle sezioni successive di questo capitolo, l'AI può facilitare la mitigazione ottimizzando le reti elettriche che integrano fonti rinnovabili, riducendo gli sprechi nella logistica e nell'industria, accelerando la scoperta di nuovi materiali per batterie e celle solari. Parallelamente, l'AI può supportare l'adattamento migliorando i sistemi di allerta precoce per eventi estremi, identificando le aree più vulnerabili, ottimizzando la gestione delle risorse idriche in condizioni di scarsità.

### 2.1.2 Una tassonomia delle applicazioni AI per il clima

La survey più completa e sistematica sulle applicazioni dell'intelligenza artificiale per la crisi climatica è "Tackling Climate Change with Machine Learning" di [@Rolnick2022TacklingClimate], un lavoro collaborativo che coinvolge alcuni dei principali esperti mondiali di AI e scienze del clima. Gli autori identificano applicazioni promettenti in tredici domini principali:

1. **Sistemi elettrici**: previsione della produzione da fonti rinnovabili, ottimizzazione delle reti intelligenti, gestione della domanda energetica
2. **Trasporti**: ottimizzazione della logistica, riduzione del traffico, supporto alla transizione verso veicoli elettrici
3. **Edifici e città**: gestione intelligente del riscaldamento e raffreddamento, pianificazione urbana sostenibile
4. **Industria**: ottimizzazione delle supply chain, riduzione degli sprechi, scoperta di nuovi materiali a basso impatto
5. **Agricoltura e foreste**: agricoltura di precisione, monitoraggio della deforestazione, gestione sostenibile delle risorse naturali
6. **Rimozione della CO2**: ottimizzazione dei sistemi di cattura diretta dall'atmosfera, sequestro geologico
7. **Previsione climatica**: miglioramento dei modelli climatici, integrazione di dati eterogenei
8. **Previsione di eventi estremi**: allerta precoce per alluvioni, uragani, incendi, ondate di calore
9. **Impatti sociali**: monitoraggio degli ecosistemi, supporto all'adattamento delle comunità vulnerabili
10. **Finanza**: valutazione dei rischi climatici, orientamento degli investimenti verso attività sostenibili

Ciascuno di questi domini presenta specifiche opportunità per l'applicazione di tecniche di machine learning – dalla computer vision per l'analisi di immagini satellitari, al reinforcement learning per l'ottimizzazione di sistemi complessi, dalle serie temporali per le previsioni meteorologiche al natural language processing per l'analisi di policy e documenti normativi.

[Kaack 2022] propongono un framework complementare che classifica le applicazioni AI in base al loro *ruolo funzionale* piuttosto che al dominio applicativo:

- **Data mining e remote sensing**: tradurre dati grezzi (immagini satellitari, documenti testuali) in informazioni utilizzabili per la ricerca, il policy-making e la pianificazione
- **Sperimentazione accelerata**: esplorare rapidamente spazi di parametri nella scoperta scientifica (materiali, processi chimici)
- **Simulazione fisica rapida**: approssimare modelli computazionalmente costosi per permettere analisi di scenario
- **Previsione**: apprendere da serie temporali per predire produzione energetica, domanda di trasporto, eventi meteorologici
- **Ottimizzazione e controllo di sistemi**: gestire in tempo reale sistemi complessi come reti elettriche, edifici, processi industriali
- **Manutenzione predittiva**: anticipare guasti e inefficienze in sistemi a basso impatto carbonico

Questo framework evidenzia come le stesse tecniche di ML possano essere applicate trasversalmente a domini diversi: un algoritmo di deep learning per la previsione di serie temporali può essere adattato tanto alla produzione solare quanto alla domanda elettrica, tanto ai flussi di traffico quanto alle rese agricole.

### 2.1.3 L'AI nella prospettiva della modernizzazione ecologica

Dal punto di vista della teoria della modernizzazione ecologica, le applicazioni "AI for Green" rappresentano una manifestazione emblematica dei concetti chiave discussi nel Capitolo 1. In particolare:

**Razionalità ecologica attraverso l'informazione.** L'AI permette di rendere visibile ciò che prima era invisibile o difficilmente quantificabile. Le emissioni di metano da pipeline che sfuggono ai controlli tradizionali possono essere rilevate da satelliti e analizzate automaticamente con computer vision. La deforestazione illegale in aree remote può essere monitorata in tempo quasi-reale. I consumi energetici di milioni di edifici possono essere stimati da immagini aeree. Questa "trasparenza informazionale" crea le condizioni per l'applicazione di criteri ecologici a decisioni che prima venivano prese in assenza di dati adeguati.

**Efficienza e ottimizzazione.** L'AI eccelle nel trovare soluzioni ottimali in spazi di ricerca complessi. Una rete elettrica con migliaia di generatori rinnovabili intermittenti, milioni di consumatori con pattern variabili, sistemi di storage distribuiti presenta un livello di complessità che sfugge alle capacità di gestione manuale. L'AI può coordinare questi elementi in tempo reale, massimizzando l'uso di energia pulita e minimizzando gli sprechi. Questo è precisamente il tipo di disaccoppiamento tra servizio fornito (elettricità affidabile) e impatto ambientale (emissioni) che la EMT identifica come obiettivo della transizione ecologica.

**Governance multi-attore e distribuzione della conoscenza.** Molte applicazioni AI per il clima non sono sviluppate da istituzioni pubbliche centralizzate ma da una molteplicità di attori: startup che ottimizzano la logistica, ONG che monitorano le foreste, comunità di citizen scientists che raccolgono dati sulla biodiversità, università che sviluppano modelli climatici più accurati. L'AI democratizza l'accesso alla capacità di analisi ambientale, permettendo a attori che prima erano esclusi di contribuire alla governance ecologica.

**Accelerazione dell'innovazione tecnologica.** L'AI sta trasformando il processo di ricerca e sviluppo in domini cruciali per la transizione: materiali per batterie, celle fotovoltaiche, sistemi di cattura del carbonio. Ciò che prima richiedeva anni di sperimentazione in laboratorio può ora essere simulato computazionalmente, riducendo drasticamente i tempi di scoperta. Questo è esattamente il tipo di "intensificazione della modernizzazione" che la EMT identifica come percorso per superare i problemi ambientali.

### 2.1.4 Struttura del capitolo

Le sezioni successive esplorano empiricamente queste promesse, documentando le applicazioni concrete dell'AI per la transizione ecologica:

**Sezione 2.2** esamina il contributo dell'AI alla **transizione energetica**, analizzando le applicazioni nelle smart grid, nella previsione della produzione rinnovabile, nell'integrazione di sistemi di storage e nella ricerca di nuovi materiali. Questo è il dominio dove l'AI ha forse il maggiore potenziale di impatto, dato che il settore energetico è responsabile di circa il 73% delle emissioni globali di gas serra.

**Sezione 2.3** si concentra sul **monitoraggio climatico e la prevenzione dei disastri**, documentando come l'AI stia rivoluzionando le previsioni meteorologiche, i sistemi di allerta per alluvioni e il monitoraggio della biodiversità. Queste applicazioni illustrano particolarmente bene il potenziale della governance informazionale: l'AI permette di "vedere" il pianeta con una granularità e tempestività senza precedenti.

**Sezione 2.4** presenta brevemente alcune **applicazioni emergenti** in agricoltura di precisione, economia circolare e ottimizzazione delle supply chain, evidenziando la trasversalità dell'AI come strumento di sostenibilità.

**Sezione 2.5** riprende il framework teorico del Capitolo 1 per offrire un'**interpretazione sociologica** di queste applicazioni attraverso la lente della modernizzazione ecologica. Valutiamo in che misura le applicazioni "AI for Green" realizzano effettivamente le promesse della EMT informazionale, e quali sono i limiti e le condizioni che ne determinano l'efficacia.

È importante sottolineare fin dall'inizio che questo capitolo presenta deliberatamente la prospettiva più *ottimista* sul rapporto tra AI e ambiente – quella che enfatizza le potenzialità trasformative della tecnologia. Il Capitolo 3 offrirà la prospettiva complementare e critica, analizzando i costi ambientali nascosti dell'AI stessa e i meccanismi attraverso cui le promesse di efficienza possono paradossalmente portare a maggiori consumi totali. Solo tenendo insieme entrambe le prospettive – l'AI come soluzione e l'AI come problema – possiamo sviluppare una valutazione sociologicamente informata del ruolo effettivo dell'intelligenza artificiale nella transizione ecologica.

## 2.2 AI e transizione energetica

Il settore energetico rappresenta il cuore della crisi climatica contemporanea: secondo l'International Energy Agency [@IEA2024], è responsabile di circa il 73% delle emissioni globali di gas serra. La transizione da fonti fossili a fonti rinnovabili costituisce quindi la priorità assoluta per qualsiasi strategia di mitigazione climatica. In questo contesto, l'intelligenza artificiale emerge come strumento potenzialmente trasformativo, capace di affrontare alcune delle sfide tecniche più complesse che ostacolano la decarbonizzazione del sistema energetico.

Come documentato da [@Rolnick2022TacklingClimate] nella loro survey sistematica "Tackling Climate Change with Machine Learning", l'AI può contribuire alla transizione energetica attraverso tre vettori principali: ottimizzazione delle reti elettriche intelligenti, massimizzazione dell'utilizzo di energie rinnovabili attraverso migliori previsioni e gestione dello storage, e accelerazione della ricerca su nuovi materiali per tecnologie low-carbon. Ciascuno di questi ambiti presenta sfide specifiche dove le capacità di apprendimento automatico, ottimizzazione e gestione della complessità dell'AI possono tradursi in benefici ambientali concreti.

### 2.2.1 Ottimizzazione delle reti elettriche intelligenti (smart grids)

Le **smart grid** – reti elettriche intelligenti dotate di sensori, comunicazione bidirezionale e capacità di gestione dinamica – rappresentano l'infrastruttura fondamentale per integrare fonti rinnovabili su larga scala. Il problema centrale che le smart grid devono risolvere è il **bilanciamento in tempo reale tra domanda e offerta di elettricità**. A differenza delle centrali fossili tradizionali, che possono essere attivate o spente su richiesta per adattarsi ai picchi di domanda, le fonti rinnovabili come solare ed eolico sono intrinsecamente intermittenti: la loro produzione dipende dalle condizioni meteorologiche e non può essere controllata a piacimento.

Questa caratteristica crea una sfida tecnica fondamentale: in ogni istante, la quantità di elettricità immessa nella rete deve corrispondere esattamente alla quantità consumata. Uno squilibrio causa fluttuazioni di frequenza che, se non corretto, può portare a blackout su larga scala. Nel paradigma tradizionale, basato su poche grandi centrali fossili centralizzate, il bilanciamento era relativamente semplice: gli operatori di rete potevano prevedere la domanda e regolare l'output delle centrali di conseguenza. Ma con migliaia di impianti solari ed eolici distribuiti sul territorio, ciascuno con produzione variabile e parzialmente imprevedibile, il problema diventa di ordini di grandezza più complesso.

L'intelligenza artificiale, e in particolare il machine learning, offre strumenti potenti per affrontare questa complessità. Come documentato da [Rolnick], gli algoritmi di ML possono gestire simultaneamente un numero enorme di variabili – condizioni meteorologiche in diverse località, pattern di consumo storici di milioni di utenze, stato di carica dei sistemi di storage distribuiti, prezzi dell'energia in tempo reale – per ottimizzare il funzionamento della rete elettrica.

**Previsione della domanda elettrica.** Un primo ambito di applicazione riguarda la **previsione a breve e medio termine della domanda energetica**. Algoritmi di deep learning addestrati su serie temporali storiche possono apprendere pattern complessi di consumo – giornalieri, settimanali, stagionali – e correlarli con variabili esterne come temperatura, giorno della settimana, eventi speciali. Previsioni accurate della domanda permettono agli operatori di rete di programmare in anticipo l'attivazione di capacità produttiva aggiuntiva, riducendo la dipendenza da costose e inquinanti centrali di riserva ("peaker plants") che vengono attivate solo nei momenti di picco.

**Previsione della produzione da fonti rinnovabili.** Simmetricamente, l'AI può migliorare significativamente la **previsione della produzione da fonti variabili**. Algoritmi di ML analizzano dati meteorologici, satellitari e storici di produzione per stimare quanta elettricità verrà generata da impianti solari ed eolici nelle ore e nei giorni successivi. Come vedremo nella sezione 2.2.2, DeepMind ha dimostrato di poter prevedere la produzione eolica con 36 ore di anticipo, aumentando il valore economico dell'energia eolica del 20% grazie alla possibilità di partecipare ai mercati dell'energia a termine.

**Controllo e dispatch in tempo reale.** L'applicazione forse più promettente, ma anche tecnicamente più complessa, riguarda l'uso di tecniche di **reinforcement learning** per il controllo dinamico della rete elettrica. In questo paradigma, un sistema AI apprende a prendere decisioni di dispatch – quali generatori attivare, quando caricare o scaricare batterie, come gestire la domanda flessibile – attraverso simulazioni o esperienza diretta, ottimizzando obiettivi multipli: minimizzare le emissioni, garantire l'affidabilità, ridurre i costi. Alcuni operatori di rete hanno iniziato a sperimentare queste tecniche su piccola scala.

**Riduzione degli sprechi energetici.** Le reti elettriche tradizionali sono soggette a perdite significative durante la trasmissione e distribuzione dell'elettricità – in alcuni paesi queste perdite raggiungono il 10-15% della produzione totale. L'AI può contribuire a ridurre questi sprechi ottimizzando il routing dell'energia attraverso la rete, identificando anomalie che indicano furti o guasti, e migliorando la manutenzione predittiva delle infrastrutture.

**Caso studio: DeepMind e l'ottimizzazione dei data center Google.** Un esempio concreto e ben documentato del potenziale dell'AI nell'efficienza energetica è rappresentato dal progetto di Google DeepMind per l'ottimizzazione dei sistemi di raffreddamento dei data center. Secondo quanto riportato dall'International Energy Agency (2024) nel report "Electricity 2024: Analysis and forecast to 2026", Google ha utilizzato i suoi algoritmi di intelligenza artificiale DeepMind per **ridurre del 40% il consumo energetico dei sistemi di raffreddamento** dei propri data center.

I data center sono infrastrutture particolarmente energy-intensive: i sistemi di raffreddamento rappresentano tipicamente il 40% del consumo elettrico totale di un data center, bilanciati dal 40% dei server stessi e dal 20% di sistemi di alimentazione e comunicazione. L'AI di DeepMind ha appreso a gestire in modo ottimale centinaia di variabili – temperature esterne, umidità, carichi computazionali, efficienza delle diverse unità di raffreddamento – per minimizzare il consumo energetico mantenendo le temperature operative necessarie. Questo risultato dimostra concretamente come l'ottimizzazione basata su ML possa generare risparmi energetici sostanziali in sistemi complessi.

È importante notare che questa applicazione, pur essendo significativa, non riguarda direttamente le reti elettriche nazionali ma singoli edifici ad alta intensità energetica. Tuttavia, il principio è lo stesso che può essere applicato alle smart grid: gestire la complessità di sistemi con molteplici variabili interdipendenti per trovare configurazioni ottimali che riducano sprechi e massimizzino l'efficienza.

**Sfide e limiti.** Nonostante il potenziale, l'applicazione dell'AI alle smart grid affronta ostacoli significativi. Le reti elettriche sono **infrastrutture critiche** dove la sicurezza e l'affidabilità sono priorità assolute: un errore può causare blackout che colpiscono milioni di persone. Questo rende difficile sperimentare direttamente con algoritmi AI su reti reali. Inoltre, molte utilities elettriche operano ancora con sistemi legacy incompatibili con tecnologie moderne, e gli investimenti necessari per modernizzare le infrastrutture sono ingenti. Infine, la **qualità e disponibilità dei dati** rappresenta un collo di bottiglia: in molti paesi, specialmente nel Sud globale, mancano i sensori e i sistemi di monitoraggio necessari per raccogliere i dati su cui addestrare algoritmi di ML.

### 2.2.2 Massimizzazione dell'autoconsumo da fonti rinnovabili

Oltre all'ottimizzazione delle reti centralizzate, l'AI può facilitare la transizione energetica migliorando l'integrazione di **generazione distribuita** – impianti solari su tetti residenziali, piccoli parchi eolici, sistemi di storage domestici. Questo paradigma, spesso chiamato "prosumer" (produttore-consumatore), trasforma utenti passivi in partecipanti attivi al mercato energetico.

**Previsione della produzione e massimizzazione del valore economico.** Un esempio emblematico del potenziale dell'AI in questo ambito è il lavoro di Google DeepMind sulla **previsione della produzione eolica**. Come riportato da [Rolnick], DeepMind ha sviluppato modelli di machine learning capaci di prevedere la produzione energetica di parchi eolici con **36 ore di anticipo** utilizzando dati meteorologici e storici di produzione.

Questa capacità predittiva ha permesso di **aumentare del 20% il valore economico dell'energia eolica**. Come è possibile? I mercati elettrici funzionano su diverse scadenze temporali: mercati "day-ahead" dove l'energia viene venduta per il giorno successivo, mercati infragiornalieri, e mercati in tempo reale. L'energia venduta con maggiore anticipo ha generalmente un valore superiore perché offre maggiore certezza agli operatori di rete. Tuttavia, l'imprevedibilità dell'eolico ha tradizionalmente costretto i produttori a vendere solo all'ultimo momento, quando hanno certezza di quanto produrranno, accettando prezzi più bassi. Con previsioni accurate a 36 ore, i produttori possono partecipare ai mercati day-ahead, ottenendo prezzi migliori.

Questo incremento del valore economico non è solo rilevante per la redditività degli impianti eolici, ma ha implicazioni sistemiche per la transizione energetica: rende le rinnovabili più competitive rispetto alle fonti fossili, incentivando ulteriori investimenti. Dal punto di vista della modernizzazione ecologica, rappresenta un perfetto esempio di come la razionalità economica (massimizzare i profitti) possa allinearsi con la razionalità ecologica (favorire energie pulite) attraverso l'innovazione tecnologica.

**Gestione intelligente dello storage energetico.** Un'altra applicazione cruciale riguarda l'ottimizzazione dei **sistemi di accumulo** – batterie residenziali, storage su scala di utility, veicoli elettrici usati come storage distribuito (vehicle-to-grid). Il problema tecnico è determinare *quando* caricare e scaricare le batterie per massimizzare il beneficio economico e ambientale: caricare quando l'energia è abbondante (e economica e pulita), scaricare quando è scarsa (e costosa e sporca).

Algoritmi di reinforcement learning possono apprendere strategie ottimali di gestione dello storage considerando simultaneamente: previsioni di produzione rinnovabile, previsioni di domanda, prezzi dell'energia attuali e previsti, stato di carica delle batterie, degradazione delle batterie dovuta ai cicli di carica-scarica. La complessità del problema – con migliaia di batterie distribuite, pattern di produzione e consumo variabili, mercati dinamici – lo rende ideale per approcci basati su ML.

**Microgrids e autoconsumo.** L'AI può anche ottimizzare il funzionamento di **microreti** – sistemi energetici localizzati che possono operare autonomamente o connessi alla rete principale. In edifici o campus dotati di pannelli solari, batterie e carichi flessibili (come sistemi di climatizzazione), algoritmi di ML possono massimizzare l'autoconsumo di energia rinnovabile prodotta localmente, riducendo i prelievi dalla rete e minimizzando le emissioni associate.

**Gestione della domanda flessibile.** Un aspetto complementare riguarda la **demand response** – spostare temporalmente alcuni consumi energetici per allinearli con i picchi di produzione rinnovabile. Elettrodomestici come lavatrici, lavastoviglie, sistemi di riscaldamento possono essere programmati per funzionare quando l'energia solare è abbondante. L'AI può apprendere le preferenze degli utenti e ottimizzare automaticamente questi spostamenti minimizzando il disagio.

Dal punto di vista sociologico, queste applicazioni incarnano la visione della modernizzazione ecologica di una governance energetica distribuita e informazionale. Non più un sistema centralizzato top-down dove pochi grandi operatori controllano la produzione, ma un ecosistema complesso di milioni di attori – famiglie, imprese, comunità – che producono, consumano e scambiano energia in modo coordinato attraverso sistemi intelligenti. L'AI diventa l'infrastruttura cognitiva che rende possibile questa coordinazione decentralizzata.

### 2.2.3 Accelerazione della ricerca su materiali low-carbon

Forse l'applicazione più trasformativa, anche se meno immediatamente visibile, dell'AI per la transizione energetica riguarda l'**accelerazione della scoperta scientifica** di nuovi materiali. Batterie più efficienti, celle solari più economiche, catalizzatori per la produzione di idrogeno verde, materiali per la cattura del carbonio: tutte queste tecnologie dipendono dalla scoperta di nuovi composti chimici con proprietà specifiche. Tradizionalmente, questo processo è estremamente lento e costoso: i ricercatori sintetizzano e testano manualmente migliaia di materiali candidati, un processo che può richiedere anni o decenni.

L'intelligenza artificiale sta rivoluzionando questo paradigma. Come documentato da [Rolnick], il machine learning può **esplorare lo spazio di miliardi di possibili materiali** molto più rapidamente della sperimentazione fisica. Il processo funziona tipicamente così:

1. **Creazione di database.** Si raccolgono dati su materiali esistenti – composizione chimica, struttura cristallina, proprietà fisiche (conduttività, densità, stabilità termica, ecc.).

2. **Training di modelli predittivi.** Algoritmi di ML – spesso neural networks o support vector machines – apprendono le relazioni tra struttura chimica e proprietà. Essenzialmente, il modello impara a "predire" le proprietà di un materiale basandosi sulla sua composizione.

3. **Screening computazionale.** Una volta addestrato, il modello può valutare rapidamente milioni di materiali candidati mai sintetizzati prima, identificando quelli con le proprietà desiderate senza bisogno di esperimenti fisici.

4. **Sintesi e test sperimentale.** Solo i candidati più promettenti identificati dall'AI vengono effettivamente sintetizzati e testati in laboratorio, riducendo drasticamente tempo e costi.

**Applicazioni specifiche.** [Rolnick] documentano diverse applicazioni concrete di questo approccio:

- **Batterie per veicoli elettrici e storage.** Ricercatori hanno utilizzato tecniche di ML combinate con calcoli di fisica quantistica per progettare nuovi materiali conduttori per batterie al litio, potenzialmente più efficienti e meno costosi delle tecnologie attuali. Il miglioramento delle batterie è cruciale sia per i veicoli elettrici (autonomia, tempi di ricarica) sia per lo storage di rete necessario a bilanciare le fonti rinnovabili intermittenti.

- **Celle fotovoltaiche.** L'AI può identificare nuovi materiali per celle solari con migliore efficienza di conversione (più energia elettrica per unità di luce solare) o costi di produzione inferiori. Anche miglioramenti incrementali nell'efficienza hanno impatti enormi quando scalati a livello globale.

- **Solar fuels.** Alcuni ricercatori stanno usando AI, ottimizzazione e fisica computazionale per scoprire materiali che possano produrre combustibili sintetici (come idrogeno) direttamente dalla luce solare, immagazzinando energia solare in forma chimica.

- **Catalizzatori per elettrolizzatori.** La produzione di idrogeno verde attraverso elettrolisi dell'acqua richiede catalizzatori efficienti. ML può accelerare la scoperta di nuovi catalizzatori che riducano i costi e aumentino l'efficienza del processo.

**Riduzione dei tempi di R&D.** L'aspetto più rivoluzionario di questo approccio è la **compressione temporale** della ricerca. Ciò che prima richiedeva anni di esperimenti in laboratorio – sintetizzare materiali, testarne le proprietà, iterare – può ora essere in gran parte simulato computazionalmente in settimane o mesi. Come affermano [Rolnick], il machine learning può "automatizzare questo processo combinando euristiche esistenti con dati sperimentali, fisica e ragionamento per applicare ed estendere la conoscenza fisica esistente".

Questa accelerazione ha implicazioni profonde per la velocità della transizione energetica. Le tecnologie energetiche hanno tipicamente cicli di sviluppo molto lunghi – dalle prime ricerche in laboratorio alla commercializzazione possono passare 20-30 anni. Se l'AI può ridurre questi tempi anche solo del 30-50%, l'impatto sulla rapidità con cui nuove tecnologie pulite diventano disponibili potrebbe essere determinante nel rispettare le scadenze climatiche.

**Sfide metodologiche.** Naturalmente, questo approccio presenta anche limiti. I modelli di ML sono validi quanto i dati su cui vengono addestrati: se il dataset è limitato a certe classi di materiali, il modello potrebbe non generalizzare bene a composti radicalmente diversi. Inoltre, la fisica dei materiali non è completamente compresa: esistono fenomeni complessi (superconduttività ad alta temperatura, catalisi biologica) che nemmeno i migliori modelli fisici possono predire accuratamente, e quindi nemmeno il ML può farlo senza nuove scoperte scientifiche fondamentali.

Inoltre, come notano [Rolnick], rimangono sfide specifiche per il ML nella scienza dei materiali: dataset di dimensioni moderate (non i Big Data dell'internet), necessità di estrarre principi fisici interpretabili dai modelli addestrati (non solo predizioni "black box"), e la difficoltà di validare predizioni su materiali mai sintetizzati.

**Interpretazione dalla prospettiva della modernizzazione ecologica.** Dal punto di vista della teoria della modernizzazione ecologica, l'applicazione dell'AI alla scoperta di materiali rappresenta l'esempio perfetto della "intensificazione della modernizzazione" come via d'uscita dalla crisi ecologica. Non si tratta di rallentare la ricerca tecnologica o tornare a tecnologie preindustriali, ma di accelerarla ulteriormente attraverso strumenti computazionali avanzati. La promessa è che attraverso *più* scienza, *più* tecnologia, *più* innovazione – mediata dall'intelligenza artificiale – possiamo sviluppare le soluzioni tecniche necessarie a decarbonizzare l'economia.

Questo approccio si allinea perfettamente con la visione EMT di una razionalità ecologica che si realizza attraverso il progresso scientifico-tecnologico piuttosto che attraverso la sua limitazione. Tuttavia, solleva anche domande critiche che emergeranno nel Capitolo 3: chi ha accesso a queste capacità di AI? Come vengono distribuiti i benefici delle scoperte? E soprattutto, qual è il costo energetico e materiale dell'infrastruttura computazionale stessa necessaria per addestrare questi modelli di ML?

### 2.2.4 Considerazioni conclusive sulla transizione energetica

Le applicazioni dell'AI alla transizione energetica documentate in questa sezione – ottimizzazione delle smart grid, massimizzazione delle rinnovabili, accelerazione della ricerca materiali – condividono alcune caratteristiche comuni che vale la pena evidenziare:

**Gestione della complessità.** In tutti i casi, l'AI affronta problemi caratterizzati da un enorme numero di variabili interdipendenti, pattern non lineari, e necessità di decisioni in tempo reale. Questi sono precisamente i tipi di problemi dove il machine learning eccelle rispetto agli approcci tradizionali.

**Disaccoppiamento potenziale.** Dal punto di vista della modernizzazione ecologica, queste applicazioni promettono di realizzare il "disaccoppiamento" tra servizi energetici (elettricità affidabile, trasporti, riscaldamento) e impatto ambientale (emissioni di CO2). Non richiedono che i consumatori riducano il loro utilizzo di energia, ma che la stessa quantità di energia sia fornita in modo più pulito ed efficiente.

**Scalabilità economica.** Un algoritmo ML, una volta sviluppato, può essere replicato a costo marginale quasi nullo. Una smart grid ottimizzata da AI in California può ispirare implementazioni simili in Europa o Asia. Un modello predittivo per la produzione solare può essere adattato a diversi contesti geografici. Questa scalabilità è cruciale per la rapidità della transizione globale.

Tuttavia, è essenziale mantenere uno sguardo critico. Le applicazioni descritte rappresentano il potenziale *tecnico* dell'AI, ma la loro effettiva implementazione su larga scala dipende da fattori istituzionali, economici e politici: investimenti in infrastrutture, regolamentazione dei mercati energetici, volontà politica di prioritizzare la decarbonizzazione. Come vedremo nella sezione 2.5, la tecnologia da sola non garantisce la transizione: sono necessarie condizioni abilitanti.

Inoltre, queste applicazioni "AI for Green" rappresentano ancora una piccola frazione dell'uso totale dell'intelligenza artificiale a livello globale. La maggior parte delle risorse computazionali dedicate all'AI è impiegata in ambiti commerciali – pubblicità online, raccomandazioni di contenuti, riconoscimento facciale – che hanno scarsa o nulla rilevanza per la crisi climatica. Come documentato da Kaack  (2022), le applicazioni climate-positive dell'AI rimangono una nicchia all'interno del settore AI globale.

Infine, e questo sarà il tema centrale del Capitolo 3, dobbiamo interrogarci sul costo ambientale dell'infrastruttura computazionale stessa. I data center che addestrano modelli di ML per ottimizzare le reti elettriche consumano essi stessi enormi quantità di elettricità. I GPU necessari per il deep learning richiedono minerali rari e generano rifiuti elettronici. Esiste il rischio, come vedremo, che i benefici ambientali delle applicazioni "AI for Green" siano vanificati dall'impronta ecologica dell'AI stessa – un paradosso che la teoria della modernizzazione ecologica fatica a riconoscere.

## 2.3 Monitoraggio climatico e prevenzione dei disastri

Se la transizione energetica rappresenta il dominio dove l'AI può fornire il maggiore contributo alla *mitigazione* del cambiamento climatico, il monitoraggio climatico e la prevenzione dei disastri costituiscono il terreno più promettente per l'*adattamento*. In questo ambito, l'intelligenza artificiale sta rivoluzionando sia la nostra capacità di comprendere e prevedere il sistema climatico, sia la nostra capacità di proteggere popolazioni e infrastrutture dagli eventi estremi sempre più frequenti e intensi che caratterizzano l'Antropocene.

Come sottolineato nel Capitolo 1, il monitoraggio ambientale automatizzato su scala planetaria rappresenta una delle manifestazioni più emblematiche della modernizzazione ecologica informazionale: l'AI permette di "vedere" il pianeta con una granularità spaziale e temporale senza precedenti, trasformando enormi volumi di dati grezzi (immagini satellitari, misurazioni meteorologiche, registrazioni acustiche) in informazioni utilizzabili per decisioni di policy, pianificazione e intervento d'emergenza. Questa "governance informazionale" estende radicalmente il raggio d'azione della razionalità ecologica discussa da Mol e Spaargaren.

Questa sezione documenta tre aree di applicazione dove l'AI sta generando impatti particolarmente significativi: le previsioni meteorologiche di medio termine, i sistemi di allerta precoce per disastri naturali (con particolare focus sulle alluvioni), e il monitoraggio della biodiversità e della deforestazione.

### 2.3.1 Previsioni meteorologiche basate su AI: una rivoluzione metodologica

Le previsioni meteorologiche hanno rappresentato per decenni uno dei trionfi della scienza computazionale applicata. I modelli numerici tradizionali – noti come Numerical Weather Prediction (NWP) systems – si basano sulla simulazione fisica dell'atmosfera: risolvono numericamente le equazioni differenziali che governano la dinamica dei fluidi atmosferici, la termodinamica, la radiazione solare e altri processi fisici. Questi modelli, come il sistema HRES (High RESolution) dell'European Centre for Medium-Range Weather Forecasts (ECMWF), rappresentano il gold standard delle previsioni meteorologiche globali.

Tuttavia, i modelli NWP tradizionali presentano limitazioni significative. Primo, sono computazionalmente estremamente costosi: una singola previsione globale a 10 giorni richiede ore di calcolo su supercomputer massivi, consumando enormi quantità di energia. Secondo, la loro risoluzione spaziale è inevitabilmente limitata dalle risorse computazionali disponibili: aumentare la risoluzione richiede un incremento esponenziale della potenza di calcolo necessaria. Terzo, la loro accuratezza tende a degradare rapidamente oltre i 7-10 giorni di anticipo a causa della natura caotica dell'atmosfera.

#### Il paradigma dell'AI meteorologica: GraphCast e l'apprendimento dai dati storici

Negli ultimi anni, un approccio radicalmente diverso ha iniziato a emergere: invece di simulare esplicitamente la fisica dell'atmosfera, i modelli basati su machine learning *apprendono* le dinamiche atmosferiche direttamente dai dati storici. Questo cambio di paradigma – da modelli basati su equazioni fisiche a modelli basati su pattern appresi dai dati – sta producendo risultati sorprendenti.

Il caso più emblematico è **GraphCast**, un modello sviluppato da DeepMind e pubblicato su *Science* nel 2023 da Lam e colleghi. GraphCast rappresenta il primo sistema di machine learning a superare sistematicamente il modello HRES dell'ECMWF – considerato il sistema NWP più accurato al mondo – su un'ampia gamma di variabili meteorologiche e orizzonti temporali.

**Architettura e funzionamento tecnico.** GraphCast è un modello basato su Graph Neural Networks (GNN), una classe di reti neurali progettata per operare su dati strutturati come grafi. La superficie terrestre viene rappresentata come una griglia a risoluzione 0,25° di latitudine/longitudine (approssimativamente 28×28 km all'equatore), che corrisponde a circa 40.000 punti di griglia distribuiti sul pianeta. Ogni punto contiene informazioni su cinque variabili superficiali (temperatura a 2 metri, componenti del vento a 10 metri, pressione al livello del mare, precipitazione totale) e sei variabili atmosferiche misurate a 37 livelli di pressione verticali (temperatura, vento orizzontale e verticale, geopotenziale, umidità specifica).

Il modello prende come input lo stato corrente dell'atmosfera e lo stato di sei ore prima, e predice lo stato dell'atmosfera sei ore nel futuro. Questa previsione può poi essere iterata – usando le previsioni precedenti come nuovi input – per generare previsioni fino a 10 giorni di anticipo. Ciò che richiede ore di calcolo ai modelli NWP tradizionali, GraphCast lo produce in meno di un minuto su un singolo processore Google Cloud TPU v4.

**Training e validazione.** GraphCast è stato addestrato su 39 anni di dati storici (1979-2017) provenienti dal dataset di rianalisi ERA5 dell'ECMWF – essenzialmente la "migliore ricostruzione possibile" dello stato storico dell'atmosfera ottenuta combinando osservazioni e simulazioni fisiche. L'obiettivo di apprendimento era minimizzare l'errore tra le previsioni del modello e gli stati atmosferici realmente osservati.

La validazione è stata condotta sui dati degli anni 2018-2021, mai visti durante il training. GraphCast ha dimostrato accuratezza superiore a HRES su 90% delle 227 combinazioni variabile-livello-orizzonte temporale testate. Il vantaggio è particolarmente marcato per orizzonti temporali oltre le 36 ore e per variabili cruciali come la temperatura, il vento e l'umidità.

**Previsione di eventi estremi: il test dei cicloni tropicali.** Particolarmente impressionante è la capacità di GraphCast di prevedere fenomeni ad alto impatto come i cicloni tropicali. Lam e colleghi hanno testato sistematicamente la previsione delle traiettorie cicliche su tutti gli eventi del periodo 2018-2021. GraphCast ha mostrato errori mediani di traiettoria significativamente inferiori a HRES per orizzonti temporali da 18 ore fino a 4,75 giorni. Questo significa che GraphCast può identificare dove un uragano colpirà con maggiore anticipo e precisione – informazione cruciale per evacuazioni e preparazione d'emergenza.

Analogamente, per eventi di temperatura estrema (ondate di calore e freddo) e per fiumi atmosferici (stretti corridoi di intenso trasporto di vapore acqueo che causano precipitazioni estreme sulla costa occidentale degli Stati Uniti), GraphCast ha dimostrato capacità predittive superiori. Queste non sono variabili per cui il modello è stato esplicitamente ottimizzato durante il training – emerge spontaneamente dalla sua capacità di apprendere pattern atmosferici complessi dai dati storici.

#### Pangu-Weather e l'ecosistema emergente di modelli AI

GraphCast non è un caso isolato. Quasi contemporaneamente, ricercatori di Huawei hanno sviluppato **Pangu-Weather**, un modello basato su architettura Transformer (la stessa famiglia usata per i grandi modelli linguistici come GPT) che ha dimostrato performance competitive o superiori ai modelli NWP tradizionali. Anche altri gruppi di ricerca stanno producendo modelli ML per previsioni meteorologiche con risultati promettenti.

Questa convergenza di risultati positivi da team indipendenti suggerisce che non si tratta di un artefatto metodologico ma di una genuina superiorità dell'approccio basato su ML, almeno per determinati compiti e orizzonti temporali. Si sta configurando un nuovo ecosistema di modelli meteorologici basati su AI che coesistono e in alcuni casi superano i sistemi tradizionali.

#### Effetto di recency e adattamento ai cambiamenti climatici

Un aspetto particolarmente rilevante nel contesto del cambiamento climatico è la capacità di GraphCast di adattarsi a pattern meteorologici in evoluzione. Lam e colleghi hanno addestrato quattro varianti del modello usando dati che si fermavano rispettivamente al 2017, 2018, 2019 e 2020. Hanno scoperto che le performance su dati del 2021 miglioravano progressivamente: il modello addestrato fino al 2020 era più accurato di quello addestrato fino al 2018.

Questo "effetto di recency" suggerisce che GraphCast può catturare tendenze climatiche in atto – pattern meteorologici che stanno cambiando a causa del riscaldamento globale. Questa è una proprietà cruciale: mentre i modelli NWP tradizionali si basano su equazioni fisiche che assumono un sistema climatico stazionario, i modelli ML possono in linea di principio adattarsi a un clima che cambia semplicemente venendo riaddestrati periodicamente con dati recenti.

#### Implicazioni per la governance informazionale

La rivoluzione delle previsioni meteorologiche basate su AI ha implicazioni profonde per la governance informazionale discussa nel framework della modernizzazione ecologica:

**Democratizzazione dell'accesso.** Mentre gestire un supercomputer per previsioni NWP richiede investimenti di decine o centinaia di milioni di dollari, eseguire un modello ML pre-addestrato come GraphCast richiede risorse computazionali relativamente modeste. Questo potrebbe permettere a paesi in via di sviluppo, istituzioni di ricerca minori, o anche organizzazioni non governative di accedere a previsioni meteorologiche di alta qualità senza dipendere da grandi centri meteorologici.

**Velocità e efficienza computazionale.** La differenza di velocità – minuti invece di ore – non è solo una curiosità tecnica. Significa che si possono generare molte più previsioni alternative (ensemble) per quantificare l'incertezza, o che si possono produrre previsioni aggiornate con maggiore frequenza incorporando le osservazioni più recenti. Nel contesto di eventi in rapida evoluzione come tempeste, questa velocità può fare la differenza tra un'evacuazione tempestiva e una tardiva.

**Efficienza energetica.** GraphCast consuma drasticamente meno energia di un modello NWP tradizionale per produrre una previsione equivalente. In un contesto dove ogni riduzione di consumo energetico contribuisce alla mitigazione climatica, questo è un beneficio aggiuntivo non trascurabile – benché, come vedremo nel Capitolo 3, debba essere bilanciato contro i costi energetici del training iniziale del modello.

#### Limiti e complementarietà con modelli fisici

È importante sottolineare che i modelli ML meteorologici presentano anche limiti significativi. Primo, sono essenzialmente sistemi di interpolazione statistica: apprendono pattern dai dati storici e li proiettano nel futuro. Questo significa che possono avere difficoltà con eventi senza precedenti o situazioni al di fuori della distribuzione dei dati di training. Secondo, sono "scatole nere" opache: mentre un meteorologo può interpretare cosa sta "pensando" un modello NWP guardando le equazioni e le variabili intermedie, capire *perché* un modello ML fa una certa previsione è molto più difficile. Terzo, i modelli ML dipendono criticamente dalla qualità e completezza dei dati di training.

Per queste ragioni, il futuro più probabile non è la sostituzione completa dei modelli NWP con modelli ML, ma una loro integrazione complementare: modelli ML per previsioni rapide ed efficienti di routine, modelli NWP per situazioni critiche e per validare fisicamente le previsioni ML, e sistemi ibridi che combinano i punti di forza di entrambi gli approcci.

### 2.3.2 Sistemi di allerta precoce per alluvioni: proteggere le popolazioni vulnerabili

Se le previsioni meteorologiche accurate sono il primo anello della catena di protezione dalle catastrofi naturali, i sistemi di allerta precoce specifici per determinati rischi costituiscono l'ultimo miglio – il passaggio dall'informazione meteorologica generale all'azione protettiva concreta per popolazioni a rischio.

Le alluvioni rappresentano uno dei disastri naturali più devastanti e frequenti. Causano migliaia di vittime ogni anno, distruggono infrastrutture critiche, contaminano fonti idriche, e colpiscono in modo sproporzionato le comunità più vulnerabili. Il cambiamento climatico sta intensificando il ciclo idrologico globale: l'atmosfera più calda contiene più vapore acqueo, portando a precipitazioni più intense e concentrate. Molte regioni stanno sperimentando sia siccità più severe (quando non piove) sia alluvioni più devastanti (quando piove).

#### Il divario dati globale e la sfida dei bacini non monitorati

Tradizionalmente, le previsioni di alluvioni fluviali si basano su reti di sensori idrometrici (misuratori di livello e flusso dei fiumi) combinati con modelli idrologici che simulano come la pioggia si trasforma in deflusso superficiale e scorre attraverso i bacini idrografici. Questi sistemi funzionano bene dove esistono – tipicamente nei paesi sviluppati con risorse adeguate per installare e mantenere reti di sensori dense.

Il problema è che la maggior parte dei bacini fluviali del mondo non ha alcun monitoraggio. Rolnick e colleghi stimano che oltre l'80% delle aree soggette a rischio alluvionale globale mancano di sistemi di allerta funzionanti. Questo divario dati riflette profonde disuguaglianze globali: i paesi che hanno maggiore bisogno di sistemi di allerta (paesi del Sud globale esposti a monsoni, cicloni tropicali, e con infrastrutture vulnerabili) sono spesso quelli che meno possono permettersi di installarli.

L'AI offre un percorso per colmare questo divario attraverso approcci che non dipendono da reti di sensori locali ma utilizzano dati globalmente disponibili come immagini satellitari, modelli di elevazione del terreno, e dati meteorologici.

#### Google Flood Hub: un caso di studio di democratizzazione della protezione

Il sistema più ambizioso attualmente operativo è **Google Flood Hub**, lanciato nel 2018 e progressivamente espanso fino a coprire oltre 80 paesi e fornire previsioni per più di 460 milioni di persone. Flood Hub rappresenta un esempio paradigmatico di come l'AI possa essere usata per "colmare il divario dati tra Nord e Sud globale", come sottolineato nell'indice della presente tesi.

**Architettura tecnica.** Il sistema combina diversi componenti di machine learning in una pipeline integrata:

1. **Modelli idrologici guidati da ML.** Invece di richiedere dati idrometrici locali, il sistema usa modelli di machine learning addestrati su bacini monitorati per apprendere la relazione tra precipitazioni previste, caratteristiche del terreno (pendenza, permeabilità del suolo, copertura vegetale ricavata da satellite), e portata dei fiumi. Questi modelli vengono poi applicati a bacini non monitorati con caratteristiche simili.

2. **Modelli di inondazione basati su fisica e ML.** Una volta prevista la portata del fiume, un secondo set di modelli predice l'estensione spaziale dell'inondazione – quali aree verranno sommerse e a che profondità. Questi modelli combinano simulazioni fisiche del flusso dell'acqua con apprendimento automatico per accelerare i calcoli.

3. **Sistema di allerta a 5 giorni di anticipo.** Flood Hub può emettere previsioni di alluvione fino a 5 giorni prima dell'evento previsto. Questo orizzonte temporale è cruciale: permette evacuazioni ordinate, mobilitazione di risorse di emergenza, e comunicazioni preventive alle comunità a rischio.

**Impatto e validazione sul campo.** Nearing e colleghi (2024) hanno documentato l'accuratezza del sistema in diversi contesti geografici. Le previsioni sono state validate contro eventi alluvionali realmente osservati, mostrando tassi di rilevamento (capacità di identificare eventi che si sono effettivamente verificati) e precisione (capacità di non generare falsi allarmi) che rendono il sistema utilizzabile operativamente.

Particolarmente significativo è l'impatto in paesi come Bangladesh, India, e nazioni africane dove precedentemente non esistevano sistemi di allerta. Durante la stagione dei monsoni del 2022 in Bangladesh, Flood Hub ha emesso allerte che hanno permesso evacuazioni preventive di decine di migliaia di persone da aree che sono state successivamente sommerse.

**Interfaccia accessibile e localizzazione.** Flood Hub non è solo un sistema tecnico sofisticato ma anche uno strumento progettato per essere accessibile. Le previsioni sono visualizzate su mappe interattive disponibili pubblicamente online, con informazioni tradotte in lingue locali. Le allerte possono essere integrate con servizi di notifica via SMS o attraverso canali di comunicazione già usati dalle comunità locali.

#### Giustizia climatica e riduzione delle disuguaglianze

Dal punto di vista della sociologia ambientale e della giustizia climatica, Flood Hub rappresenta un caso interessante di tecnologia che potenzialmente riduce anziché amplificare le disuguaglianze. Le comunità più vulnerabili alle alluvioni sono spesso quelle che hanno contribuito meno alle emissioni storiche di gas serra – un'ingiustizia fondamentale dell'antropocene. Un sistema di allerta accessibile gratuitamente, che non richiede investimenti locali in infrastrutture, rappresenta una forma di "trasferimento tecnologico" che avviene attraverso il cloud piuttosto che attraverso aiuti allo sviluppo tradizionali.

Tuttavia, rimangono sfide significative. L'efficacia di qualsiasi sistema di allerta dipende non solo dall'accuratezza tecnica ma dalla capacità istituzionale e sociale di agire sulle informazioni: esistono piani di evacuazione? Le comunità si fidano delle allerte? Esistono rifugi sicuri raggiungibili? La comunicazione raggiunge le popolazioni rurali senza accesso internet affidabile? Queste "last mile problems" – il passaggio dall'informazione all'azione – richiedono investimenti complementari in capacità istituzionale, infrastrutture di comunicazione, e costruzione di fiducia sociale.

#### Altre applicazioni di ML per disastri naturali

Oltre alle alluvioni, il machine learning viene applicato a una crescente varietà di rischi naturali:

**Incendi boschivi.** Modelli ML analizzano immagini satellitari per rilevare focolai incendiari nelle fasi iniziali (quando sono ancora controllabili), predire la progressione spaziale del fuoco in base a vento e topografia, e ottimizzare l'allocazione di risorse di spegnimento. Durante la stagione degli incendi californiani, sistemi basati su ML hanno dimostrato capacità di rilevamento più rapide dei metodi tradizionali.

**Ondate di calore.** Deep learning su dati meteorologici storici può identificare pattern che precedono ondate di calore estreme, permettendo allerte con giorni di anticipo. Questo è particolarmente rilevante per proteggere popolazioni vulnerabili (anziani, lavoratori all'aperto) in contesti urbani dove l'effetto "isola di calore" amplifica le temperature.

**Tempeste e uragani.** Come documentato nella sezione su GraphCast, l'AI sta migliorando le previsioni di traiettoria e intensità dei cicloni tropicali, estendendo l'orizzonte temporale delle allerte e riducendo le "zone di incertezza" delle evacuazioni.

### 2.3.3 Monitoraggio della deforestazione e della biodiversità: "vedere" il pianeta vivente

Se le sezioni precedenti hanno documentato come l'AI permetta di "vedere" l'atmosfera e i suoi pericoli con accuratezza senza precedenti, questa sezione illustra come analoghe tecnologie stiano trasformando la nostra capacità di monitorare la biosfera terrestre – le foreste, gli ecosistemi, e la biodiversità che sostengono la vita sul pianeta.

La deforestazione contribuisce approssimativamente al 10% delle emissioni globali di gas serra quando la vegetazione viene bruciata o decade, rilasciando il carbonio precedentemente sequestrato. Oltre al contributo diretto al cambiamento climatico, la perdita di foreste distrugge habitat critici per la biodiversità, degrada servizi ecosistemici (regolazione idrica, prevenzione dell'erosione), e impatta i mezzi di sussistenza di comunità indigene e rurali. Circa l'80% della deforestazione globale è causata dall'espansione agricola (conversione di foreste in pascoli o coltivazioni), mentre cause secondarie includono estrazione mineraria, taglio legale e illegale del legname, e sviluppo urbano.

#### Remote sensing e computer vision per la deforestazione

Le tecniche di **remote sensing** – l'acquisizione di informazioni sulla superficie terrestre tramite sensori su satelliti o aerei – hanno da tempo permesso di monitorare i cambiamenti nella copertura forestale. Satelliti come quelli della costellazione Landsat (operativa dal 1972) producono immagini multispettrali della superficie terrestre che possono essere analizzate per identificare diversi tipi di vegetazione.

Ciò che l'AI aggiunge è la capacità di automatizzare completamente questa analisi su scala planetaria e in tempo quasi-reale. Algoritmi di **computer vision** basati su reti neurali convoluzionali (CNN) possono essere addestrati a identificare cambiamenti nella copertura forestale confrontando immagini successive della stessa area. Questi sistemi apprendono a distinguere tra perdita di foresta dovuta a deforestazione vera e propria, perdita temporanea dovuta ad agricoltura rotazionale, perdita naturale dovuta a incendi spontanei o tempeste, e false rilevazioni dovute a copertura nuvolosa o ombre.

#### Global Forest Watch: sorveglianza forestale partecipativa

**Global Forest Watch (GFW)** è una piattaforma online che combina dati satellitari, algoritmi di machine learning, e tecnologie cloud per fornire monitoraggio della deforestazione quasi in tempo reale a scala globale. Lanciata nel 2014 e gestita dal World Resources Institute in collaborazione con Google e altre organizzazioni, GFW analizza automaticamente immagini satellitari Landsat per rilevare perdita di copertura arborea con risoluzione di 30 metri e latenza di poche settimane.

**Funzionalità tecniche.** Il sistema si basa su algoritmi di classificazione supervisionata: il modello ML viene addestrato su esempi etichettati di "foresta", "non-foresta", e "perdita di foresta", e impara a identificare questi pattern in nuove immagini. La classificazione avviene automaticamente per ogni nuova immagine satellitare disponibile, coprendo l'intero pianeta. Gli utenti possono:

- Visualizzare mappe interattive della perdita di copertura forestale per qualsiasi regione del mondo
- Iscriversi ad allerte automatiche quando viene rilevata deforestazione in aree specifiche (ad esempio, riserve protette)
- Scaricare dati grezzi per analisi indipendenti
- Sovrapporre dati sulla deforestazione con altre informazioni geografiche (confini di concessioni minerarie, aree protette, territori indigeni)

**Impatto su enforcement e accountability.** GFW ha dimostrato impatti documentabili su policy e enforcement. In Indonesia, ONG ambientaliste hanno usato le allerte di GFW per identificare deforestazione illegale nelle concessioni di palma da olio e presentare esposti alle autorità di regolamentazione. In Brasile, i dati di GFW sono stati usati per monitorare l'efficacia (o inefficacia) delle politiche di protezione forestale, creando pressione pubblica su governi. A livello globale, investitori e aziende utilizzano GFW per monitorare le supply chain e verificare claim di "zero deforestazione" da parte di fornitori.

**Differenziazione tra taglio selettivo e deforestazione totale.** Sviluppi più recenti degli algoritmi permettono non solo di rilevare *se* c'è stata perdita di copertura, ma anche di che *tipo*: deforestazione completa (conversione permanente a uso non-forestale) versus taglio selettivo (rimozione di alcuni alberi mantenendo la struttura forestale). Questa distinzione è cruciale per policy: il taglio selettivo sostenibile è molto diverso dalla conversione permanente a pascolo o miniera.

#### Monitoraggio acustico e biodiversità

Mentre il remote sensing ottico (immagini) si concentra sulla copertura vegetale, un filone emergente usa **remote sensing acustico** per monitorare la fauna. Sensori audio alimentati a energia solare vengono installati nelle foreste per registrare continuamente i suoni dell'ambiente. Algoritmi di machine learning analizzano queste registrazioni per:

- **Rilevare attività umane dannose.** Un progetto chiamato Rainforest Connection installa vecchi smartphone nelle foreste pluviali tropicali che registrano continuamente audio e usano ML per rilevare suoni di motoseghe entro un raggio di un chilometro. Quando viene rilevato un suono sospetto, viene inviata un'allerta in tempo reale ai ranger forestali che possono intervenire.

- **Identificare specie tramite vocalizzazioni.** Reti neurali addestrate su database di richiami di uccelli, mammiferi, anfibi possono identificare automaticamente quali specie sono presenti in un'area basandosi sulle registrazioni acustiche. Questo permette monitoraggio della biodiversità su vasta scala senza richiedere la presenza fisica di biologi.

#### Citizen science e riconoscimento automatico di specie

Piattaforme come **iNaturalist** combinano crowdsourcing (citizen science) e machine learning per costruire database massicci di osservazioni di biodiversità. Gli utenti caricano foto di piante, animali, funghi osservati in natura; algoritmi di computer vision suggeriscono identificazioni automatiche; esperti umani validano le identificazioni; il sistema apprende continuamente migliorando le sue capacità di riconoscimento.

Al 2022, iNaturalist contava oltre 100 milioni di osservazioni verificate di più di 400.000 specie diverse. Questo database crowdsourced sta diventando una risorsa cruciale per la ricerca ecologica e la conservazione: permette di tracciare distribuzioni di specie, identificare trend popolazionali, rilevare specie invasive in espansione, e coinvolgere il pubblico nella scienza della biodiversità.

**Wildlife Insights** è una piattaforma analoga focalizzata su immagini da fototrappole – camere automatiche che si attivano quando rilevano movimento e che vengono installate nelle aree selvagge per monitorare fauna sfuggente. Tradizionalmente, analizzare migliaia di immagini da fototrappole richiedeva centinaia di ore di lavoro umano per identificare quali contenevano animali e di che specie. Algoritmi di deep learning riducono questo lavoro del 99%: identificano automaticamente se un'immagine contiene un animale, di che specie, quanti individui, che comportamento stanno mostrando.

#### Dalla sorveglianza alla giustizia: questioni critiche

Il monitoraggio ambientale basato su AI solleva anche questioni critiche che verranno approfondite nel Capitolo 3. Chi controlla questi sistemi di sorveglianza? A chi appartengono i dati? Come vengono usati?

Nel contesto della deforestazione, c'è il rischio che la sorveglianza venga usata principalmente per criminalizzare piccoli agricoltori o comunità indigene che praticano agricoltura di sussistenza, mentre attori più potenti (grandi corporazioni agro-industriali, concessionari minerari con connessioni politiche) sfuggono alle conseguenze. La tecnologia di monitoraggio è neutrale rispetto al potere – può essere usata tanto per proteggere quanto per controllare.

Analogamente, nel monitoraggio della biodiversità emerge la questione di chi beneficia della conoscenza generata. Database globali di biodiversità costruiti tramite AI incorporano spesso conoscenza ecologica tradizionale di comunità indigene – ma queste comunità ricevono riconoscimento e benefici?

Nonostante queste legittime preoccupazioni, è innegabile che la capacità di "vedere il pianeta vivente" con la granularità e continuità rese possibili dall'AI rappresenta uno strumento potenzialmente potente per la governance ambientale. Come sottolineato dalla teoria della modernizzazione ecologica, la trasparenza informazionale è una precondizione necessaria (benché non sufficiente) per l'accountability ecologica.

### 2.3.4 Sintesi: l'AI come estensione radicale della governance informazionale

Le applicazioni documentate in questa sezione – dalle previsioni meteorologiche ai sistemi di allerta alluvioni, dal monitoraggio forestale al riconoscimento della biodiversità – condividono una logica comune che risuona profondamente con i principi della modernizzazione ecologica informazionale discussi nel Capitolo 1.

**Primo, trasformazione di dati grezzi in conoscenza utilizzabile.** In tutti i casi, l'AI agisce come intermediario che traduce enormi volumi di dati grezzi (pixel di immagini satellitari, misurazioni meteorologiche, registrazioni acustiche) in informazioni comprensibili e utilizzabili: "questa area sta per essere allagata", "questa foresta è stata abbattuta", "questa specie è in declino". Questa traduzione non è banale – richiede pattern recognition sofisticato che solo recentemente è diventato possibile grazie ai progressi del machine learning.

**Secondo, scalabilità globale e democratizzazione.** Queste applicazioni operano a scala planetaria, fornendo capacità di monitoraggio a regioni e comunità che non potrebbero mai permettersi sistemi tradizionali. Flood Hub serve 460 milioni di persone in 80+ paesi; Global Forest Watch copre tutte le foreste tropicali del mondo; GraphCast produce previsioni globali accessibili a chiunque abbia una connessione internet. Questa è governance informazionale distribuita e democratizzata.

**Terzo, velocità e tempestività.** La differenza tra una previsione prodotta in minuti invece che in ore, tra un'allerta di alluvione con 5 giorni invece di 1 giorno di anticipo, tra la rilevazione di deforestazione con settimane invece che mesi di latenza – queste differenze temporali si traducono in capacità concreta di azione preventiva.

**Quarto, colmare il divario Nord-Sud.** Un tema ricorrente è come l'AI permetta di estendere capacità di monitoraggio e previsione precedentemente disponibili solo ai paesi ricchi a regioni del Sud globale. Questo non risolve magicamente le disuguaglianze strutturali – come vedremo nel Capitolo 3, l'infrastruttura AI stessa riproduce e amplifica certe disuguaglianze – ma rappresenta un potenziale contrappeso.

Tuttavia, è cruciale mantenere una prospettiva equilibrata. Come sottolineato nell'introduzione al capitolo, queste applicazioni sono ancora una *nicchia* rispetto all'uso totale dell'AI globalmente. La loro efficacia dipende da fattori istituzionali, politici ed economici che vanno oltre la tecnologia: sistemi di allerta non salvano vite se non esistono piani di evacuazione o se le comunità non si fidano delle autorità; il monitoraggio della deforestazione non ferma il taglio illegale se non c'è volontà politica di enforcement.

E soprattutto, come documenteremo nel Capitolo 3, l'infrastruttura computazionale che rende possibili queste applicazioni benefiche ha essa stessa un'impronta ecologica considerevole. La promessa dell'AI come strumento di razionalità ecologica deve essere valutata insieme alla realtà dell'AI come sistema ad alta intensità energetica, idrica e materiale. Solo tenendo insieme entrambe le prospettive – l'AI for Green e l'AI come problema ambientale – possiamo sviluppare una comprensione sociologicamente informata del ruolo dell'intelligenza artificiale nell'Antropocene.

## 2.4 Applicazioni emergenti e settoriali

Le sezioni precedenti hanno documentato le applicazioni dell'intelligenza artificiale nei due domini dove gli impatti sono potenzialmente più significativi per la mitigazione climatica: il sistema energetico, responsabile del 73% delle emissioni globali di gas serra, e i sistemi di monitoraggio e previsione per l'adattamento ai cambiamenti climatici. Ma l'AI si sta diffondendo come strumento di sostenibilità ambientale in una molteplicità di altri settori. Questa sezione presenta brevemente alcune applicazioni emergenti che, pur non raggiungendo ancora la maturità e l'impatto documentato delle precedenti, illustrano la **trasversalità** dell'AI come tecnologia abilitante per la transizione ecologica.

In particolare, ci concentriamo su due ambiti dove l'AI sta dimostrando un potenziale significativo: l'agricoltura di precisione, che promette di ridurre drasticamente l'impronta ambientale della produzione alimentare, e l'ottimizzazione delle supply chain e l'economia circolare, dove l'AI può contribuire a minimizzare gli sprechi lungo l'intero ciclo di vita dei prodotti. Entrambi questi settori hanno un peso rilevante nelle emissioni globali – l'uso del suolo è responsabile di circa un quarto delle emissioni totali di gas serra – e rappresentano quindi obiettivi cruciali per qualsiasi strategia di decarbonizzazione.

### 2.4.1 Agricoltura di precisione: ottimizzare la produzione alimentare

L'agricoltura industriale moderna costituisce una fonte significativa di emissioni di gas serra, ma non per le ragioni che intuitivamente potremmo pensare. Sebbene le piante assorbano CO2 dall'atmosfera, i processi associati alla produzione agricola intensiva generano impatti ambientali considerevoli attraverso tre meccanismi principali [Rolnick]: 

**Primo, la preparazione del terreno.** La terra viene generalmente spogliata della vegetazione esistente, rilasciando il carbonio sequestrato. Il processo di aratura espone il suolo superficiale all'aria, rilasciando così il carbonio che era stato trattenuto negli aggregati del suolo e distruggendo i microrganismi che contribuiscono al sequestro.

**Secondo, l'uso di fertilizzanti azotati.** Poiché le pratiche agricole intensive impoveriscono il suolo di nutrienti, i fertilizzanti a base di azoto devono essere aggiunti nuovamente al sistema. La sintesi di questi fertilizzanti consuma quantità enormi di energia – circa il 2% del consumo energetico globale. Inoltre, mentre parte di questo azoto viene assorbito dalle piante o trattenuto nel suolo, una parte significativa viene convertita in protossido di azoto (N2O), un gas serra circa 300 volte più potente della CO2.

**Terzo, le emissioni da allevamento.** Il bestiame e la coltivazione del riso generano metano, un gas serra molto più potente della CO2 stessa.

#### Le promesse dell'agricoltura di precisione

Secondo una stima citata da [Rolnick] circa **un terzo delle riduzioni di emissioni di gas serra potrebbe provenire da una migliore gestione del suolo e dell'agricoltura**. L'intelligenza artificiale può svolgere un ruolo importante in questo ambito attraverso l'agricoltura di precisione – un approccio che, come osservano gli autori, "si basa fondamentalmente sul rendere le terre agricole più uniformi e prevedibili", ma che ora, grazie all'AI, può essere gestito su larga scala pur adattandosi all'eterogeneità della terra e delle colture.

L'approccio tradizionale dell'agricoltura industriale tratta il terreno come uniforme, utilizzando strumenti di automazione di base come i trattori. Questo può essere sia più distruttivo che meno produttivo rispetto ad approcci che lavorano con l'eterogeneità naturale del suolo. L'agricoltura di precisione, al contrario, riconosce e sfrutta questa eterogeneità: c'è una crescente domanda di strumenti sofisticati che permettano agli agricoltori di lavorare su larga scala adattandosi alle specifiche esigenze del terreno.

#### Applicazioni concrete e strumenti robotici intelligenti

**Robot intelligenti per interventi mirati.** Sono in fase di sviluppo robot dotati di capacità di diserbo meccanico, applicazione mirata di pesticidi e aspirazione di parassiti. Questi robot possono raccogliere grandi quantità di dati per un miglioramento continuo. Numerose aziende operano ormai nello spazio della robotica assistita da ML per l'agricoltura di precisione.

**Sistemi di irrigazione intelligenti.** I sistemi di irrigazione basati su AI possono risparmiare grandi quantità di acqua riducendo al contempo i parassiti che prosperano in condizioni di eccessiva umidità [Rolnick].

**Rilevamento di malattie ed erbe infestanti.** Il machine learning può contribuire al rilevamento di malattie delle piante, al rilevamento di erbe infestanti e al rilevamento delle caratteristiche del suolo. Spesso questi compiti hanno requisiti hardware minimi, poiché possono essere utilizzati dispositivi come droni (UAV - Unmanned Aerial Vehicles) dotati di telecamere iperspettrali.

**Previsione delle rese e pianificazione.** L'AI può guidare la previsione delle rese agricole e persino modelli macroeconomici che aiutano gli agricoltori a prevedere la domanda di colture e decidere cosa piantare all'inizio della stagione.

#### Potenziale di riduzione dell'impatto ambientale

Anche se la letteratura scientifica resta prudente nel quantificare i benefici netti (data la possibilità di effetti rimbalzo), alcuni studi citano potenziali riduzioni molto significative. Come riportato nell'indice della tesi basandosi sulle fonti primarie, le stime parlano di possibili riduzioni del **28% dei costi**, del **22% nell'uso di acqua** e del **35% nel deflusso di azoto** nel suolo.

È importante sottolineare che, a livello globale, l'agricoltura costituisce un'industria da 2,4 trilioni di dollari e c'è già un significativo incentivo economico per aumentare l'efficienza [Rolnick]. Tuttavia, i guadagni di efficienza non si traducono necessariamente in riduzione delle emissioni di gas serra – ad esempio attraverso effetti rimbalzo che aumentano il consumo di prodotti particolarmente intensivi in termini di emissioni. Inoltre, ridurre significativamente le emissioni potrebbe richiedere un cambiamento nei paradigmi agricoli, ad esempio l'adozione diffusa dell'agricoltura rigenerativa, della silvopastura e dell'intercropping arboreo.

#### Remote sensing per la gestione del territorio

Tecniche di ML possono essere utilizzate per supportare i decisori politici e gli agronomi. Ad esempio, il telerilevamento con droni e satelliti potrebbe eseguire il rilevamento del metano e la stima dello stock di carbonio, che potrebbero essere utilizzati per incentivare gli agricoltori a sequestrare più carbonio e ridurre le emissioni [Rolnick]. Le telecamere iperspettrali – che possono registrare diverse centinaia di diverse lunghezze d'onda invece del semplice rosso, verde e blu – forniscono informazioni sull'interazione tra luce e sostanze chimiche individuali. Molti satelliti sono dotati di tali telecamere e possono eseguire, in una certa misura, stime delle emissioni di CO2, CH₄ (metano), H2O e N2O (protossido di azoto).

### 2.4.2 Ottimizzazione della supply chain e economia circolare

Oltre alla produzione primaria, l'AI trova applicazioni cruciali nell'ottimizzazione dei flussi di materiali ed energia lungo l'intera catena del valore – dalla progettazione dei prodotti alla loro distribuzione, uso e fine vita. Questo dominio è particolarmente rilevante per la transizione verso un'economia circolare, dove i materiali vengono continuamente riutilizzati piuttosto che estratti, usati e scartati.

#### Riduzione della sovrapproduzione attraverso demand forecasting

Uno dei problemi più significativi delle supply chain globali contemporanee è la **sovrapproduzione e l'eccessivo accumulo di scorte**, fonte importante di emissioni industriali di gas serra, in particolare per beni deperibili o per beni al dettaglio che rapidamente passano di moda [Rolnick]. 

I dati sono impressionanti: secondo il Council of Supply Chain Management Professionals, l'inventario in eccesso a livello globale nel 2011 ammontava a circa **8 trilioni di dollari** di merci. Questo eccesso può essere in parte dovuto a una stima errata della domanda, poiché la stessa organizzazione ha osservato che le stime di vendita aziendali divergevano dalle vendite effettive in media del 40%.

Il machine learning può contribuire a mitigare questi problemi di sovrapproduzione e/o sovra-stoccaggio migliorando la **previsione della domanda**. Ad esempio, l'industria dell'abbigliamento vende in media solo il 60% della sua merce a prezzo pieno, ma alcuni marchi possono vendere fino all'85% grazie alla produzione just-in-time e a reti di intelligence sofisticate [Rolnick]. 

Man mano che lo shopping online e la produzione just-in-time diventano più diffusi e i siti web offrono più tipi di prodotti rispetto ai negozi fisici, saranno necessarie migliori previsioni della domanda a livello regionale per distribuire efficientemente l'inventario senza lasciare che merci indesiderate percorrano lunghe distanze solo per languire nei magazzini. Tuttavia, gli effetti collaterali negativi possono essere significativi a seconda del tipo di prodotto e delle caratteristiche regionali: la produzione just-in-time e lo shopping online sono spesso responsabili della creazione di mode di prodotti con cicli di vita più brevi, oltre a spedizioni più piccole e veloci di merci (principalmente su strada) che mancano dell'efficienza energetica dell'aggregazione del trasporto merci e di metodi di spedizione più lenti come il trasporto ferroviario.

#### Ottimizzazione delle rotte di spedizione

La logistica contemporanea presenta inefficienze sorprendenti. Come documentato da [Rolnick] nel 2006 almeno due aziende scozzesi di frutti di mare hanno fatto volare centinaia di tonnellate di gamberi dalla Scozia alla Cina e alla Thailandia per la pelatura, per poi riportarli in Scozia per la vendita – perché potevano risparmiare sui costi di manodopera. Questo esempio illustra la complessità delle supply chain globalizzate contemporanee, ovvero i processi organizzativi e le reti di spedizione necessari per portare un prodotto dal produttore al consumatore finale. 

L'AI può contribuire a ridurre le emissioni nelle supply chain prevedendo intelligentemente domanda e offerta, identificando prodotti a minor impatto di carbonio e ottimizzando le rotte di spedizione. Tuttavia, come sottolineano gli autori, **per molte di queste applicazioni affinché riducano effettivamente le emissioni, gli incentivi finanziari delle imprese devono anche allinearsi con la mitigazione dei cambiamenti climatici** attraverso meccanismi di carbon pricing o altri strumenti di policy.

#### Riduzione degli sprechi alimentari

A livello globale, la società perde o spreca **1,3 miliardi di tonnellate metriche di cibo ogni anno**, che si traduce in **un terzo di tutto il cibo prodotto per il consumo umano** [Rolnick]. Nei paesi in via di sviluppo, il 40% degli sprechi alimentari si verifica tra raccolta e lavorazione o vendita al dettaglio, mentre oltre il 40% degli sprechi alimentari nelle nazioni industrializzate si verifica alla fine delle catene di approvvigionamento, nei punti vendita al dettaglio, ristoranti e case dei consumatori.

Questa è un'area dove il machine learning potrebbe avere un impatto particolarmente significativo. Gli stessi algoritmi di previsione della domanda discussi per la sovrapproduzione industriale possono essere applicati alla distribuzione alimentare, riducendo gli sprechi nei supermercati, nei ristoranti e nella ristorazione collettiva.

#### Sistemi di raccomandazione per opzioni a basso impatto climatico

I sistemi di raccomandazione potrebbero potenzialmente indirizzare consumatori e imprese acquirenti verso opzioni più rispettose del clima, purché si possano ottenere informazioni sulle emissioni di gas serra lungo l'intero ciclo di vita di un prodotto [Rolnick]. La sfida qui risiede nel reperire dati utilizzabili su ogni materiale e processo produttivo rilevante, dall'estrazione di metalli fino alla produzione, alla spedizione e all'eventuale uso e smaltimento di un prodotto. Si deve anche convincere le aziende a condividere dati proprietari per aiutare altre imprese a imparare dalle migliori pratiche. Se questi dataset possono essere acquisiti, gli algoritmi ML potrebbero ipoteticamente assistere nell'identificazione delle opzioni più pulite.

#### Economia circolare e tracciamento dei materiali

Un'applicazione emergente particolarmente promettente riguarda il **tracciamento dei materiali per il riciclo e il riuso**. L'economia circolare – dove i materiali vengono mantenuti in uso il più a lungo possibile attraverso riuso, riparazione e riciclo – richiede sistemi di tracciamento sofisticati che permettano di identificare dove si trovano i materiali, qual è la loro qualità residua e come possono essere reintrodotti nei cicli produttivi. 

L'AI può supportare questi sistemi attraverso computer vision per la classificazione automatica dei rifiuti, algoritmi di ottimizzazione per la logistica inversa (il trasporto dei materiali dai punti di raccolta agli impianti di riciclo), e sistemi di tracciamento che seguono i materiali lungo l'intera catena del valore. Come evidenziato da [@Vinuesa2020RoleAI] nella loro analisi dell'impatto dell'AI sugli Obiettivi di Sviluppo Sostenibile, queste applicazioni potrebbero contribuire significativamente al raggiungimento dell'SDG 12 su produzione e consumo responsabili.

### 2.4.3 Una prospettiva d'insieme: la trasversalità dell'AI

Ciò che emerge da questa panoramica di applicazioni settoriali è la **natura trasversale** dell'intelligenza artificiale come strumento per la sostenibilità. Come evidenziato nel framework di Kaack  [2022] discusso nella sezione 2.1, le stesse tecniche di machine learning – previsione di serie temporali, ottimizzazione di sistemi complessi, computer vision per remote sensing – possono essere applicate a domini molto diversi.

Un algoritmo di deep learning per la previsione di serie temporali può essere adattato tanto alla produzione solare quanto alla domanda elettrica, tanto ai flussi di traffico quanto alle rese agricole. Questa portabilità delle tecniche AI spiega perché vediamo emergere applicazioni in settori apparentemente distanti: l'architettura informazionale dell'ottimizzazione è simile, anche se i dettagli fisici dei sistemi sono molto diversi.

Dal punto di vista della teoria della modernizzazione ecologica, queste applicazioni settoriali incarnano particolarmente bene il concetto di **razionalità ecologica attraverso l'efficienza informazionale**. In ciascun caso – agricoltura, supply chain, logistica – l'AI permette di ridurre l'uso di risorse (acqua, fertilizzanti, energia per il trasporto, materiali sprecati) attraverso una gestione più fine-grained e adattiva dei processi. L'informazione sostituisce il materiale: invece di applicare fertilizzanti uniformemente su tutto il campo, li applico solo dove servono; invece di produrre merci in eccesso "per sicurezza", produco esattamente quanto prevede la domanda; invece di buttare cibo perché non so quando scadrà, ottimizzare la rotazione degli stock.

Tuttavia, come sottolineato ripetutamente in letteratura, questi guadagni potenziali dipendono fortemente dal contesto istituzionale ed economico. Se gli incentivi di mercato non sono allineati con gli obiettivi ambientali – ad esempio, se il trasporto è così economico che conviene far volare i gamberi dall'altra parte del mondo – l'ottimizzazione guidata dall'AI può persino peggiorare il problema invece di risolverlo. E come vedremo nel Capitolo 3, c'è il rischio concreto che i guadagni di efficienza si traducano in aumenti del consumo totale attraverso il paradosso di Jevons.

Inoltre, è importante riconoscere che queste applicazioni sono ancora **emergenti** piuttosto che mature. A differenza delle smart grid o dei sistemi di previsione meteorologica, dove abbiamo deployment operativi su larga scala e dati empirici sugli impatti, molte applicazioni in agricoltura di precisione ed economia circolare sono ancora in fase pilota o limitata a contesti specifici. La letteratura parla spesso di "potenziale" e "promesse" piuttosto che di risultati consolidati. Sarà necessaria ricerca ulteriore per quantificare con precisione i benefici netti, tenendo conto degli effetti sistemici e dei possibili trade-off.

## 2.5 La prospettiva della modernizzazione ecologica: interpretazione

Le applicazioni documentate nelle sezioni precedenti incarnano diversi concetti chiave della teoria della modernizzazione ecologica informazionale [@Mol2008].

**Razionalità ecologica attraverso informazione.** L'AI permette di rendere "visibile l'invisibile": emissioni che prima sfuggivano al monitoraggio diventano tracciabili in tempo reale (smart grid), foreste remote vengono monitorate satellitarmente, alluvioni in bacini non strumentati diventano prevedibili. Questa capacità di generare, elaborare e utilizzare informazione ambientale su scala senza precedenti rappresenta l'essenza della governance informazionale teorizzata da Mol: la razionalità ecologica mediata dai dati.

**Efficienza e ottimizzazione.** Le applicazioni in smart grid, previsioni meteorologiche e agricoltura di precisione promettono guadagni di efficienza sostanziali: meno energia sprecata nella trasmissione, meno acqua e fertilizzanti utilizzati, maggiore accuratezza nelle previsioni che riduce danni da disastri. Questo allineamento tra efficienza economica ed ecologica è precisamente ciò che la EMT identifica come motore del cambiamento: la sostenibilità diventa razionalità economica.

**Governance multi-attore.** Lo sviluppo e il deployment di queste tecnologie coinvolgono aziende tech (Google, DeepMind, Huawei), istituzioni pubbliche (agenzie meteorologiche, ministeri dell'ambiente), ONG (Global Forest Watch), e partnership pubblico-private. Questo ecosistema multi-attore riflette il modello di governance della EMT, dove il cambiamento non è imposto top-down dallo Stato ma emerge da coordinamento tra attori diversi.

**Limiti e condizioni di efficacia.** Tuttavia, le evidenze empiriche rivelano anche limiti significativi. Come riconoscono [@Kaack2022], le applicazioni climate-positive rappresentano una **frazione minuscola** dell'uso totale dell'AI - la maggior parte del computing è dedicata a pubblicità, raccomandazioni, social media. Inoltre, l'efficacia di queste applicazioni dipende fortemente dal contesto istituzionale: smart grid funzionano solo se i sistemi di incentivazione allineano interessi economici e ambientali; il monitoraggio della deforestazione è inutile senza enforcement legale; l'agricoltura di precisione può ridurre input ma anche intensificare la monocoltura se non regolata.

La domanda critica che emerge non è quindi "l'AI può aiutare la transizione ecologica?" (la risposta è chiaramente sì, in linea di principio) ma piuttosto: **sotto quali condizioni istituzionali, economiche e politiche queste potenzialità si realizzano effettivamente?** E, crucialmente, **a quale costo ambientale complessivo?** Quest'ultima domanda ci porta al Capitolo 3.

## 2.6 Sintesi del capitolo

Le applicazioni documentate incarnano la promessa della modernizzazione ecologica informazionale: razionalità ecologica attraverso dati, efficienza e governance multi-attore. Tuttavia, queste applicazioni climate-positive rappresentano una frazione minuscola dell'uso totale dell'AI [@Kaack2022], e la loro efficacia dipende da condizioni istituzionali ed economiche specifiche. La domanda che emerge è: a quale costo ambientale complessivo?

# CAPITOLO 3 - L'IMPRONTA ECOLOGICA DELL'INTELLIGENZA ARTIFICIALE: COSTI NASCOSTI E CONTRADDIZIONI

## 3.1 Introduzione: il lato oscuro dell'AI

Questo capitolo esamina l'intelligenza artificiale non come *soluzione* alla crisi climatica, ma come *parte del problema* – un'infrastruttura tecnologica con un'impronta ecologica significativa e in rapida crescita.

### 3.1.1 La materialità nascosta dell'"immateriale"

La metafora della "nuvola" (*cloud*) per descrivere l'infrastruttura computazionale dell'AI è profondamente fuorviante. Come documenta [@Crawford2021] in *The Atlas of AI*, ciò che appare come eterea computazione digitale è in realtà radicato in catene materiali estremamente concrete: miniere di litio nel deserto di Atacama, estrazione di terre rare in Mongolia, data center che consumano milioni di litri d'acqua, cavi sottomarini che attraversano gli oceani, server raffreddati 24 ore su 24, chip semiconduttori prodotti in impianti che richiedono acqua ultrapura.

L'AI non è immateriale: è profondamente *terrestre*. Ogni query a ChatGPT, ogni raccomandazione di Netflix,  ogni predizione di un modello climatico richiede elettricità generata da qualche parte, hardware costruito con minerali estratti da qualche parte, calore dissipato attraverso sistemi di raffreddamento che consumano risorse. La "leggerezza" dell'interfaccia utente nasconde il peso dell'infrastruttura sottostante.

Questa materialità nascosta ha conseguenze ambientali che devono essere analizzate sistematicamente per comprendere il paradosso dell'AI: una tecnologia che promette di essere lo strumento della transizione ecologica, ma la cui crescita esponenziale sta generando pressioni ambientali sempre più significative. Come vedremo nelle sezioni seguenti, queste pressioni si manifestano lungo molteplici dimensioni: energia, acqua, materiali, rifiuti elettronici – ciascuna con le proprie implicazioni per la giustizia ambientale e per la sostenibilità dei sistemi socio-tecnici contemporanei.

## 3.2 Il consumo energetico dell'AI

### 3.2.1 L'energia per l'addestramento dei modelli

Il processo di addestramento di modelli di machine learning – in particolare dei grandi modelli di linguaggio (*Large Language Models*, LLM) e dei sistemi di deep learning – richiede quantità straordinarie di energia computazionale. Come ha documentato il pionieristico studio di [@Strubell2019], l'addestr amento di un singolo grande modello di elaborazione del linguaggio naturale può generare emissioni di CO2 equivalenti a quelle prodotte da **cinque automobili durante l'intero ciclo di vita** – dalla produzione allo smaltimento.

I dati empirici sono impressionanti. [@Strubell2019] hanno calcolato che l'addestramento di un modello transformer con ricerca dell'architettura neurale (*neural architecture search*) emette circa **284.000 kg di CO2e** (CO2 equivalente). Per contestualizzare: questo corrisponde alle emissioni di 125 voli andata-ritorno tra New York e San Francisco, o al consumo energetico di una famiglia americana media per 57 anni. Anche modelli più piccoli generano impronte significative: un singolo modello BERT base emette circa 652 kg di CO2e, equivalente a un volo transatlantico [@Strubell2019].

**GPT-3: un caso di studio emblematico.** Il modello GPT-3 di OpenAI, alla base di ChatGPT, rappresenta un esempio particolarmente illuminante dell'intensità energetica dell'AI contemporanea. Secondo le stime riportate da [@Patterson2021] e [@Li2023], l'addestramento di GPT-3 ha consumato **1.287 MWh** (megawattora) di elettricità e generato circa **552 tonnellate di CO2e**. Per dare un ordine di grandezza: 1.287 MWh potrebbero alimentare circa 120 abitazioni americane medie per un anno intero [@Patterson2021].

È cruciale sottolineare che questi calcoli si riferiscono a un *singolo* ciclo di addestramento. Nella pratica dello sviluppo di modelli AI, i ricercatori raramente addestrano un modello una volta sola. Il processo tipico coinvolge:

1. **Sperimentazione con iperparametri**: testare decine o centinaia di configurazioni diverse per trovare quella ottimale
2. **Ablation studies**: addestrare versioni ridotte del modello per comprendere il contributo di diverse componenti
3. **Ri-addestramento**: quando arrivano nuovi dati o si correggono errori nel dataset
4. **Modelli ensemble**: addestrare multipli modelli per poi combinare le loro predizioni

[@Strubell2019] hanno documentato che il costo computazionale effettivo di sviluppare un modello NLP all'avanguardia può essere **78.000 volte superiore** al costo di un singolo addestramento, una volta inclusi tutti gli esperimenti di tuning. Questo significa che l'impronta di carbonio totale del processo di ricerca e sviluppo può raggiungere dimensioni astronomiche.

**La crescita esponenziale del compute.** Un trend particolarmente preoccupante riguarda la crescita esponenziale della potenza computazionale (*compute*) utilizzata per addestrare modelli AI. Come documentano [@Patterson2021], la quantità di compute necessaria per i modelli all'avanguardia è cresciuta di un fattore **10 ogni anno** dal 2012 al 2021. Questa crescita segue una curva esponenziale molto più ripida della Legge di Moore (che prevedeva un raddoppio ogni due anni).

Ciò che sta emergendo nella comunità del machine learning è quella che [@Schwartz2020] chiamano la cultura del **"compute maximalism"** o "Red AI": l'idea che modelli più grandi, addestrati con più dati e più compute, siano sempre migliori. Questa cultura privilegia l'accuratezza e le prestazioni a scapito dell'efficienza energetica. [@Schwartz2020] hanno analizzato gli articoli pubblicati nelle principali conferenze di machine learning e hanno trovato che circa il **90% degli articoli** riporta solo metriche di accuratezza, ignorando completamente il costo computazionale e l'impronta energetica dei metodi proposti.

Questo rappresenta un'inversione delle priorità rispetto al trend storico dell'informatica, dove l'efficienza – fare di più con meno – era considerata un valore fondamentale. Nel contesto dell'AI contemporanea, invece, prevale la logica opposta: fare di più richiede necessariamente *più* risorse, e questo viene accettato come inevitabile piuttosto che come un problema da risolvere [@Schwartz2020].

### 3.2.2 Il consumo energetico per l'inferenza (uso dei modelli)

Se l'addestramento dei modelli AI genera titoli allarmanti per la sua intensità energetica, è l'*inferenza* – l'uso quotidiano dei modelli già addestrati – a rappresentare la quota maggiore del consumo energetico totale dell'intelligenza artificiale. Come osserva [@deVries2023], mentre l'addestramento è un evento unico (o quantomeno occasionale) che genera picchi di consumo, l'inferenza è un processo continuo che avviene ogni volta che un utente interagisce con un sistema AI.

**Il predominio dell'inferenza nel bilancio energetico.** Secondo le stime riportate da [@deVries2023], l'inferenza rappresenta tra l'**80% e il 90%** del computing AI totale in termini di energia consumata. Questo perché, sebbene una singola query richieda ordini di grandezza meno energia di un addestramento completo, il numero di query è astronomico: milioni di utenti che interrogano quotidianamente ChatGPT, Alexa, Google Assistant, sistemi di raccomandazione, filtri antispam, riconoscimento facciale su smartphone.

Per contestualizzare: [@Li2023] stimano che una singola conversazione con ChatGPT (circa 10-50 query) consumi tra **0.01 e 0.05 kWh** di elettricità – una quantità relativamente piccola. Ma se moltiplichiamo questo per i 100 milioni di utenti attivi mensili che ChatGPT ha raggiunto nei primi mesi dopo il lancio, e consideriamo che ciascun utente fa multiple query giornaliere, arriviamo a consumi complessivi enormi. Secondo le proiezioni di [@deVries2023], se Google integrasse l'AI generativa in tutte le sue ricerche (attualmente circa 9 miliardi al giorno), il consumo energetico aggiuntivo sarebbe paragonabile al consumo annuale di interi paesi come l'Irlanda.

**Le proiezioni dell'International Energy Agency.** Nel report "Electricity 2024: Analysis and Forecast to 2026", l'International Energy Agency [@IEA2024] ha documentato come l'esplosione dell'AI stia contribuendo a un'impennata senza precedenti nel consumo elettrico dei data center a livello globale. Le proiezioni indicano che il consumo elettrico dei data center **raddoppierà entro il 2026**, raggiungendo circa **945 TWh** (terawattora) annui – equivalente al consumo elettrico combinato di Giappone e Germania [@IEA2024].

Non tutto questo aumento è attribuibile all'AI – anche il mining di criptovalute e l'espansione generale dei servizi cloud contribuiscono – ma l'AI rappresenta il fattore di crescita più rapido. Come riporta [@Kaack2022], le grandi aziende tech come Google e Microsoft hanno registrato aumenti del **20-34% anno-su-anno** nel consumo energetico dei loro data center dal 2018 al 2022, con l'AI identificata come il principale driver di questa crescita.

**Query apparentemente innocue, impatto cumulativo significativo.** Un aspetto particolarmente insidioso del consumo energetico da inferenza è la sua invisibilità per l'utente finale. Quando facciamo una domanda a ChatGPT o chiediamo a Siri di impostare una sveglia, non percepiamo alcun costo energetico – l'interazione appare istantanea e immateriale. Eppure, dietro ogni query si attivano server che processano miliardi di parametri, sistemi di raffreddamento che dissipano il calore generato, reti che trasmettono dati.

Secondo i calcoli di [@Li2023], ogni interazione con GPT-3 consuma tra **0.01 e 0.05 kWh** di elettricità a seconda della complessità della query. Moltiplicato per decine o centinaia di milioni di query giornaliere, questo si traduce in un'impronta energetica paragonabile a quella di intere città. E con l'integrazione sempre più pervasiva dell'AI in applicazioni quotidiane – dalle e-mail che si scrivono automaticamente ai filtri fotografici, dalle traduzioni istantanee ai suggerimenti di acquisto personalizzati – questo consumo "di sottofondo" è destinato a crescere esponenzialmente.

### 3.2.3 Data center e infrastruttura computazionale

**La spina dorsale energivora dell'AI.** I data center – le enormi strutture che ospitano i server su cui girano i modelli AI – rappresentano già oggi tra l'**1% e il 2% del consumo elettrico globale** [@Kaack2022; @IEA2024]. Questa percentuale può sembrare piccola, ma in termini assoluti corrisponde a centinaia di terawattora all'anno, più dell'intero consumo elettrico di molti paesi. E la quota è in rapida crescita.

Come documentato da [@IEA2024], l'espansione dell'AI sta mettendo sotto pressione le reti elettriche nazionali in modi senza precedenti. In alcune regioni degli Stati Uniti – in particolare Virginia, Oregon e Iowa, dove si concentrano i maggiori data center – le utilities elettriche stanno lottando per soddisfare la domanda crescente. Questo crea un paradosso perverso: mentre le società tech dichiarano impegni verso il 100% di energia rinnovabile, l'esplosione della domanda richiede la costruzione di nuova capacità elettrica che, almeno nel breve termine, viene spesso soddisfatta con centrali a gas naturale per la loro maggiore flessibilità e rapidità di costruzione rispetto alle rinnovabili [@Kaack2022].

**Il caso Google e Microsoft: crescita insostenibile.** I report di sostenibilità delle grandi tech company forniscono evidenza diretta di questa dinamica. Google, che aveva raggiunto l'obiettivo di operare al 100% con energia rinnovabile su base annuale, ha visto le sue **emissioni totali aumentare del 48% tra il 2019 e il 2022**, con l'espansione dell'AI identificata come principale causa [@Li2023]. Microsoft ha registrato un aumento ancora più marcato: **+34% di emissioni tra il 2020 e il 2022**, nonostante gli impegni pubblici verso la carbon neutrality entro il 2030 [@Li2023].

Questi dati rivelano un problema strutturale: anche quando i data center sono alimentati da energia rinnovabile *sulla carta* (attraverso l'acquisto di crediti di energia rinnovabile o Power Purchase Agreements), la crescita della domanda è così rapida che richiede l'espansione della capacità di generazione complessiva. E poiché le rinnovabili come solare ed eolico sono intermittenti e richiedono anni per essere costruite su larga scala, nel breve-medio termine questa domanda aggiuntiva viene inevitabilmente soddisfatta con fonti fossili, vanificando parzialmente gli sforzi di decarbonizzazione [@Kaack2022].

**Pressione sulle reti elettriche locali.** Un aspetto spesso trascurato riguarda l'impatto locale dei data center sulle comunità che li ospitano. Come documenta [@Crawford2021], la costruzione di grandi data center – che possono richiedere decine o centinaia di megawatt di potenza continua – crea tensioni significative con le reti elettriche locali. In alcune aree rurali degli Stati Uniti, un singolo data center può consumare più elettricità dell'intera città circostante, causando aumenti nelle tariffe elettriche per i residenti e ritardi nell'elettrificazione di altre infrastrutture [@Crawford2021].

Inoltre, i data center richiedono alimentazione elettrica estremamente affidabile – anche pochi minuti di blackout possono causare perdite di dati e interruzioni di servizio costose. Questo significa che le utilities devono mantenere capacità di riserva significative specificamente per servire i data center, riducendo l'efficienza complessiva del sistema elettrico e aumentando i costi per tutti gli utenti [@Kaack2022].

La prossima sezione esamina un impatto ambientale dell'AI ancora meno visibile ma altrettanto preoccupante: il consumo di acqua dolce per il raffreddamento dei data center.

## 3.3 Il consumo d'acqua: la "sete" dell'AI

### 3.3.1 Acqua per il raffreddamento dei data center

Mentre il dibattito pubblico sull'impronta ambientale dell'AI si è concentrato principalmente sulle emissioni di carbonio, un impatto altrettanto significativo ma molto meno discusso riguarda il **consumo di acqua dolce**. Come documentano [@Li2023] nel loro studio pionieristico "Making AI Less 'Thirsty'", l'addestramento e l'uso di modelli AI su larga scala richiedono quantità impressionanti di acqua per raffreddare i server dei data center.

**GPT-3: 700.000 litri di acqua evaporata.** Applicando la metodologia di lifecycle assessment ai data center di Microsoft dove è stato addestrato GPT-3, [@Li2023] hanno stimato che l'addestramento di questo singolo modello abbia consumato circa **700.000 litri di acqua dolce** direttamente evaporata nei sistemi di raffreddamento. Per contestualizzare: questa quantità basterebbe a produrre circa 370 automobili o 320 tonnellate di acciaio [@Li2023].

E questo calcolo si riferisce solo al consumo diretto (*scope 1*) – l'acqua effettivamente evaporata nelle torri di raffreddamento del data center. Se includiamo il consumo indiretto (*scope 2*) – l'acqua utilizzata nelle centrali elettriche per generare l'elettricità che alimenta il data center – i numeri diventano molto più grandi. [@Li2023] stimano che il consumo totale di acqua per addestrare GPT-3, includendo sia scope 1 che scope 2, varia tra **4 e 5,4 milioni di litri** a seconda della localizzazione del data center e del mix energetico regionale.

**Come funzionano i sistemi di raffreddamento.** Per comprendere perché l'AI è così "assetata", dobbiamo capire come funzionano i data center. I server che eseguono computazioni AI generano enormi quantità di calore – quasi tutta l'energia elettrica consumata viene convertita in calore che deve essere dissipato per evitare il surriscaldamento delle componenti. Esistono due principali sistemi di raffreddamento [@Li2023]:

1. **Torri di raffreddamento (*cooling towers*)**: usano un circuito aperto dove l'acqua assorbe il calore dai server e poi viene raffreddata in una torre attraverso l'evaporazione. Lungo questo processo, parte dell'acqua evapora e viene "consumata" (ossia non può essere recuperata). In media, i data center che usano torri di raffreddamento evaporano circa **1-9 litri di acqua per ogni kWh** di energia dei server, con una media globale di circa 1,8 L/kWh per Google e 9 L/kWh per grandi data center commerciali in Arizona durante l'estate [@Li2023].

2. **Raffreddamento ad aria esterna (*outside air cooling*)**: quando le condizioni climatiche lo permettono, alcuni data center usano direttamente aria esterna per raffreddare i server, evitando o riducendo l'uso di acqua. Tuttavia, questo è possibile solo in climi freschi e secchi, e comunque richiede acqua per il controllo dell'umidità quando l'aria esterna è troppo secca [@Li2023].

**Scale aggregate: miliardi di litri.** A livello aggregato, i numeri diventano astronomici. Google ha riportato di aver **prelevato 25 miliardi di litri di acqua** nel 2022 solo per i suoi data center proprietari – questo esclude i data center in cloud affittati a terzi [@Li2023]. Microsoft ha registrato un aumento del **34% nel consumo d'acqua tra il 2021 e il 2022**, attribuendo questa crescita principalmente all'espansione dell'infrastruttura AI [@Li2023].

Per dare un senso a questi numeri: 25 miliardi di litri potrebbero riempire circa 10.000 piscine olimpioniche, o soddisfare il fabbisogno annuale di acqua potabile di circa 250.000 persone nei paesi sviluppati [@Li2023].

### 3.3.2 Conflitti idrici e giustizia ambientale

Il consumo massiccio di acqua da parte dei data center non è solo una questione di quantità aggregate, ma solleva problemi acuti di **giustizia ambientale** e conflitti territoriali. Come documentano [@Li2023], i data center vengono spesso costruiti in regioni che stanno già affrontando stress idrico, creando tensioni con le comunità locali e compromettendo la sicurezza idrica di popolazioni vulnerabili.

**Il caso Uruguay: proteste popolari contro i data center.** Un esempio emblematico riguarda il progetto di Google per costruire un grande data center in Uruguay, un paese che ha attratto investimenti tech grazie alla disponibilità di energia rinnovabile a basso costo. Quando è emerso che il data center avrebbe consumato milioni di litri d'acqua al giorno in una regione già soggetta a siccità periodiche, le comunità locali hanno organizzato proteste e raccolte firme [@Li2023]. I residenti hanno denunciato che stavano già razionando l'acqua per uso domestico durante i periodi di siccità, mentre un'azienda straniera avrebbe avuto accesso illimitato alla risorsa per operazioni commerciali.

Questo caso rivela una dinamica di potere asimmetrica: le grandi tech companies negoziano accordi direttamente con i governi nazionali, spesso con incentivi fiscali e accesso prioritario alle risorse, mentre le comunità locali che subiscono gli impatti ambientali hanno scarso potere decisionale. Come osserva [@Crawford2021], questa è una manifestazione del colonialismo estrattivista applicato alle risorse digitali: regioni del Sud globale forniscono risorse materiali (acqua, energia, minerali) per sostenere infrastrutture che servono principalmente utenti del Nord globale.

**La crisi idrica globale e la scelta dei siti.** Il problema diventa ancora più grave se consideriamo le proiezioni sulla scarsità idrica futura. Secondo i dati citati da [@Li2023], si stima che circa il **50% della popolazione mondiale vivrà in aree water-scarce entro il 2050**. Eppure, come documenta il loro studio, una quota significativa dei data center esistenti e pianificati si trova già oggi in regioni caratterizzate da stress idrico.

[@Li2023] hanno analizzato la localizzazione dei data center di Microsoft e Google e hanno scoperto che molti sono situati in zone già classificate come *drought-prone* (soggette a siccità). Ad esempio, alcuni dei più grandi data center si trovano in Arizona, una regione desertica dove le città stanno già affrontando deficit idrici cronici e restrizioni all'uso dell'acqua. Altri si trovano in Texas e California, stati che hanno sperimentato siccità prolungate negli ultimi decenni [@Li2023].

La logica che porta a queste scelte di localizzazione apparentemente controintuitive riguarda altri fattori: vicinanza ai mercati, disponibilità di terra a basso costo, incentivi fiscali, connettività di rete, costi energetici. La disponibilità di acqua dolce, pur essendo critica per le operazioni, sembra pesare meno nelle decisioni di investimento [@Crawford2021].

**Scope 2: l'acqua nascosta nella generazione elettrica.** Un aspetto che rende il problema ancora più complesso riguarda il consumo idrico *indiretto*. Come spiegato nella sezione precedente, oltre all'acqua evaporata direttamente nei sistemi di raffreddamento dei data center (*scope 1*), c'è l'acqua consumata nelle centrali termoelettriche che generano l'elettricità per alimentare i data center (*scope 2*).

La generazione termoelettrica – da carbone, gas naturale o nucleare – richiede enormi quantità di acqua per il raffreddamento. Negli Stati Uniti, la media nazionale è di circa **43,8 litri prelevati e 3,1 litri consumati per ogni kWh** generato [@Li2023]. Questo significa che un data center che consuma 100 MWh di elettricità all'ora causa indirettamente il prelievo di circa 4,4 milioni di litri d'acqua nelle centrali elettriche, di cui circa 310.000 litri vengono effettivamente consumati (evaporati o inquinati e non restituibili all'ambiente) [@Li2023].

[@Li2023] sottolineano che le aziende tech tipicamente *non riportano* il consumo di acqua scope 2 nei loro sustainability report, concentrandosi solo sull'acqua usata direttamente nei loro data center. Questo crea una sottostima significativa dell'impronta idrica reale dell'AI. Quando si include lo scope 2, l'impronta idrica totale può essere **3-5 volte superiore** a quella riportata ufficialmente [@Li2023].

**Disuguaglianze globali nell'accesso all'acqua.** Il problema assume una dimensione di giustizia globale quando consideriamo che 2,2 miliardi di persone nel mondo non hanno ancora accesso ad acqua potabile sicura, e che la scarsità idrica è una delle principali cause di conflitti e migrazioni forzate [@Li2023]. In questo contesto, destinare miliardi di litri di acqua dolce per addestrare modelli AI che servono principalmente popolazioni benestanti solleva questioni etiche profonde.

Come osserva [@Luccioni2025] nella loro analisi degli effetti di secondo ordine dell'AI, questa è un'altra manifestazione del pattern generale: i benefici dell'AI (migliore efficienza, nuovi servizi, profitti aziendali) si concentrano in alcune regioni e classi sociali, mentre i costi ambientali (emissioni, consumo d'acqua, estrazione di minerali) ricadono sproporzionatamente su comunità vulnerabili e paesi del Sud globale.

## 3.4 Materiali e rifiuti elettronici

### 3.4.1 Estrazione di terre rare e minerali critici

L'infrastruttura fisica dell'intelligenza artificiale – GPU, TPU, server, sistemi di storage, reti di trasmissione – richiede una vasta gamma di **minerali critici e terre rare** la cui estrazione genera impatti ambientali e sociali devastanti. Come documenta [@Crawford2021] in *The Atlas of AI*, ogni componente dell'hardware AI nasconde una lunga catena di estrazione che attraversa il pianeta, dalle miniere di litio nel deserto di Atacama alle raffinerie di terre rare in Mongolia, dalle miniere di cobalto nella Repubblica Democratica del Congo agli impianti di produzione di semiconduttori a Taiwan.

**I materiali critici per l'AI.** Le GPU (Graphics Processing Units) e le TPU (Tensor Processing Units) – i chip specializzati che eseguono le computazioni di machine learning – richiedono una combinazione complessa di materiali [@Crawford2021; @Luccioni2025]:

- **Terre rare**: neodimio, disprosio, terbio, cerio, ittrio, gadolinio – usati per le loro proprietà magnetiche ed elettroniche uniche
- **Metalli di transizione**: litio, cobalto, nichel – per batterie di backup e sistemi di alimentazione
- **Semiconduttori**: silicio ultrapuro, gallio, germanio, arseniuro di gallio – per i chip
- **Metalli preziosi**: oro, argento, platino, palladio – per connessioni e conduttori
- **Altri metalli critici**: tungsteno, tantalio (coltan), indio, stagno – per condensatori e altri componenti

La produzione di questi materiali è altamente concentrata geograficamente. Come riporta [@Crawford2021], la **Cina controlla circa il 95% della produzione mondiale di terre rare**, non tanto per ragioni geologiche – questi minerali sono relativamente abbondanti nella crosta terrestre – quanto per la disponibilità del paese ad accettare i devastanti costi ambientali della loro estrazione e raffinazione.

**Baotou: il lago tossico della modernità digitale.** [@Crawford2021] descrive in dettaglio il caso di Baotou, in Mongolia Interna, sede del più grande deposito di terre rare del pianeta. Il processo di estrazione e raffinazione delle terre rare richiede l'uso massiccio di acidi solforici e nitrici per dissolvere i minerali dalla roccia. Secondo la Chinese Society of Rare Earths citata da [@Crawford2021], la raffinazione di una singola tonnellata di terre rare produce **75.000 litri di acque acide reflue e una tonnellata di residui radioattivi**.

Questi rifiuti tossici si accumulano in un enorme lago artificiale vicino a Baotou – un bacino di contenimento dove vengono scaricati i residui dell'industria mineraria. [@Crawford2021] descrive questo lago come "riempito con quello che la studiosa ambientale Myra Hird chiama 'i rifiuti che vogliamo dimenticare'" – una discarica di sostanze tossiche e radioattive che rappresenta il costo nascosto e invisibile della nostra economia digitale.

Il rapporto tra materiale utile e scarto è estremo. [@Crawford2021] riporta che nell'estrazione di disprosio e terbio nella provincia di Jiangxi, solo lo **0,2% dell'argilla estratta** contiene effettivamente elementi di terre rare utilizzabili. Questo significa che il **99,8% del materiale rimosso** viene scartato come rifiuto (*tailings*), scaricato nelle colline e nei corsi d'acqua, creando nuovi inquinanti come ammonio e compromettendo gli ecosistemi locali.

**Geopolitica dell'estrazione e territori indigeni.** Come documentano [@Luccioni2025], i minerali critici vengono estratti in modo sproporzionato da territori indigeni e da zone già soggette a stress ambientale. Il loro studio evidenzia che circa il **54% dei materiali critici** utilizzati nell'industria tech globale proviene da territori indigeni, spesso senza il consenso informato delle comunità locali e con impatti devastanti sui loro modi di vita tradizionali [@Luccioni2025].

Inoltre, il **62% dell'estrazione di minerali critici** avviene in zone classificate come *drought-prone* (soggette a siccità) [@Luccioni2025]. Questo crea un doppio problema: l'estrazione mineraria richiede grandi quantità di acqua per il processing, competendo con le necessità delle comunità locali e dell'agricoltura; e la contaminazione delle falde acquifere riduce ulteriormente la disponibilità di acqua potabile in regioni già idricamente vulnerabili.

### 3.4.2 E-waste e ciclo di vita dell'hardware

Oltre agli impatti dell'estrazione mineraria, l'infrastruttura AI genera un flusso crescente di **rifiuti elettronici** (*e-waste*) dovuto ai cicli di aggiornamento sempre più rapidi dell'hardware e all'obsolescenza programmata dei componenti. Come documentano [@Crawford2021] e [@Luccioni2025], i rifiuti elettronici rappresentano la frazione di rifiuti solidi in più rapida crescita a livello globale, con implicazioni ambientali e sanitarie gravi.

**La scala del problema e-waste.** Secondo i dati citati da [@Luccioni2025], nel 2022 sono stati generati circa **62 milioni di tonnellate (Mt)** di rifiuti elettronici a livello globale. Di questi, solo circa il **22% viene formalmente raccolto e riciclato** attraverso sistemi certificati. Il restante 78% finisce in discariche, viene incenerito, o – nel peggiore dei casi – viene esportato illegalmente verso paesi del Sud globale dove viene smaltito in modo informale con tecniche pericolose per la salute umana e l'ambiente [@Luccioni2025].

L'industria AI contribuisce a questo flusso in modi specifici e accelerati. Le GPU e le TPU utilizzate per il machine learning hanno cicli di vita molto più brevi rispetto all'hardware consumer standard. Come osserva [@Crawford2021], mentre un computer personale può rimanere funzionale per 5-10 anni, l'hardware specializzato per l'AI viene spesso sostituito ogni **2-3 anni** o anche più frequentemente per rimanere al passo con le esigenze computazionali dei modelli sempre più grandi.

**La corsa all'hardware e l'obsolescenza accelerata.** Questa dinamica è guidata da quella che [@Luccioni2025] chiamano la "corsa agli armamenti computazionali". Ogni nuova generazione di modelli AI richiede hardware più potente: più memoria, maggiore larghezza di banda, capacità di calcolo parallelo più elevate. Le aziende sono quindi costrette ad aggiornare costantemente i loro data center per rimanere competitive, generando montagne di hardware "obsoleto" che tecnicamente funziona ancora ma non è più abbastanza performante per i carichi di lavoro contemporanei.

Questo crea un paradosso particolarmente evidente: mentre l'AI viene presentata come strumento per l'economia circolare e l'ottimizzazione delle risorse (come discusso nella sezione 2.4), l'infrastruttura stessa dell'AI segue una logica profondamente lineare e estrattivista – estrai, produci, usa brevemente, scarta – che è l'antitesi dei principi dell'economia circolare [@Crawford2021].

**Tossicità e rischi sanitari.** I componenti elettronici contengono una miscela complessa di materiali, molti dei quali tossici. Come documenta [@Crawford2021], quando i rifiuti elettronici vengono smaltiti in modo improprio – bruciati a cielo aperto per recuperare i metalli preziosi, o scaricati in discariche dove i composti chimici filtrano nel terreno e nelle falde acquifere – rilasciano sostanze pericolose:

- **Metalli pesanti**: piombo, mercurio, cadmio, cromo esavalente – neurotossici e cancerogeni
- **Ritardanti di fiamma**: composti bromati e clorurati – interferenti endocrini e persistenti nell'ambiente
- **Plastiche**: quando bruciate, rilasciano diossine e furani – tra le sostanze più tossiche conosciute
- **Acidi e solventi**: usati nel processing, contaminano suolo e acqua

[@Crawford2021] descrive le comunità del Sud globale – in particolare in Ghana, Nigeria, India, Pakistan, Cina – dove i rifiuti elettronici del Nord vengono "riciclati" informalmente. Bambini e adulti bruciano circuiti stampati per estrarre rame e oro, respirando fumi tossici; immergono componenti in bagni acidi per recuperare metalli preziosi, senza protezioni adeguate. Studi sanitari in queste aree hanno documentato livelli allarmanti di piombo nel sangue, danni neurologici, malattie respiratorie e tassi elevati di cancro [@Crawford2021].

**Il "commercio tossico" globale.** Anche se esistono convenzioni internazionali – come la Convenzione di Basilea che dovrebbe limitare il trasferimento di rifiuti pericolosi dai paesi sviluppati a quelli in via di sviluppo – [@Crawford2021] documenta come enormi quantità di e-waste continuino a fluire dal Nord al Sud globale attraverso canali legali e illegali. 

I rifiuti elettronici vengono spesso esportati con l'etichetta di "equipaggiamento usato" o "donazioni per il riuso", aggirando le restrizioni. Una volta arrivati a destinazione, gran parte di questo materiale risulta non funzionante o non riparabile e finisce smaltito in modo informale [@Crawford2021]. Questo rappresenta un trasferimento di costi ambientali e sanitari: i paesi ricchi godono dei benefici dell'innovazione tecnologica accelerata, mentre i paesi poveri subiscono i costi dello smaltimento dei rifiuti tossici.

**Limiti strutturali del riciclo.** Anche quando l'e-waste viene riciclato formalmente, il processo è tutt'altro che perfetto. [@Luccioni2025] sottolineano che il tasso del 22% di riciclo formale nasconde il fatto che molti materiali non vengono effettivamente recuperati. Il riciclo di componenti elettronici è tecnicamente complesso e costoso: richiede processi di separazione sofisticati per estrarre i diversi metalli dalla matrice composita dei circuiti stampati.

Alcuni materiali – come le terre rare – sono particolarmente difficili da recuperare. [@Crawford2021] osserva che il costo economico ed energetico di riciclare terre rare da vecchi dispositivi è spesso superiore al costo di estrarre minerale vergine, creando un disincentivo economico al riciclo. Il risultato è che, nonostante la retorica dell'economia circolare, la maggior parte delle terre rare utilizzate nell'elettronica vengono estratte ex novo e poi perse quando i dispositivi diventano rifiuti.

**Verso una prospettiva di lifecycle completo.** Questi dati evidenziano la necessità di valutare l'impatto ambientale dell'AI attraverso un'analisi completa del ciclo di vita (*lifecycle assessment*), che includa:
- L'estrazione e raffinazione dei minerali
- La produzione dei componenti (chip, server, storage)
- Il trasporto e l'assemblaggio
- L'uso operativo (energia, acqua, raffreddamento)
- Lo smaltimento a fine vita

Come argomenteranno [@Luccioni2025] nella loro analisi del paradosso di Jevons applicato all'AI, concentrarsi solo sull'efficienza energetica operativa – pur importante – rischia di oscurare questi impatti "upstream" (estrazione, produzione) e "downstream" (smaltimento) che sono ugualmente significativi dal punto di vista ambientale e di giustizia sociale.

La prossima sezione integra questi diversi impatti materiali ed energetici attraverso la lente teorica del paradosso di Jevons, mostrando come i guadagni di efficienza nell'AI possano paradossalmente portare a un aumento del consumo totale di risorse.

## 3.5 Il paradosso di Jevons applicato all'AI

### 3.5.1 Cos'è il paradosso di Jevons

Il **paradosso di Jevons**, o effetto rimbalzo (*rebound effect*), rappresenta una delle critiche empiriche più potenti alla fiducia ingenua nell'efficienza tecnologica come soluzione ai problemi ambientali. Come discusso nel Capitolo 1 (sezione 1.2.3), questo fenomeno – identificato dall'economista britannico William Stanley Jevons nel XIX secolo nel contesto delle macchine a vapore – descrive come i guadagni di efficienza possano paradossalmente portare a un *aumento* anziché a una diminuzione del consumo totale di risorse.

Il meccanismo è apparentemente controintuitivo ma empiricamente ben documentato: quando una tecnologia diventa più efficiente, i suoi costi d'uso diminuiscono, rendendone l'utilizzo più economico e accessibile. Questo stimola un maggiore utilizzo della tecnologia stessa, l'espansione delle sue applicazioni, e talvolta la crescita economica complessiva che aumenta la domanda di risorse a livello sistemico. Il risultato netto può essere un *aumento* del consumo totale, nonostante i guadagni di efficienza per unità di output [@Luccioni2025].

Come ricordato nel Capitolo 1, [@Luccioni2025] identificano tre tipi di effetti rimbalzo:

1. **Effetto rimbalzo diretto**: l'efficienza riduce il costo d'uso, stimolando maggiore utilizzo della stessa tecnologia (es: automobili più efficienti → si guida di più)

2. **Effetto rimbalzo indiretto**: il risparmio economico viene speso per altri beni/servizi ad alta intensità di risorse (es: risparmi sul carburante → volo aereo)

3. **Effetto rimbalzo sistemico**: l'efficienza stimola crescita economica complessiva, aumentando la domanda totale di risorse (es: interi settori economici si espandono grazie alle nuove tecnologie efficienti)

L'applicazione di questo framework all'intelligenza artificiale, come dimostrano [@Luccioni2025] nel loro recente studio, rivela dinamiche preoccupanti che minano le narrative ottimistiche sulla sostenibilità dell'AI.

### 3.5.2 L'effetto rimbalzo nell'AI

L'intelligenza artificiale manifesta tutti e tre i tipi di effetto rimbalzo identificati da [@Luccioni2025], in modi che sono allo stesso tempo tecnicamente sofisticati e strutturalmente prevedibili. La loro analisi dimostra come i guadagni di efficienza computazionale – spesso celebrati come "Green AI" – possano paradossalmente accelerare la crescita complessiva dell'impronta ambientale del settore.

**Effetti rimbalzo diretti: modelli più grandi, training più frequente.** Il primo e più evidente effetto rimbalzo nell'AI riguarda il rapporto tra efficienza e scala dei modelli. Come documentano [@Luccioni2025], ogni volta che viene sviluppata una tecnica che rende l'addestramento più efficiente – algoritmi migliori, hardware specializzato, ottimizzazioni software – questa efficienza non si traduce in una riduzione del consumo totale, ma piuttosto viene "reinvestita" in modelli ancora più grandi e computazionalmente intensivi.

Ad esempio, quando [@Patterson2021] hanno dimostrato che modelli *sparse* (con attivazione parziale dei parametri) possono consumare meno di 1/10 dell'energia di modelli densi equivalenti mantenendo prestazioni simili, la risposta del settore non è stata "usiamo meno energia mantenendo modelli della stessa dimensione", ma piuttosto "costruiamo modelli 10 volte più grandi allo stesso costo energetico". Il risultato: il consumo energetico rimane costante o aumenta, mentre la complessità e la capacità computazionale crescono esponenzialmente [@Luccioni2025].

[@Luccioni2025] documentano che il numero di parametri nei modelli all'avanguardia è cresciuto di oltre **10.000 volte** tra il 2018 e il 2023 (da BERT con 340 milioni di parametri a GPT-4 con centinaia di miliardi). Questa crescita è stata resa possibile proprio dai guadagni di efficienza hardware e algoritmica, che hanno abbassato la "barriera all'ingresso" per addestrare modelli giganteschi.

Inoltre, i modelli più efficienti rendono economicamente sostenibile un addestramento più frequente. Invece di addestrare un modello una volta e usarlo per anni, le aziende ora ri-addestrano continuamente i modelli su dati aggiornati, eseguono esperimenti multipli, creano varianti specializzate per diversi task. [@Luccioni2025] citano il caso di DeepSeek-R1, un modello che richiede ri-addestramento frequente per mantenere le prestazioni, moltiplicando l'impronta energetica totale nonostante l'efficienza per singola iterazione.

**Effetti rimbalzo indiretti: democratizzazione e proliferazione.** Il secondo tipo di effetto rimbalzo opera attraverso l'espansione dell'accesso. Come osservano [@Luccioni2025], quando l'AI diventa più efficiente e quindi più economica, il suo utilizzo si espande a nuove applicazioni e nuovi utenti che prima non potevano permettersela.

Questo è particolarmente evidente con l'avvento di API pubbliche e modelli as-a-service. ChatGPT, Claude, Gemini e altri LLM sono ora accessibili gratuitamente o a costi molto bassi a centinaia di milioni di utenti. Ogni utente genera centinaia o migliaia di query, creando un carico computazionale aggregato enorme. [@deVries2023], come menzionato nella sezione 3.2.2, stima che se Google integrasse l'AI generativa in tutte le sue ricerche, il consumo energetico aggiuntivo sarebbe paragonabile al consumo annuale dell'Irlanda.

Ma l'effetto indiretto va oltre l'uso consumer. [@Luccioni2025] documentano come l'AI più accessibile stimoli la creazione di applicazioni che prima erano impossibili: chatbot personalizzati per ogni sito web, assistenti virtuali integrati in ogni app, sistemi di raccomandazione sempre più sofisticati, filtri AI per foto e video, traduzione in tempo reale, generazione di contenuti multimediali. Ciascuna di queste applicazioni, individualmente modesta, contribuisce al carico computazionale complessivo.

Un esempio citato da [@Luccioni2025] riguarda gli strumenti di "AI writing assistants" integrati in software di produttività. Tools come Grammarly, Notion AI, Microsoft Copilot eseguono continuamente inferenze AI mentre gli utenti scrivono, controllando grammatica, suggerendo riformulazioni, completando frasi. Ogni keystroke può potenzialmente triggerare una chiamata API. Moltiplicato per milioni di utenti che usano questi strumenti quotidianamente per ore, il consumo energetico aggregato diventa significativo – ma invisibile all'utente finale.

**Effetti rimbalzo sistemici: l'AI al servizio di industrie estrattive.** Il terzo e più preoccupante tipo di effetto rimbalzo riguarda l'uso dell'AI per espandere e ottimizzare settori economici ad alta intensità di carbonio. [@Luccioni2025] documentano numerosi casi dove l'AI viene applicata non per ridurre le emissioni, ma per *aumentare l'efficienza di industrie fossili*, portando paradossalmente a maggiori emissioni totali.

**Il caso Microsoft-ExxonMobil.** L'esempio più emblematico citato da [@Luccioni2025] riguarda la partnership tra Microsoft e ExxonMobil per l'uso dell'AI nell'esplorazione petrolifera. Microsoft ha sviluppato algoritmi di machine learning per analizzare dati geologici e identificare giacimenti petroliferi con maggiore precisione, permettendo a ExxonMobil di aumentare la produzione di **50.000 barili al giorno** nel bacino Permiano in Texas.

[@Luccioni2025] hanno calcolato che le emissioni di CO2 derivanti da questo aumento di produzione petrolifera superano di **640 volte** le emissioni che Microsoft dichiara di aver evitato attraverso i suoi progetti di carbon removal (cattura e sequestro del carbonio). In altre parole: mentre pubblicamente Microsoft si impegna per la neutralità carbonica e investe in tecnologie di rimozione della CO2, privatamente vende servizi AI che causano emissioni centinaia di volte superiori a quelle che dichiara di rimuovere.

Questo non è un caso isolato. [@Kaack2022] documentano l'uso diffuso dell'AI in:
- **Esplorazione petrolifera e di gas**: ottimizzazione delle trivellazioni, identificazione di giacimenti, riduzione dei costi di esplorazione
- **Agricoltura intensiva**: ottimizzazione di allevamenti industriali che generano enormi emissioni di metano
- **Logistica di merci**: rendendo più efficiente il trasporto di beni materiali, stimola l'aumento del commercio globale e quindi delle emissioni da trasporto
- **Fast fashion**: sistemi di raccomandazione che accelerano il ciclo di consumo di abbigliamento

In ciascuno di questi casi, l'AI rende le industrie problematiche più *efficienti* – ma questa efficienza si traduce in maggiore *volume* di attività, non in riduzione dell'impatto ambientale totale. Questo è precisamente il meccanismo del paradosso di Jevons operante a livello sistemico [@Luccioni2025].

**Quantificare il rimbalzo: oltre il 100%?** In alcuni casi, l'effetto rimbalzo può essere così forte da superare completamente i guadagni di efficienza – quello che gli economisti chiamano "backfire" (controeffetto). [@Luccioni2025] citano studi che suggeriscono che in certi settori tecnologici, per ogni miglioramento dell'1% nell'efficienza energetica, il consumo totale aumenta dello 0,5-1,5%, a seconda del contesto e delle dinamiche di mercato.

Nel caso dell'AI, [@Luccioni2025] argomentano che siamo probabilmente già in una situazione di backfire: i miglioramenti nell'efficienza computazionale (misurata come operazioni per watt) sono stati drammatici negli ultimi 10 anni, ma il consumo energetico totale dell'industria AI è *aumentato* ancora più rapidamente. Le proiezioni dell'IEA sul raddoppio del consumo dei data center entro il 2026 (discusse nella sezione 3.2.2) confermano questa dinamica [@IEA2024].

**Implicazioni per le politiche "Green AI".** Queste evidenze sollevano seri dubbi sull'efficacia delle iniziative "Green AI" che si concentrano esclusivamente sull'efficienza tecnica. Come argomentano [@Luccioni2025], migliorare l'efficienza energetica dell'addestramento e dell'inferenza è certamente importante – sarebbe peggio se i modelli fossero *anche* inefficienti. Ma in assenza di limiti assoluti sulla scala e sull'uso dell'AI, l'efficienza da sola non garantisce riduzioni nell'impronta ambientale totale, e può anzi facilitare un'espansione ancora più rapida del settore.

[@Kaack2022] arrivano a conclusioni simili, sostenendo che le politiche per l'AI sostenibile devono andare oltre l'efficienza tecnica e affrontare le dinamiche economiche e istituzionali che guidano la crescita del settore: incentivi al profitto, competizione tra aziende, mancanza di regolamentazione, esternalizzazione dei costi ambientali.

La sezione successiva esamina il dibattito "Green AI vs Red AI" per contestualizzare queste dinamiche nella cultura della ricerca in machine learning.

### 3.5.3 Il dibattito "Green AI vs Red AI"

Il fenomeno degli effetti rimbalzo nell'AI si interseca con un dibattito metodologico che ha iniziato a emergere all'interno della comunità di machine learning: la distinzione tra **"Red AI"** e **"Green AI"**. Questa distinzione, introdotta da [@Schwartz2020], rappresenta un tentativo di reindirizzare le priorità della ricerca AI verso una maggiore sostenibilità, ma rivela anche le resistenze culturali e istituzionali che rendono difficile questo cambiamento.

**Red AI: la cultura del "compute maximalism".** [@Schwartz2020] usano il termine "Red AI" per descrivere l'approccio dominante nella ricerca di machine learning: massimizzare l'accuratezza dei modelli a prescindere dal costo computazionale. In questa paradigma, l'efficienza energetica è considerata secondaria o irrilevante; ciò che conta è ottenere le migliori prestazioni possibili sul benchmark, anche se questo richiede addestrare modelli sempre più grandi su hardware sempre più potente.

Questa cultura è profondamente radicata negli incentivi della ricerca accademica e industriale. I paper che raggiungono lo "state-of-the-art" (le migliori prestazioni) su dataset standardizzati hanno maggiori probabilità di essere accettati alle conferenze prestigiose, di ottenere citazioni, di portare a carriere accademiche di successo. Le aziende competono per sviluppare i modelli più capaci, perché questo genera attenzione mediatica, attira investimenti, e crea vantaggio competitivo nel mercato [@Schwartz2020].

**Green AI: efficienza come metrica primaria.** In contrasto, [@Schwartz2020] propongono il concetto di "Green AI": ricerca che considera l'efficienza computazionale non come vincolo secondario ma come obiettivo primario. Questo significa:

1. **Riportare costi computazionali**: tutti i paper dovrebbero includere non solo l'accuratezza raggiunta, ma anche il tempo di addestramento, il numero di operazioni in virgola mobile (FLOPs), il consumo energetico stimato, le emissioni di CO2

2. **Valorizzare l'efficienza nelle valutazioni**: le conferenze e i journal dovrebbero dare credito a metodi che raggiungono prestazioni competitive con meno risorse, anche se non ottengono il punteggio assoluto più alto

3. **Sviluppare benchmark di efficienza**: oltre ai tradizionali benchmark di accuratezza, creare competizioni che premiano il miglior rapporto prestazioni/energia

4. **Democratizzare la ricerca**: metodi più efficienti permettono a ricercatori con meno risorse computazionali di contribuire, riducendo la concentrazione della ricerca AI nelle grandi corporation

**La resistenza al cambiamento.** Nonostante queste proposte, [@Schwartz2020] documentano che il cambiamento è stato lento. Nella loro analisi degli articoli pubblicati nelle principali conferenze di machine learning, hanno trovato che circa il **90% degli articoli** continua a riportare solo metriche di accuratezza, omettendo completamente informazioni su costi computazionali ed energetici.

Questo non è solo pigrizia o disattenzione. [@Luccioni2025] argomentano che esistono incentivi strutturali che rendono difficile l'adozione della Green AI:

- **Competizione per il prestigio**: in un campo altamente competitivo, dedicare risorse computazionali all'ottimizzazione dell'efficienza piuttosto che al miglioramento dell'accuratezza può significare perdere la "corsa" per pubblicare il modello migliore

- **Accesso asimmetrico alle risorse**: le grandi aziende tech hanno data center così vasti che il costo energetico di addestrare modelli enormi è marginale rispetto al loro budget; per loro, l'efficienza è meno critica che per laboratori universitari con budget limitati

- **Mancanza di dati pubblici**: senza dati standardizzati sui consumi energetici dei diversi modelli e sistemi, è difficile fare confronti significativi e premiare l'efficienza

- **Assenza di regolamentazione**: a differenza di settori come l'automotive o l'edilizia, dove esistono standard di efficienza energetica obbligatori, l'industria AI opera in un vuoto regolatorio pressoché completo

**Oltre la dicotomia Red/Green.** [@Luccioni2025] suggeriscono che la distinzione Red AI/Green AI, pur utile pedagogicamente, rischia di essere eccessivamente semplicistica. Il vero problema non è scegliere tra efficienza e prestazioni, ma riconoscere che *l'efficienza da sola non basta* in presenza di effetti rimbalzo sistemici.

Anche se tutta la ricerca AI diventasse "Green" nel senso di [@Schwartz2020] – modelli più efficienti, hardware ottimizzato, algoritmi parsimoniosi – fintanto che gli incentivi economici premiano la crescita e l'espansione, il consumo totale continuerebbe ad aumentare. Come dimostrato nella sezione precedente sul paradosso di Jevons, modelli più efficienti rendono l'AI più accessibile e quindi ne amplificano l'uso, potenzialmente annullando i guadagni di efficienza a livello aggregato [@Luccioni2025].

Questo suggerisce che una vera AI sostenibile richiede non solo innovazione tecnica (Green AI) ma anche cambiamenti nelle strutture di governance, negli incentivi economici, e nelle priorità sociali – temi che esploreremo nella sezione 3.7 sull'interpretazione sociologica critica.

## 3.6 Opacità e mancanza di trasparenza

### 3.6.1 I dati mancanti

Uno degli ostacoli più significativi alla comprensione e alla regolamentazione dell'impronta ambientale dell'AI è la **mancanza di trasparenza** da parte delle aziende che sviluppano e deployano questi sistemi. Come documentano [@Crawford2021] e [@Li2023], le grandi tech companies trattano i dati sui consumi energetici e idrici dei loro modelli AI come informazioni proprietarie e commercialmente sensibili, rendendo estremamente difficile una valutazione indipendente dei loro impatti.

**Il problema delle "AI model cards" incomplete.** Negli ultimi anni, sotto pressione della comunità di ricerca e della società civile, alcune aziende hanno iniziato a pubblicare "model cards" – documenti che descrivono le caratteristiche dei modelli AI, incluse informazioni sul loro addestramento e performance. Tuttavia, come criticano [@Li2023], queste model cards raramente includono dati completi sull'impronta ambientale.

In particolare, [@Li2023] evidenziano che le model cards tipicamente *omettono completamente* i dati su:

- **Consumo d'acqua scope 1** (acqua evaporata direttamente nei data center durante l'addestramento)
- **Consumo d'acqua scope 2** (acqua usata nelle centrali elettriche per generare l'energia consumata)
- **Emissioni scope 3** (emissioni nella supply chain: produzione di chip, costruzione di data center, trasporti)
- **Localizzazione geografica specifica** dell'addestramento (che determina il carbon intensity del mix energetico e la disponibilità idrica locale)

Quando vengono forniti dati sul carbon footprint, questi sono spesso calcolati usando il metodo *market-based* piuttosto che *location-based*. La differenza è cruciale: il metodo market-based permette alle aziende di "compensare" le emissioni acquistando crediti di energia rinnovabile o certificati verdi, anche se l'elettricità effettivamente consumata proviene da centrali fossili. Il metodo location-based, invece, calcola le emissioni reali basandosi sul mix energetico effettivo della rete elettrica dove opera il data center [@Li2023].

**Asimmetria informativa strutturale.** [@Crawford2021] argomenta che questa opacità non è accidentale ma riflette una strategia deliberata di controllo dell'informazione. Le aziende tech hanno un interesse diretto a mantenere vaghi i dettagli sull'impronta ambientale dei loro sistemi, per diverse ragioni:

1. **Vantaggio competitivo**: rivelare i costi energetici dettagliati dei modelli potrebbe dare informazioni utili ai competitori sulla scala e l'efficienza delle loro infrastrutture

2. **Rischio reputazionale**: dati precisi potrebbero alimentare critiche pubbliche e campagne di pressione da parte di attivisti ambientali

3. **Evitare regolamentazione**: maggiore trasparenza potrebbe catalizzare richieste di regolamentazione obbligatoria sui consumi energetici e idrici

4. **Proteggere le narrative di sostenibilità**: numeri concreti potrebbero contraddire le dichiarazioni pubbliche di impegno ambientale

Questa asimmetria informativa rende estremamente difficile per ricercatori indipendenti, regolatori, e la società civile valutare accuratamente l'impatto dell'AI. Gli studi come quelli di [@Strubell2019], [@Patterson2021], [@Li2023] e [@Luccioni2025] devono basarsi su stime, assunzioni ragionevoli, e i pochi dati parziali disponibili – un processo che introduce inevitabilmente incertezza e margini di errore significativi.

### 3.6.2 Greenwashing e narrative corporate

La mancanza di trasparenza discussa nella sezione precedente si intreccia con pratiche sistematiche di **greenwashing** – la presentazione pubblica di un'immagine di sostenibilità ambientale che maschera o contraddice le pratiche effettive dell'azienda. Come documentano [@Crawford2021] e [@Luccioni2025], le grandi tech companies hanno sviluppato narrative sofisticate che enfatizzano selettivamente gli aspetti "green" dell'AI mentre minimizzano o occultano gli impatti negativi.

**Le dichiarazioni di "carbon neutrality" e i loro limiti.** Molte aziende tech – incluse Google, Microsoft, Amazon – hanno annunciato impegni ambiziosi verso la "carbon neutrality" o addirittura la "carbon negativity" (rimuovere più CO2 di quanto emesso). Tuttavia, come osservano [@Crawford2021] e [@Luccioni2025], questi impegni si basano prevalentemente su meccanismi di *compensazione* (carbon offsets) piuttosto che su riduzioni effettive delle emissioni.

I carbon offsets funzionano così: un'azienda che genera emissioni può "compensarle" finanziando progetti che dovrebbero rimuovere o evitare emissioni equivalenti altrove – piantare alberi, investire in energie rinnovabili, proteggere foreste. Sulla carta, il bilancio netto risulta zero o negativo. Ma questo approccio presenta problemi strutturali ben documentati dalla letteratura scientifica [@Luccioni2025]:

1. **Addizionalità incerta**: molti progetti di offset sarebbero avvenuti comunque senza il finanziamento, quindi non rappresentano riduzioni *aggiuntive* di emissioni

2. **Permanenza dubbia**: gli alberi piantati potrebbero morire, bruciare in incendi, o essere tagliati nei decenni successivi, rilasciando nuovamente la CO2

3. **Problemi di quantificazione**: calcolare esattamente quanta CO2 un progetto rimuove o evita è estremamente complesso e soggetto a incertezze

4. **Giustizia ambientale**: molti progetti di offset avvengono nel Sud globale e possono avere impatti negativi su comunità locali (es: espropriazione di terre per piantagioni)

Soprattutto, come criticano [@Luccioni2025], gli offset permettono alle aziende di continuare ad *aumentare* le loro emissioni assolute mentre dichiarano di essere "carbon neutral" – un paradosso contabile che non risolve il problema fisico dell'accumulo di CO2 in atmosfera.

**Il caso Microsoft: contraddizioni tra dichiarazioni e pratiche.** Un esempio particolarmente emblematico analizzato da [@Luccioni2025] riguarda Microsoft. Pubblicamente, l'azienda si è impegnata a diventare "carbon negative" entro il 2030, rimuovendo più carbonio di quanto ne emette. Ha investito miliardi in progetti di carbon removal e pubblica report di sostenibilità dettagliati che enfatizzano questi impegni.

Tuttavia, come documentato nella sezione 3.5.2 sul paradosso di Jevons, contemporaneamente Microsoft vende servizi AI a ExxonMobil per ottimizzare l'estrazione petrolifera, contribuendo a un aumento di produzione di 50.000 barili al giorno. [@Luccioni2025] calcolano che le emissioni derivanti da questo petrolio aggiuntivo superano di **640 volte** le emissioni che Microsoft dichiara di rimuovere attraverso i suoi progetti di carbon capture.

Questa contraddizione rivela un problema strutturale: le aziende tech definiscono la loro "responsabilità ambientale" in modo estremamente selettivo, includendo solo le emissioni dirette delle loro operazioni (scope 1 e 2) e alcuni aspetti limitati della supply chain (scope 3), ma escludendo completamente le emissioni *abilitate* dall'uso dei loro prodotti e servizi. Come osserva [@Crawford2021], è come se un'azienda di armi dichiarasse la propria sostenibilità calcolando solo le emissioni delle fabbriche, ignorando quelle delle guerre combattute con le armi prodotte.

**AI "per il bene" vs AI "per il profitto".** Un altro pattern di greenwashing identificato da [@Kaack2022] riguarda la presentazione selettiva delle applicazioni AI. Nei materiali di marketing, nei report di sostenibilità, e nelle conferenze pubbliche, le aziende tech enfatizzano le applicazioni "AI for Good" – modelli climatici, monitoraggio della deforestazione, ottimizzazione delle energie rinnovabili – come discusso nel Capitolo 2.

Tuttavia, come documentano [@Kaack2022], queste applicazioni climate-positive rappresentano una **frazione minuscola** dell'uso totale dell'AI da parte delle stesse aziende. La maggior parte della capacità computazionale viene dedicata ad applicazioni commerciali: advertising personalizzato, sistemi di raccomandazione per aumentare il consumo, ottimizzazione di supply chain per fast fashion, strumenti per industrie estrattive.

[@Kaack2022] hanno analizzato il portfolio di progetti AI delle grandi tech companies e hanno trovato che meno del **5% della capacità computazionale** viene dedicata ad applicazioni esplicitamente orientate alla sostenibilità climatica. Il restante 95% serve applicazioni che al meglio sono neutrali rispetto al clima, e spesso contribuiscono attivamente ad aumentare consumi ed emissioni attraverso gli effetti rimbalzo discussi nella sezione 3.5.

**L'invisibilità strategica degli impatti.** [@Crawford2021] argomenta che la retorica della "nuvola" (*cloud*) e dell'AI "immateriale" serve una funzione ideologica precisa: rendere invisibili le catene materiali di estrazione, produzione, consumo e smaltimento che sostengono l'infrastruttura digitale. Quando l'AI viene presentata come pura "intelligenza software" slegata dalla fisicità, diventa più facile ignorare o minimizzare i suoi impatti ambientali concreti.

Questa invisibilità è particolarmente evidente nei consumer-facing products. Quando un utente fa una domanda a ChatGPT o chiede a Siri di impostare un promemoria, non c'è alcun feedback sul costo ambientale dell'interazione. L'interfaccia è pulita, istantanea, apparentemente gratuita. La materialità – i server che si scaldano, l'acqua che evapora, l'elettricità consumata, i minerali estratti per produrre l'hardware – rimane nascosta nei data center remoti, nelle miniere del Congo e della Mongolia, nelle discariche di e-waste in Ghana [@Crawford2021].

**Verso una trasparenza obbligatoria?** Di fronte a queste dinamiche, [@Li2023] e [@Luccioni2025] argomentano che la trasparenza volontaria ha fallito e che servono meccanismi di **reporting obbligatorio** regolato per legge. Propongono che:

1. Ogni modello AI deployato commercialmente dovrebbe includere una "environmental model card" standardizzata con dati verificabili su consumi energetici, idrici, emissioni (scope 1, 2 e 3), e materiali

2. Le aziende dovrebbero essere obbligate a usare metodologie *location-based* piuttosto che *market-based* per il calcolo delle emissioni, fornendo un'immagine più accurata dell'impatto reale

3. I dati dovrebbero essere resi pubblici in formato machine-readable per permettere audit indipendenti e ricerca scientifica

4. Le dichiarazioni di sostenibilità dovrebbero includere non solo le emissioni dirette ma anche quelle "abilitate" dagli usi downstream dei sistemi AI

Senza questo tipo di trasparenza obbligatoria, concludono [@Luccioni2025], il greenwashing continuerà a dominare il discorso pubblico sull'AI e ambiente, ostacolando la comprensione dei reali trade-off e delle scelte necessarie per una transizione ecologica genuina.

## 3.7 Interpretazione critica dalla prospettiva sociologica

Come discusso nella sezione 1.2, i teorici critici della modernizzazione ecologica hanno evidenziato i limiti strutturali della versione "debole": la subordinazione della razionalità ecologica a quella economica, la sottovalutazione delle dinamiche capitaliste di crescita e profitto, il paradosso di Jevons che vanifica i guadagni di efficienza [@Foster2012; @Ewing2017].

**Il caso empirico dell'AI conferma queste critiche teoriche.** L'evidenza documentata in questo capitolo mostra che:

- I guadagni di efficienza computazionale si traducono in modelli più grandi e deployment più diffuso, non in riduzioni assolute (paradosso di Jevons empiricamente verificato)
- Le logiche di profitto prevalgono sistematicamente: l'AI viene venduta a industrie fossili mentre si proclama "green", i data center vengono costruiti dove l'energia è economica (non dove è pulita)
- I costi ambientali vengono esternalizzati su comunità vulnerabili (Sud globale, territori indigeni) mentre i benefici si concentrano nel Nord globale
- L'opacità delle aziende tech impedisce accountability democratica

Verso una modernizzazione ecologica "riflessiva" che incorpori governance democratica, trasparenza obbligatoria, giustizia distributiva e internalizzazione dei costi nascosti nel calcolo economico [@Beck1992].


## 3.8 Sintesi del capitolo

L'evidenza documentata rivela il paradosso dell'AI: una tecnologia presentata come strumento della transizione ecologica che manifesta un'impronta ambientale significativa e in rapida crescita attraverso consumi energetici, idrici e materiali. I guadagni di efficienza computazionale portano paradossalmente a maggiore consumo totale (paradosso di Jevons), mentre i costi ambientali vengono esternalizzati su comunità vulnerabili. Questo conferma le critiche alla modernizzazione ecologica "debole" e richiede una valutazione che integri dimensioni di giustizia, governance democratica e trasparenza.

# CONCLUSIONI

Questa tesi ha esplorato il rapporto tra intelligenza artificiale e ambiente attraverso la lente della teoria della modernizzazione ecologica, con l'obiettivo di comprendere se e come l'AI possa contribuire alla transizione ecologica delle società contemporanee. La domanda di ricerca che ha guidato l'analisi è stata: **In che modo l'intelligenza artificiale può essere analizzata sociologicamente come strumento di transizione ecologica nella prospettiva della modernizzazione ecologica?**

Le sotto-domande che hanno strutturato l'indagine erano:
1. Quali sono le applicazioni dell'AI che contribuiscono alla mitigazione del cambiamento climatico?
2. Qual è l'impronta ambientale dell'AI stessa e come questa contraddice le narrative "green"?
3. Come può la teoria della modernizzazione ecologica aiutare a interpretare questo paradosso?

Dopo aver esplorato queste domande attraverso un'analisi critica della letteratura scientifica, possiamo ora offrire una sintesi dei risultati e delle implicazioni teoriche e pratiche che emergono.

## Sintesi dei risultati principali

### Risposta alla domanda di ricerca: la duplice natura dell'AI

La risposta alla domanda di ricerca centrale è necessariamente complessa e dialettica: **l'intelligenza artificiale manifesta una duplice natura, operando simultaneamente come potenziale strumento di transizione ecologica e come vettore di intensificazione del metabolismo industriale**. Questa non è una contraddizione superficiale che possa essere risolta con semplici aggiustamenti tecnici, ma riflette tensioni strutturali profonde tra le logiche del capitalismo (crescita, profitto, competizione) e gli imperativi ecologici (limiti planetari, sostenibilità, giustizia distributiva).

**L'AI come alleata della transizione ecologica.** Come documentato nel Capitolo 2, esistono applicazioni concrete e promettenti dell'AI per affrontare la crisi climatica. [@Rolnick2022] hanno mappato sistematicamente come il machine learning possa contribuire alla mitigazione e all'adattamento climatico attraverso:

- **Transizione energetica**: ottimizzazione delle smart grid per integrare fonti rinnovabili intermittenti, previsione della produzione solare ed eolica, riduzione degli sprechi nella trasmissione. L'esempio di DeepMind che ha ridotto del 40% il consumo energetico dei sistemi di raffreddamento dei data center Google dimostra concretamente il potenziale dell'ottimizzazione basata su ML [@IEA2024]

- **Monitoraggio climatico e gestione dei disastri**: modelli AI che rivoluzionano le previsioni meteorologiche, sistemi di allerta precoce per alluvioni che raggiungono 460+ milioni di persone in 80+ paesi, monitoraggio satellitare della deforestazione in tempo reale [@Nearing2024]

- **Applicazioni settoriali**: agricoltura di precisione, ottimizzazione delle supply chain, economia circolare, tracciamento dei materiali per il riciclo [@Vinuesa2020RoleAI]

Queste applicazioni incarnano la promessa della modernizzazione ecologica informazionale: l'AI permette di rendere visibile l'invisibile (emissioni, deforestazione, sprechi), di ottimizzare sistemi complessi, di prevedere eventi futuri, di coordinare processi distribuiti. In questa prospettiva, l'AI appare come l'incarnazione tecnologica più avanzata del disaccoppiamento tra crescita economica e degradazione ambientale che la EMT identifica come obiettivo della transizione ecologica.

**L'AI come problema ambientale.** Tuttavia, il Capitolo 3 ha documentato sistematicamente come l'infrastruttura stessa dell'AI generi impatti ambientali significativi e in rapida crescita:

- **Consumo energetico**: l'addestramento di un singolo grande modello può emettere 284.000 kg di CO2e, equivalente a 5 automobili durante l'intero ciclo di vita [@Strubell2019]; GPT-3 ha consumato 1.287 MWh [@Patterson2021]; le proiezioni indicano che il consumo dei data center raddoppierà entro il 2026, raggiungendo 945 TWh [@IEA2024]

- **Consumo idrico**: l'addestramento di GPT-3 ha evaporato circa 700.000 litri di acqua dolce [@Li2023]; Google ha prelevato 25 miliardi di litri nel 2022; i data center vengono costruiti in regioni già water-scarce, creando conflitti con comunità locali

- **Materiali e rifiuti**: l'estrazione di terre rare genera 75.000 litri di acque acide per tonnellata raffinata [@Crawford2021]; 62 milioni di tonnellate di e-waste nel 2022, solo 22% riciclato formalmente [@Luccioni2025]

- **Effetti rimbalzo sistemici**: i guadagni di efficienza computazionale non riducono il consumo totale ma vengono "reinvestiti" in modelli più grandi, applicazioni più numerose, deployment più esteso; l'AI viene usata per ottimizzare industrie fossili (es: Microsoft-ExxonMobil genera emissioni 640 volte superiori ai target di carbon removal di Microsoft) [@Luccioni2025]

**Il paradosso rivelato dalla teoria sociologica.** La teoria della modernizzazione ecologica, applicata criticamente al caso dell'AI, aiuta a interpretare questo paradosso apparente. La versione "debole" della EMT – che confida nel mercato e nell'innovazione tecnologica spontanea per risolvere le crisi ambientali – si rivela inadeguata. Come hanno argomentato i critici [@Foster2012; @Ewing2017], questa versione sottostima sistematicamente:

1. La **subordinazione della razionalità ecologica a quella economica**: quando profitto e sostenibilità entrano in conflitto, prevale il primo (es: vendita di AI a ExxonMobil nonostante gli impegni di carbon neutrality)

2. Il **"treadmill of production"**: le dinamiche di competizione capitalistica impongono crescita continua indipendentemente dalle conseguenze ambientali (es: corsa agli armamenti computazionali)

3. Il **paradosso di Jevons**: i guadagni di efficienza stimolano maggiore utilizzo anziché ridurre il consumo totale (es: modelli più efficienti → modelli più grandi e deployment più diffuso)

4. L'**illusione della dematerializzazione**: la "leggerezza" digitale nasconde pesanti catene materiali di estrazione, produzione e smaltimento [@Crawford2021]

**Verso una sintesi: condizioni per una AI ecologicamente sostenibile.** La risposta alla domanda di ricerca non può quindi essere un semplice "sì" o "no" alla possibilità che l'AI contribuisca alla transizione ecologica. Deve invece specificare le *condizioni istituzionali, economiche e politiche* sotto cui questo contributo potrebbe realizzarsi, evitando di riprodurre le contraddizioni del capitalismo verde.

Queste condizioni, come emerso dall'analisi, includono:
- Governance democratica e trasparenza obbligatoria, non volontaria
- Internalizzazione dei costi ambientali attraverso regolamentazione
- Attenzione esplicita alla giustizia distributiva (chi beneficia, chi paga i costi)
- Possibili limiti assoluti alla crescita di applicazioni AI futili o dannose
- Prioritizzazione di usi climate-positive rispetto a usi commerciali estrattivi

Senza queste condizioni, l'AI continuerà probabilmente a manifestare la sua natura contraddittoria: uno strumento potente che genera sia opportunità ecologiche sia intensificazione degli impatti ambientali, con un bilancio netto incerto e probabilmente negativo data la traiettoria attuale di crescita esponenziale.

## Riflessioni teoriche

### Applicabilità della modernizzazione ecologica all'AI

La teoria della modernizzazione ecologica si rivela allo stesso tempo *illuminante* e *limitata* quando applicata al caso dell'intelligenza artificiale. È illuminante perché cattura effettivamente alcuni aspetti reali e importanti di come l'AI viene sviluppata e deployata in direzione ecologica; è limitata perché non riesce a cogliere le dinamiche sistemiche e le contraddizioni che minano queste stesse applicazioni.

**Cosa la EMT cattura bene.** La teoria della modernizzazione ecologica riesce a spiegare efficacemente le applicazioni "AI for Green" documentate nel Capitolo 2. Il framework concettuale della EMT – razionalità ecologica attraverso informazione, efficienza e ottimizzazione, governance multi-attore, innovazione tecnologica accelerata – descrive accuratamente come l'AI viene effettivamente utilizzata per la transizione energetica, il monitoraggio climatico, e l'adattamento ai cambiamenti già in corso.

In particolare, il concetto di "modernizzazione ecologica informazionale" proposto nel Capitolo 1 si rivela utile: l'AI permette davvero forme di governance ambientale precedentemente impossibili, rendendo visibili fenomeni prima nascosti (emissioni di metano da pipeline, deforestazione in aree remote, sprechi energetici in edifici), coordinando sistemi complessi in tempo reale (smart grid con migliaia di generatori rinnovabili), e democratizzando l'accesso a capacità di analisi sofisticate (citizen science, ONG ambientaliste).

**Cosa la EMT sottostima o ignora.** Tuttavia, l'analisi critica del Capitolo 3 ha rivelato i limiti strutturali dell'approccio EMT, almeno nella sua versione "debole" orientata al mercato. Come argomentato dai teorici critici [@Foster2012; @Ewing2017; @Beck1992], la EMT tende a sottovalutare:

1. **Le contraddizioni capitaliste**: la logica del profitto e della crescita che sistematicamente prevale sulle considerazioni ecologiche quando le due entrano in conflitto

2. **Gli effetti rimbalzo**: il paradosso di Jevons che trasforma guadagni di efficienza in espansione del consumo totale – forse il finding empirico più robusto emerso dall'analisi [@Luccioni2025]

3. **Le dinamiche di potere e giustizia**: chi beneficia dell'AI (Nord globale, classi affluenti) vs chi paga i costi ambientali (Sud globale, comunità marginalizzate) [@Crawford2021]

4. **L'opacità e il greenwashing**: i meccanismi attraverso cui le aziende tech costruiscono narrative di sostenibilità che mascherano pratiche contraddittorie [@Li2023]

**Necessità di integrazione con prospettive critiche.** L'evidenza dal caso AI suggerisce che una teoria sociologica adeguata della relazione tra tecnologie digitali e ambiente deve integrare la EMT con apporti da:

- **Political ecology**: per analizzare le dinamiche di potere, le asimmetrie Nord-Sud, le esternalità ambientali come meccanismi politici non accidenti di mercato [@Ewing2017]

- **Teoria della società del rischio** (Beck): per comprendere come l'AI generi nuove forme di rischio ambientale invisibile e distribuito, richiedendo capacità riflessiva delle istituzioni [@Beck1992]

- **Ecologia economica**: per incorporare concetti come il paradosso di Jevons, i limiti biofisici della crescita, le analisi di lifecycle che l'economia neoclassica tende a ignorare [@Luccioni2025]

Solo una prospettiva teorica multi-dimensionale che integri insights dalla EMT "forte", dalle critiche marxiste ed ecologiche, e dall'analisi dei rischi può cogliere la complessità del fenomeno AI-ambiente.

### Contributo originale della tesi

Questa tesi offre diversi contributi originali al dibattito sociologico su AI e ambiente:

**1. Prima applicazione sistematica della EMT all'AI in contesto italiano.** Come documentato nella sezione 1.3.3 del Capitolo 1, l'AI è rimasta largamente assente dal dibattito sociologico sulla modernizzazione ecologica, nonostante sia diventata centrale nelle discussioni tecniche e di policy. Questa tesi colma questo gap applicando rigorosamente il framework della EMT – nelle sue versioni debole, forte e critica – all'analisi dell'intelligenza artificiale. Nel contesto italiano, questa rappresenta la prima analisi sociologica sistematica di questo tipo.

**2. Integrazione di letteratura tecnica e sociologica.** La tesi ha deliberatamente attraversato i confini disciplinari, integrando letteratura di computer science sull'efficienza energetica dei modelli [@Strubell2019; @Patterson2021; @Schwartz2020], studi ingegneristici sul consumo idrico dei data center [@Li2023], analisi economiche degli effetti rimbalzo [@Luccioni2025], con teoria sociologica sulla modernizzazione ecologica [@MolSpaargaren2000; @Foster2012; @Ewing2017]. Questa sintesi interdisciplinare è rara e permette una comprensione più ricca del fenomeno.

**3. Evidenziazione del gap tra narrative e realtà materiale.** Un contributo chiave è l'aver documentato sistematicamente la divergenza tra le *narrative* pubbliche sull'AI sostenibile (discorso "AI for Good", impegni di carbon neutrality, retorica della dematerializzazione) e le *realtà materiali* nascoste (miniere tossiche, stress idrico, greenwashing, AI venduta a industrie fossili). Questa evidenziazione di contraddizioni strutturali, non solo incongruenze superficiali, è un contributo sociologico sostantivo.

**4. Framework analitico dialettico esportabile.** L'approccio metodologico adottato – esaminare una tecnologia prima attraverso la lente ottimista (Cap. 2) poi attraverso quella critica (Cap. 3) per arrivare a una sintesi informata (Conclusioni) – rappresenta un template esportabile per analizzare sociologicamente altre tecnologie emergenti nel contesto della transizione ecologica (blockchain, Internet of Things, biotecnologie, geo-engineering).

## Implicazioni pratiche e policy

### Raccomandazioni per una AI sostenibile

Sulla base dell'analisi condotta, emergono quattro aree di intervento prioritario per orientare lo sviluppo dell'AI verso una genuina sostenibilità ecologica e sociale:

**1. Trasparenza obbligatoria e accountability.** Come proposto da [@Li2023] e [@Luccioni2025], è necessario istituire meccanismi di reporting obbligatorio, non volontario:

- **Environmental Model Cards standardizzate**: ogni modello AI deployato commercialmente deve pubblicare dati verificabili su consumi energetici (training e inference), consumo idrico (scope 1 e 2), emissioni (scope 1, 2 e 3), e materiali utilizzati

- **Metodologia location-based per le emissioni**: vietare il reporting market-based che maschera le emissioni reali attraverso crediti di energia rinnovabile; richiedere calcoli basati sul mix energetico effettivo della rete

- **Audit indipendenti**: le dichiarazioni ambientali devono essere verificate da enti terzi, con sanzioni significative per misreporting

- **Accesso pubblico ai dati**: pubblicare i dati in formato machine-readable per permettere ricerca indipendente e accountability pubblica

**2. Regolamentazione degli usi e incentivi differenziati.** Non tutta l'AI è uguale dal punto di vista ambientale e sociale. Come suggeriscono [@Kaack2022] e [@vanWynsberghe2021], serve una differenziazione:

- **Incentivi per applicazioni climate-positive**: sussidi, accesso prioritario a risorse computazionali, supporto pubblico per R&D in AI esplicitamente orientata a mitigazione e adattamento climatico

- **Disincentivi per usi futili o dannosi**: carbon tax differenziata che penalizzi applicazioni ad alto consumo energetico senza benefici sociali chiari (es: generazione di immagini per pubblicità, sorveglianza di massa)

- **Moratorie su partnership con industrie fossili**: vietare o limitare fortemente la vendita di servizi AI a compagnie petrolifere e del gas per ottimizzare l'estrazione

- **Criteri di proporzionalità**: richiedere che il beneficio sociale di un'applicazione AI sia proporzionale al suo costo ambientale

**3. Governance democratica e giustizia ambientale.** Come enfatizzato dalla versione "forte" della EMT, la governance deve essere democratica e attenta alle disuguaglianze:

- **Partecipazione delle comunità locali**: le decisioni sulla localizzazione di data center e infrastrutture AI devono coinvolgere le comunità che subiranno gli impatti, con diritto di veto per regioni già water-scarce o ambientalmente vulnerabili

- **Environmental justice impact statements**: valutazioni obbligatorie che documentino come un progetto AI distribuirà benefici e costi tra diverse popolazioni, con particolare attenzione a comunità marginalizzate

- **Rappresentanza del Sud globale**: meccanismi istituzionali per assicurare che le voci dei paesi che forniscono risorse materiali (minerali, energie, manodopera) abbiano potere decisionale sullo sviluppo dell'AI

- **Giustizia inter-generazionale**: incorporare principi di sostenibilità di lungo periodo che considerino le generazioni future nelle decisioni su deployment dell'AI

**4. Cambiamento culturale nella ricerca AI.** Come proposto dal movimento "Green AI" [@Schwartz2020], serve una trasformazione delle priorità:

- **Efficienza come metrica di valutazione**: le conferenze e i journal di ML dovrebbero dare pari peso a efficienza e accuratezza nella valutazione dei contributi scientifici

- **Penalizzare il "compute maximalism"**: disincentivare culturalmente ed economicamente la corsa a modelli sempre più grandi senza necessità dimostrata

- **Premiare l'innovazione frugale**: valorizzare metodi che raggiungono risultati con meno risorse, democratizzando l'accesso alla ricerca AI

- **Formazione dei ricercatori**: incorporare literacy ambientale nei curricula di computer science e data science

### Limiti della ricerca

Questa tesi adotta un approccio compilativo focalizzato sull'impronta ambientale dell'AI; dimensioni sociali cruciali (lavoro, concentrazione di potere, impatti occupazionali) rimangono in secondo piano. La rapida evoluzione del settore implica che alcuni dati potrebbero essere superati. L'applicazione della EMT all'AI richiede estensioni teoriche che questa tesi solo abbozza.

### Direzioni per ricerche future

Questa analisi apre diverse direzioni promettenti:

- **Studi empirici longitudinali** sull'evoluzione dell'impronta ambientale dell'AI a livello nazionale, verificando se gli impegni di carbon neutrality si traducono in riduzioni assolute
- **Analisi comparativa Nord-Sud** per approfondire le asimmetrie: chi beneficia dell'AI e chi paga i costi ambientali, con quale possibilità di ri-distribuzione equa
- **Governance partecipativa e alternative tecnologiche**: casi di coinvolgimento democratico nelle decisioni su infrastrutture AI, modelli alternativi (computazione distribuita, modelli specializzati vs general-purpose, governance cooperativa)


## Considerazioni finali

Questa tesi ha documentato come l'intelligenza artificiale incarni una profonda contraddizione della modernità contemporanea: una tecnologia presentata come strumento essenziale per la transizione ecologica che è essa stessa una fonte significativa e crescente di pressione ambientale. Non si tratta di una contraddizione superficiale risolvibile con aggiustamenti tecnici, ma di una tensione strutturale che riflette le dinamiche più ampie del capitalismo avanzato.

La teoria della modernizzazione ecologica, applicata criticamente, ci aiuta a comprendere sia le possibilità sia i limiti dell'AI come vettore di sostenibilità. Le possibilità sono reali: l'AI può effettivamente ottimizzare sistemi energetici, monitorare ecosistemi, prevedere disastri, accelerare ricerca scientifica climate-positive. Ma queste applicazioni virtuose coesistono con – e sono quantitativamente superate da – usi che intensificano il metabolismo industriale, generano nuove forme di estrazione materiale, ed estendono logiche di crescita illimitata in domini sempre nuovi.

La domanda centrale non è se l'AI sarà "buona" o "cattiva" per l'ambiente, ma piuttosto: sotto quali condizioni istituzionali, economiche e politiche potrebbe contribuire a una transizione ecologica giusta? La risposta richiede governance democratica, trasparenza obbligatoria, internalizzazione dei costi ambientali, attenzione alla giustizia distributiva, e forse limiti assoluti alla crescita di applicazioni ecologicamente dannose.

Senza questi interventi deliberati, la traiettoria attuale – crescita esponenziale guidata da logiche di profitto e competizione – suggerisce che l'AI intensificherà piuttosto che risolvere le crisi ecologiche del XXI secolo. Il ruolo della sociologia è precisamente quello di rendere visibili queste dinamiche strutturali, sfidare le narrative tecno-ottimistiche acritiche, e contribuire a immaginare alternative più giuste e sostenibili.


# BIBLIOGRAFIA

::: {#refs-bib}
:::

