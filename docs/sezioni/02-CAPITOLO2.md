# CAPITOLO 2 - L'INTELLIGENZA ARTIFICIALE COME ALLEATA DELLA TRANSIZIONE ECOLOGICA

## 2.1 Introduzione: AI for Green

Nel dibattito contemporaneo sul rapporto tra tecnologia digitale e ambiente, l'intelligenza artificiale occupa una posizione peculiare e per certi versi paradossale. Da un lato, come vedremo nel Capitolo 3, l'AI rappresenta una delle tecnologie più materialmente intensive dell'economia digitale, con un'impronta energetica, idrica e di risorse naturali che solleva crescenti preoccupazioni. Dall'altro, l'AI viene presentata e utilizzata come uno strumento potenzialmente trasformativo per affrontare la crisi climatica – capace di ottimizzare sistemi energetici, monitorare ecosistemi, prevedere disastri naturali e accelerare la ricerca scientifica in direzione della sostenibilità.

Questo capitolo si concentra su quest'ultima dimensione: l'AI come *alleata* della transizione ecologica. Adottiamo qui la prospettiva che [van Wynsberghe, 2021] definisce "AI for sustainability" – l'insieme delle applicazioni dell'intelligenza artificiale specificatamente orientate a ridurre le emissioni di gas serra, proteggere gli ecosistemi e facilitare l'adattamento ai cambiamenti climatici già in corso. In termini del framework teorico elaborato nel Capitolo 1, questo significa esaminare l'AI attraverso la lente più ottimista della modernizzazione ecologica informazionale: l'AI come incarnazione della razionalità ecologica mediata dall'informazione, come strumento di governance ambientale trasparente e efficiente, come tecnologia che promette di disaccoppiare crescita economica e degradazione ambientale.

### 2.1.1 Mitigazione e adattamento: le due strategie

La letteratura sulla crisi climatica distingue tradizionalmente tra due approcci complementari [Rolnick et al., 2022]:

**Mitigazione** (*mitigation*) si riferisce alle azioni volte a *ridurre* le emissioni di gas serra e quindi a limitare l'entità del riscaldamento globale futuro. La mitigazione richiede trasformazioni nei sistemi energetici (transizione alle rinnovabili), nei trasporti (elettrificazione, riduzione dell'attività di viaggio), negli edifici (efficienza energetica), nell'industria (riduzione delle emissioni di processo, economia circolare) e nell'uso del suolo (protezione delle foreste, agricoltura sostenibile). L'obiettivo dichiarato dagli accordi internazionali – in particolare l'Accordo di Parigi del 2015 – è di limitare il riscaldamento globale ben al di sotto dei 2°C rispetto ai livelli preindustriali, puntando idealmente a 1,5°C.

**Adattamento** (*adaptation*) si riferisce invece alle azioni volte a *prepararsi* alle conseguenze del cambiamento climatico che sono ormai inevitabili, anche negli scenari più ottimisti di mitigazione. L'adattamento richiede investimenti nella resilienza delle infrastrutture, nella gestione dei disastri naturali (alluvioni, siccità, incendi), nella sicurezza alimentare e idrica, nella protezione delle popolazioni vulnerabili. L'adattamento non è un'alternativa alla mitigazione, ma un suo necessario complemento: anche limitando il riscaldamento a 1,5-2°C, il pianeta subirà impatti significativi che richiederanno risposte adeguate.

L'intelligenza artificiale offre potenziali contributi in entrambe le direzioni. Come documenteremo nelle sezioni successive di questo capitolo, l'AI può facilitare la mitigazione ottimizzando le reti elettriche che integrano fonti rinnovabili, riducendo gli sprechi nella logistica e nell'industria, accelerando la scoperta di nuovi materiali per batterie e celle solari. Parallelamente, l'AI può supportare l'adattamento migliorando i sistemi di allerta precoce per eventi estremi, identificando le aree più vulnerabili, ottimizzando la gestione delle risorse idriche in condizioni di scarsità.

### 2.1.2 Una tassonomia delle applicazioni AI per il clima

La survey più completa e sistematica sulle applicazioni dell'intelligenza artificiale per la crisi climatica è "Tackling Climate Change with Machine Learning" di [Rolnick et al., 2022], un lavoro collaborativo che coinvolge alcuni dei principali esperti mondiali di AI e scienze del clima. Gli autori identificano applicazioni promettenti in tredici domini principali:

1. **Sistemi elettrici**: previsione della produzione da fonti rinnovabili, ottimizzazione delle reti intelligenti, gestione della domanda energetica
2. **Trasporti**: ottimizzazione della logistica, riduzione del traffico, supporto alla transizione verso veicoli elettrici
3. **Edifici e città**: gestione intelligente del riscaldamento e raffreddamento, pianificazione urbana sostenibile
4. **Industria**: ottimizzazione delle supply chain, riduzione degli sprechi, scoperta di nuovi materiali a basso impatto
5. **Agricoltura e foreste**: agricoltura di precisione, monitoraggio della deforestazione, gestione sostenibile delle risorse naturali
6. **Rimozione della CO₂**: ottimizzazione dei sistemi di cattura diretta dall'atmosfera, sequestro geologico
7. **Previsione climatica**: miglioramento dei modelli climatici, integrazione di dati eterogenei
8. **Previsione di eventi estremi**: allerta precoce per alluvioni, uragani, incendi, ondate di calore
9. **Impatti sociali**: monitoraggio degli ecosistemi, supporto all'adattamento delle comunità vulnerabili
10. **Finanza**: valutazione dei rischi climatici, orientamento degli investimenti verso attività sostenibili

Ciascuno di questi domini presenta specifiche opportunità per l'applicazione di tecniche di machine learning – dalla computer vision per l'analisi di immagini satellitari, al reinforcement learning per l'ottimizzazione di sistemi complessi, dalle serie temporali per le previsioni meteorologiche al natural language processing per l'analisi di policy e documenti normativi.

[Kaack et al., 2022] propongono un framework complementare che classifica le applicazioni AI in base al loro *ruolo funzionale* piuttosto che al dominio applicativo:

- **Data mining e remote sensing**: tradurre dati grezzi (immagini satellitari, documenti testuali) in informazioni utilizzabili per la ricerca, il policy-making e la pianificazione
- **Sperimentazione accelerata**: esplorare rapidamente spazi di parametri nella scoperta scientifica (materiali, processi chimici)
- **Simulazione fisica rapida**: approssimare modelli computazionalmente costosi per permettere analisi di scenario
- **Previsione**: apprendere da serie temporali per predire produzione energetica, domanda di trasporto, eventi meteorologici
- **Ottimizzazione e controllo di sistemi**: gestire in tempo reale sistemi complessi come reti elettriche, edifici, processi industriali
- **Manutenzione predittiva**: anticipare guasti e inefficienze in sistemi a basso impatto carbonico

Questo framework evidenzia come le stesse tecniche di ML possano essere applicate trasversalmente a domini diversi: un algoritmo di deep learning per la previsione di serie temporali può essere adattato tanto alla produzione solare quanto alla domanda elettrica, tanto ai flussi di traffico quanto alle rese agricole.

### 2.1.3 L'AI nella prospettiva della modernizzazione ecologica

Dal punto di vista della teoria della modernizzazione ecologica, le applicazioni "AI for Green" rappresentano una manifestazione emblematica dei concetti chiave discussi nel Capitolo 1. In particolare:

**Razionalità ecologica attraverso l'informazione.** L'AI permette di rendere visibile ciò che prima era invisibile o difficilmente quantificabile. Le emissioni di metano da pipeline che sfuggono ai controlli tradizionali possono essere rilevate da satelliti e analizzate automaticamente con computer vision. La deforestazione illegale in aree remote può essere monitorata in tempo quasi-reale. I consumi energetici di milioni di edifici possono essere stimati da immagini aeree. Questa "trasparenza informazionale" crea le condizioni per l'applicazione di criteri ecologici a decisioni che prima venivano prese in assenza di dati adeguati.

**Efficienza e ottimizzazione.** L'AI eccelle nel trovare soluzioni ottimali in spazi di ricerca complessi. Una rete elettrica con migliaia di generatori rinnovabili intermittenti, milioni di consumatori con pattern variabili, sistemi di storage distribuiti presenta un livello di complessità che sfugge alle capacità di gestione manuale. L'AI può coordinare questi elementi in tempo reale, massimizzando l'uso di energia pulita e minimizzando gli sprechi. Questo è precisamente il tipo di disaccoppiamento tra servizio fornito (elettricità affidabile) e impatto ambientale (emissioni) che la EMT identifica come obiettivo della transizione ecologica.

**Governance multi-attore e distribuzione della conoscenza.** Molte applicazioni AI per il clima non sono sviluppate da istituzioni pubbliche centralizzate ma da una molteplicità di attori: startup che ottimizzano la logistica, ONG che monitorano le foreste, comunità di citizen scientists che raccolgono dati sulla biodiversità, università che sviluppano modelli climatici più accurati. L'AI democratizza l'accesso alla capacità di analisi ambientale, permettendo a attori che prima erano esclusi di contribuire alla governance ecologica.

**Accelerazione dell'innovazione tecnologica.** L'AI sta trasformando il processo di ricerca e sviluppo in domini cruciali per la transizione: materiali per batterie, celle fotovoltaiche, sistemi di cattura del carbonio. Ciò che prima richiedeva anni di sperimentazione in laboratorio può ora essere simulato computazionalmente, riducendo drasticamente i tempi di scoperta. Questo è esattamente il tipo di "intensificazione della modernizzazione" che la EMT identifica come percorso per superare i problemi ambientali.

### 2.1.4 Struttura del capitolo

Le sezioni successive esplorano empiricamente queste promesse, documentando le applicazioni concrete dell'AI per la transizione ecologica:

**Sezione 2.2** esamina il contributo dell'AI alla **transizione energetica**, analizzando le applicazioni nelle smart grid, nella previsione della produzione rinnovabile, nell'integrazione di sistemi di storage e nella ricerca di nuovi materiali. Questo è il dominio dove l'AI ha forse il maggiore potenziale di impatto, dato che il settore energetico è responsabile di circa il 73% delle emissioni globali di gas serra.

**Sezione 2.3** si concentra sul **monitoraggio climatico e la prevenzione dei disastri**, documentando come l'AI stia rivoluzionando le previsioni meteorologiche, i sistemi di allerta per alluvioni e il monitoraggio della biodiversità. Queste applicazioni illustrano particolarmente bene il potenziale della governance informazionale: l'AI permette di "vedere" il pianeta con una granularità e tempestività senza precedenti.

**Sezione 2.4** presenta brevemente alcune **applicazioni emergenti** in agricoltura di precisione, economia circolare e ottimizzazione delle supply chain, evidenziando la trasversalità dell'AI come strumento di sostenibilità.

**Sezione 2.5** riprende il framework teorico del Capitolo 1 per offrire un'**interpretazione sociologica** di queste applicazioni attraverso la lente della modernizzazione ecologica. Valutiamo in che misura le applicazioni "AI for Green" realizzano effettivamente le promesse della EMT informazionale, e quali sono i limiti e le condizioni che ne determinano l'efficacia.

È importante sottolineare fin dall'inizio che questo capitolo presenta deliberatamente la prospettiva più *ottimista* sul rapporto tra AI e ambiente – quella che enfatizza le potenzialità trasformative della tecnologia. Il Capitolo 3 offrirà la prospettiva complementare e critica, analizzando i costi ambientali nascosti dell'AI stessa e i meccanismi attraverso cui le promesse di efficienza possono paradossalmente portare a maggiori consumi totali. Solo tenendo insieme entrambe le prospettive – l'AI come soluzione e l'AI come problema – possiamo sviluppare una valutazione sociologicamente informata del ruolo effettivo dell'intelligenza artificiale nella transizione ecologica.

## 2.2 AI e transizione energetica

Il settore energetico rappresenta il cuore della crisi climatica contemporanea: secondo l'International Energy Agency, è responsabile di circa il 73% delle emissioni globali di gas serra. La transizione da fonti fossili a fonti rinnovabili costituisce quindi la priorità assoluta per qualsiasi strategia di mitigazione climatica. In questo contesto, l'intelligenza artificiale emerge come strumento potenzialmente trasformativo, capace di affrontare alcune delle sfide tecniche più complesse che ostacolano la decarbonizzazione del sistema energetico.

Come documentato da Rolnick et al. (2022) nella loro survey sistematica "Tackling Climate Change with Machine Learning", l'AI può contribuire alla transizione energetica attraverso tre vettori principali: ottimizzazione delle reti elettriche intelligenti, massimizzazione dell'utilizzo di energie rinnovabili attraverso migliori previsioni e gestione dello storage, e accelerazione della ricerca su nuovi materiali per tecnologie low-carbon. Ciascuno di questi ambiti presenta sfide specifiche dove le capacità di apprendimento automatico, ottimizzazione e gestione della complessità dell'AI possono tradursi in benefici ambientali concreti.

### 2.2.1 Ottimizzazione delle reti elettriche intelligenti (smart grids)

Le **smart grid** – reti elettriche intelligenti dotate di sensori, comunicazione bidirezionale e capacità di gestione dinamica – rappresentano l'infrastruttura fondamentale per integrare fonti rinnovabili su larga scala. Il problema centrale che le smart grid devono risolvere è il **bilanciamento in tempo reale tra domanda e offerta di elettricità**. A differenza delle centrali fossili tradizionali, che possono essere attivate o spente su richiesta per adattarsi ai picchi di domanda, le fonti rinnovabili come solare ed eolico sono intrinsecamente intermittenti: la loro produzione dipende dalle condizioni meteorologiche e non può essere controllata a piacimento.

Questa caratteristica crea una sfida tecnica fondamentale: in ogni istante, la quantità di elettricità immessa nella rete deve corrispondere esattamente alla quantità consumata. Uno squilibrio causa fluttuazioni di frequenza che, se non corretto, può portare a blackout su larga scala. Nel paradigma tradizionale, basato su poche grandi centrali fossili centralizzate, il bilanciamento era relativamente semplice: gli operatori di rete potevano prevedere la domanda e regolare l'output delle centrali di conseguenza. Ma con migliaia di impianti solari ed eolici distribuiti sul territorio, ciascuno con produzione variabile e parzialmente imprevedibile, il problema diventa di ordini di grandezza più complesso.

L'intelligenza artificiale, e in particolare il machine learning, offre strumenti potenti per affrontare questa complessità. Come documentato da Rolnick et al. (2022), gli algoritmi di ML possono gestire simultaneamente un numero enorme di variabili – condizioni meteorologiche in diverse località, pattern di consumo storici di milioni di utenze, stato di carica dei sistemi di storage distribuiti, prezzi dell'energia in tempo reale – per ottimizzare il funzionamento della rete elettrica.

**Previsione della domanda elettrica.** Un primo ambito di applicazione riguarda la **previsione a breve e medio termine della domanda energetica**. Algoritmi di deep learning addestrati su serie temporali storiche possono apprendere pattern complessi di consumo – giornalieri, settimanali, stagionali – e correlarli con variabili esterne come temperatura, giorno della settimana, eventi speciali. Previsioni accurate della domanda permettono agli operatori di rete di programmare in anticipo l'attivazione di capacità produttiva aggiuntiva, riducendo la dipendenza da costose e inquinanti centrali di riserva ("peaker plants") che vengono attivate solo nei momenti di picco.

**Previsione della produzione da fonti rinnovabili.** Simmetricamente, l'AI può migliorare significativamente la **previsione della produzione da fonti variabili**. Algoritmi di ML analizzano dati meteorologici, satellitari e storici di produzione per stimare quanta elettricità verrà generata da impianti solari ed eolici nelle ore e nei giorni successivi. Come vedremo nella sezione 2.2.2, DeepMind ha dimostrato di poter prevedere la produzione eolica con 36 ore di anticipo, aumentando il valore economico dell'energia eolica del 20% grazie alla possibilità di partecipare ai mercati dell'energia a termine.

**Controllo e dispatch in tempo reale.** L'applicazione forse più promettente, ma anche tecnicamente più complessa, riguarda l'uso di tecniche di **reinforcement learning** per il controllo dinamico della rete elettrica. In questo paradigma, un sistema AI apprende a prendere decisioni di dispatch – quali generatori attivare, quando caricare o scaricare batterie, come gestire la domanda flessibile – attraverso simulazioni o esperienza diretta, ottimizzando obiettivi multipli: minimizzare le emissioni, garantire l'affidabilità, ridurre i costi. Alcuni operatori di rete hanno iniziato a sperimentare queste tecniche su piccola scala.

**Riduzione degli sprechi energetici.** Le reti elettriche tradizionali sono soggette a perdite significative durante la trasmissione e distribuzione dell'elettricità – in alcuni paesi queste perdite raggiungono il 10-15% della produzione totale. L'AI può contribuire a ridurre questi sprechi ottimizzando il routing dell'energia attraverso la rete, identificando anomalie che indicano furti o guasti, e migliorando la manutenzione predittiva delle infrastrutture.

**Caso studio: DeepMind e l'ottimizzazione dei data center Google.** Un esempio concreto e ben documentato del potenziale dell'AI nell'efficienza energetica è rappresentato dal progetto di Google DeepMind per l'ottimizzazione dei sistemi di raffreddamento dei data center. Secondo quanto riportato dall'International Energy Agency (2024) nel report "Electricity 2024: Analysis and forecast to 2026", Google ha utilizzato i suoi algoritmi di intelligenza artificiale DeepMind per **ridurre del 40% il consumo energetico dei sistemi di raffreddamento** dei propri data center.

I data center sono infrastrutture particolarmente energy-intensive: i sistemi di raffreddamento rappresentano tipicamente il 40% del consumo elettrico totale di un data center, bilanciati dal 40% dei server stessi e dal 20% di sistemi di alimentazione e comunicazione. L'AI di DeepMind ha appreso a gestire in modo ottimale centinaia di variabili – temperature esterne, umidità, carichi computazionali, efficienza delle diverse unità di raffreddamento – per minimizzare il consumo energetico mantenendo le temperature operative necessarie. Questo risultato dimostra concretamente come l'ottimizzazione basata su ML possa generare risparmi energetici sostanziali in sistemi complessi.

È importante notare che questa applicazione, pur essendo significativa, non riguarda direttamente le reti elettriche nazionali ma singoli edifici ad alta intensità energetica. Tuttavia, il principio è lo stesso che può essere applicato alle smart grid: gestire la complessità di sistemi con molteplici variabili interdipendenti per trovare configurazioni ottimali che riducano sprechi e massimizzino l'efficienza.

**Sfide e limiti.** Nonostante il potenziale, l'applicazione dell'AI alle smart grid affronta ostacoli significativi. Le reti elettriche sono **infrastrutture critiche** dove la sicurezza e l'affidabilità sono priorità assolute: un errore può causare blackout che colpiscono milioni di persone. Questo rende difficile sperimentare direttamente con algoritmi AI su reti reali. Inoltre, molte utilities elettriche operano ancora con sistemi legacy incompatibili con tecnologie moderne, e gli investimenti necessari per modernizzare le infrastrutture sono ingenti. Infine, la **qualità e disponibilità dei dati** rappresenta un collo di bottiglia: in molti paesi, specialmente nel Sud globale, mancano i sensori e i sistemi di monitoraggio necessari per raccogliere i dati su cui addestrare algoritmi di ML.

### 2.2.2 Massimizzazione dell'autoconsumo da fonti rinnovabili

Oltre all'ottimizzazione delle reti centralizzate, l'AI può facilitare la transizione energetica migliorando l'integrazione di **generazione distribuita** – impianti solari su tetti residenziali, piccoli parchi eolici, sistemi di storage domestici. Questo paradigma, spesso chiamato "prosumer" (produttore-consumatore), trasforma utenti passivi in partecipanti attivi al mercato energetico.

**Previsione della produzione e massimizzazione del valore economico.** Un esempio emblematico del potenziale dell'AI in questo ambito è il lavoro di Google DeepMind sulla **previsione della produzione eolica**. Come riportato da Rolnick et al. (2022), DeepMind ha sviluppato modelli di machine learning capaci di prevedere la produzione energetica di parchi eolici con **36 ore di anticipo** utilizzando dati meteorologici e storici di produzione.

Questa capacità predittiva ha permesso di **aumentare del 20% il valore economico dell'energia eolica**. Come è possibile? I mercati elettrici funzionano su diverse scadenze temporali: mercati "day-ahead" dove l'energia viene venduta per il giorno successivo, mercati infragiornalieri, e mercati in tempo reale. L'energia venduta con maggiore anticipo ha generalmente un valore superiore perché offre maggiore certezza agli operatori di rete. Tuttavia, l'imprevedibilità dell'eolico ha tradizionalmente costretto i produttori a vendere solo all'ultimo momento, quando hanno certezza di quanto produrranno, accettando prezzi più bassi. Con previsioni accurate a 36 ore, i produttori possono partecipare ai mercati day-ahead, ottenendo prezzi migliori.

Questo incremento del valore economico non è solo rilevante per la redditività degli impianti eolici, ma ha implicazioni sistemiche per la transizione energetica: rende le rinnovabili più competitive rispetto alle fonti fossili, incentivando ulteriori investimenti. Dal punto di vista della modernizzazione ecologica, rappresenta un perfetto esempio di come la razionalità economica (massimizzare i profitti) possa allinearsi con la razionalità ecologica (favorire energie pulite) attraverso l'innovazione tecnologica.

**Gestione intelligente dello storage energetico.** Un'altra applicazione cruciale riguarda l'ottimizzazione dei **sistemi di accumulo** – batterie residenziali, storage su scala di utility, veicoli elettrici usati come storage distribuito (vehicle-to-grid). Il problema tecnico è determinare *quando* caricare e scaricare le batterie per massimizzare il beneficio economico e ambientale: caricare quando l'energia è abbondante (e economica e pulita), scaricare quando è scarsa (e costosa e sporca).

Algoritmi di reinforcement learning possono apprendere strategie ottimali di gestione dello storage considerando simultaneamente: previsioni di produzione rinnovabile, previsioni di domanda, prezzi dell'energia attuali e previsti, stato di carica delle batterie, degradazione delle batterie dovuta ai cicli di carica-scarica. La complessità del problema – con migliaia di batterie distribuite, pattern di produzione e consumo variabili, mercati dinamici – lo rende ideale per approcci basati su ML.

**Microgrids e autoconsumo.** L'AI può anche ottimizzare il funzionamento di **microreti** – sistemi energetici localizzati che possono operare autonomamente o connessi alla rete principale. In edifici o campus dotati di pannelli solari, batterie e carichi flessibili (come sistemi di climatizzazione), algoritmi di ML possono massimizzare l'autoconsumo di energia rinnovabile prodotta localmente, riducendo i prelievi dalla rete e minimizzando le emissioni associate.

**Gestione della domanda flessibile.** Un aspetto complementare riguarda la **demand response** – spostare temporalmente alcuni consumi energetici per allinearli con i picchi di produzione rinnovabile. Elettrodomestici come lavatrici, lavastoviglie, sistemi di riscaldamento possono essere programmati per funzionare quando l'energia solare è abbondante. L'AI può apprendere le preferenze degli utenti e ottimizzare automaticamente questi spostamenti minimizzando il disagio.

Dal punto di vista sociologico, queste applicazioni incarnano la visione della modernizzazione ecologica di una governance energetica distribuita e informazionale. Non più un sistema centralizzato top-down dove pochi grandi operatori controllano la produzione, ma un ecosistema complesso di milioni di attori – famiglie, imprese, comunità – che producono, consumano e scambiano energia in modo coordinato attraverso sistemi intelligenti. L'AI diventa l'infrastruttura cognitiva che rende possibile questa coordinazione decentralizzata.

### 2.2.3 Accelerazione della ricerca su materiali low-carbon

Forse l'applicazione più trasformativa, anche se meno immediatamente visibile, dell'AI per la transizione energetica riguarda l'**accelerazione della scoperta scientifica** di nuovi materiali. Batterie più efficienti, celle solari più economiche, catalizzatori per la produzione di idrogeno verde, materiali per la cattura del carbonio: tutte queste tecnologie dipendono dalla scoperta di nuovi composti chimici con proprietà specifiche. Tradizionalmente, questo processo è estremamente lento e costoso: i ricercatori sintetizzano e testano manualmente migliaia di materiali candidati, un processo che può richiedere anni o decenni.

L'intelligenza artificiale sta rivoluzionando questo paradigma. Come documentato da Rolnick et al. (2022), il machine learning può **esplorare lo spazio di miliardi di possibili materiali** molto più rapidamente della sperimentazione fisica. Il processo funziona tipicamente così:

1. **Creazione di database.** Si raccolgono dati su materiali esistenti – composizione chimica, struttura cristallina, proprietà fisiche (conduttività, densità, stabilità termica, ecc.).

2. **Training di modelli predittivi.** Algoritmi di ML – spesso neural networks o support vector machines – apprendono le relazioni tra struttura chimica e proprietà. Essenzialmente, il modello impara a "predire" le proprietà di un materiale basandosi sulla sua composizione.

3. **Screening computazionale.** Una volta addestrato, il modello può valutare rapidamente milioni di materiali candidati mai sintetizzati prima, identificando quelli con le proprietà desiderate senza bisogno di esperimenti fisici.

4. **Sintesi e test sperimentale.** Solo i candidati più promettenti identificati dall'AI vengono effettivamente sintetizzati e testati in laboratorio, riducendo drasticamente tempo e costi.

**Applicazioni specifiche.** Rolnick et al. (2022) documentano diverse applicazioni concrete di questo approccio:

- **Batterie per veicoli elettrici e storage.** Ricercatori hanno utilizzato tecniche di ML combinate con calcoli di fisica quantistica per progettare nuovi materiali conduttori per batterie al litio, potenzialmente più efficienti e meno costosi delle tecnologie attuali. Il miglioramento delle batterie è cruciale sia per i veicoli elettrici (autonomia, tempi di ricarica) sia per lo storage di rete necessario a bilanciare le fonti rinnovabili intermittenti.

- **Celle fotovoltaiche.** L'AI può identificare nuovi materiali per celle solari con migliore efficienza di conversione (più energia elettrica per unità di luce solare) o costi di produzione inferiori. Anche miglioramenti incrementali nell'efficienza hanno impatti enormi quando scalati a livello globale.

- **Solar fuels.** Alcuni ricercatori stanno usando AI, ottimizzazione e fisica computazionale per scoprire materiali che possano produrre combustibili sintetici (come idrogeno) direttamente dalla luce solare, immagazzinando energia solare in forma chimica.

- **Catalizzatori per elettrolizzatori.** La produzione di idrogeno verde attraverso elettrolisi dell'acqua richiede catalizzatori efficienti. ML può accelerare la scoperta di nuovi catalizzatori che riducano i costi e aumentino l'efficienza del processo.

**Riduzione dei tempi di R&D.** L'aspetto più rivoluzionario di questo approccio è la **compressione temporale** della ricerca. Ciò che prima richiedeva anni di esperimenti in laboratorio – sintetizzare materiali, testarne le proprietà, iterare – può ora essere in gran parte simulato computazionalmente in settimane o mesi. Come affermano Rolnick et al. (2022), il machine learning può "automatizzare questo processo combinando euristiche esistenti con dati sperimentali, fisica e ragionamento per applicare ed estendere la conoscenza fisica esistente".

Questa accelerazione ha implicazioni profonde per la velocità della transizione energetica. Le tecnologie energetiche hanno tipicamente cicli di sviluppo molto lunghi – dalle prime ricerche in laboratorio alla commercializzazione possono passare 20-30 anni. Se l'AI può ridurre questi tempi anche solo del 30-50%, l'impatto sulla rapidità con cui nuove tecnologie pulite diventano disponibili potrebbe essere determinante nel rispettare le scadenze climatiche.

**Sfide metodologiche.** Naturalmente, questo approccio presenta anche limiti. I modelli di ML sono validi quanto i dati su cui vengono addestrati: se il dataset è limitato a certe classi di materiali, il modello potrebbe non generalizzare bene a composti radicalmente diversi. Inoltre, la fisica dei materiali non è completamente compresa: esistono fenomeni complessi (superconduttività ad alta temperatura, catalisi biologica) che nemmeno i migliori modelli fisici possono predire accuratamente, e quindi nemmeno il ML può farlo senza nuove scoperte scientifiche fondamentali.

Inoltre, come notano Rolnick et al. (2022), rimangono sfide specifiche per il ML nella scienza dei materiali: dataset di dimensioni moderate (non i Big Data dell'internet), necessità di estrarre principi fisici interpretabili dai modelli addestrati (non solo predizioni "black box"), e la difficoltà di validare predizioni su materiali mai sintetizzati.

**Interpretazione dalla prospettiva della modernizzazione ecologica.** Dal punto di vista della teoria della modernizzazione ecologica, l'applicazione dell'AI alla scoperta di materiali rappresenta l'esempio perfetto della "intensificazione della modernizzazione" come via d'uscita dalla crisi ecologica. Non si tratta di rallentare la ricerca tecnologica o tornare a tecnologie preindustriali, ma di accelerarla ulteriormente attraverso strumenti computazionali avanzati. La promessa è che attraverso *più* scienza, *più* tecnologia, *più* innovazione – mediata dall'intelligenza artificiale – possiamo sviluppare le soluzioni tecniche necessarie a decarbonizzare l'economia.

Questo approccio si allinea perfettamente con la visione EMT di una razionalità ecologica che si realizza attraverso il progresso scientifico-tecnologico piuttosto che attraverso la sua limitazione. Tuttavia, solleva anche domande critiche che emergeranno nel Capitolo 3: chi ha accesso a queste capacità di AI? Come vengono distribuiti i benefici delle scoperte? E soprattutto, qual è il costo energetico e materiale dell'infrastruttura computazionale stessa necessaria per addestrare questi modelli di ML?

### 2.2.4 Considerazioni conclusive sulla transizione energetica

Le applicazioni dell'AI alla transizione energetica documentate in questa sezione – ottimizzazione delle smart grid, massimizzazione delle rinnovabili, accelerazione della ricerca materiali – condividono alcune caratteristiche comuni che vale la pena evidenziare:

**Gestione della complessità.** In tutti i casi, l'AI affronta problemi caratterizzati da un enorme numero di variabili interdipendenti, pattern non lineari, e necessità di decisioni in tempo reale. Questi sono precisamente i tipi di problemi dove il machine learning eccelle rispetto agli approcci tradizionali.

**Disaccoppiamento potenziale.** Dal punto di vista della modernizzazione ecologica, queste applicazioni promettono di realizzare il "disaccoppiamento" tra servizi energetici (elettricità affidabile, trasporti, riscaldamento) e impatto ambientale (emissioni di CO₂). Non richiedono che i consumatori riducano il loro utilizzo di energia, ma che la stessa quantità di energia sia fornita in modo più pulito ed efficiente.

**Scalabilità economica.** Un algoritmo ML, una volta sviluppato, può essere replicato a costo marginale quasi nullo. Una smart grid ottimizzata da AI in California può ispirare implementazioni simili in Europa o Asia. Un modello predittivo per la produzione solare può essere adattato a diversi contesti geografici. Questa scalabilità è cruciale per la rapidità della transizione globale.

Tuttavia, è essenziale mantenere uno sguardo critico. Le applicazioni descritte rappresentano il potenziale *tecnico* dell'AI, ma la loro effettiva implementazione su larga scala dipende da fattori istituzionali, economici e politici: investimenti in infrastrutture, regolamentazione dei mercati energetici, volontà politica di prioritizzare la decarbonizzazione. Come vedremo nella sezione 2.5, la tecnologia da sola non garantisce la transizione: sono necessarie condizioni abilitanti.

Inoltre, queste applicazioni "AI for Green" rappresentano ancora una piccola frazione dell'uso totale dell'intelligenza artificiale a livello globale. La maggior parte delle risorse computazionali dedicate all'AI è impiegata in ambiti commerciali – pubblicità online, raccomandazioni di contenuti, riconoscimento facciale – che hanno scarsa o nulla rilevanza per la crisi climatica. Come documentato da Kaack et al. (2022), le applicazioni climate-positive dell'AI rimangono una nicchia all'interno del settore AI globale.

Infine, e questo sarà il tema centrale del Capitolo 3, dobbiamo interrogarci sul costo ambientale dell'infrastruttura computazionale stessa. I data center che addestrano modelli di ML per ottimizzare le reti elettriche consumano essi stessi enormi quantità di elettricità. I GPU necessari per il deep learning richiedono minerali rari e generano rifiuti elettronici. Esiste il rischio, come vedremo, che i benefici ambientali delle applicazioni "AI for Green" siano vanificati dall'impronta ecologica dell'AI stessa – un paradosso che la teoria della modernizzazione ecologica fatica a riconoscere.

# 2.3 Monitoraggio climatico e prevenzione dei disastri

Se la transizione energetica rappresenta il dominio dove l'AI può fornire il maggiore contributo alla *mitigazione* del cambiamento climatico, il monitoraggio climatico e la prevenzione dei disastri costituiscono il terreno più promettente per l'*adattamento*. In questo ambito, l'intelligenza artificiale sta rivoluzionando sia la nostra capacità di comprendere e prevedere il sistema climatico, sia la nostra capacità di proteggere popolazioni e infrastrutture dagli eventi estremi sempre più frequenti e intensi che caratterizzano l'Antropocene.

Come sottolineato nel Capitolo 1, il monitoraggio ambientale automatizzato su scala planetaria rappresenta una delle manifestazioni più emblematiche della modernizzazione ecologica informazionale: l'AI permette di "vedere" il pianeta con una granularità spaziale e temporale senza precedenti, trasformando enormi volumi di dati grezzi (immagini satellitari, misurazioni meteorologiche, registrazioni acustiche) in informazioni utilizzabili per decisioni di policy, pianificazione e intervento d'emergenza. Questa "governance informazionale" estende radicalmente il raggio d'azione della razionalità ecologica discussa da Mol e Spaargaren.

Questa sezione documenta tre aree di applicazione dove l'AI sta generando impatti particolarmente significativi: le previsioni meteorologiche di medio termine, i sistemi di allerta precoce per disastri naturali (con particolare focus sulle alluvioni), e il monitoraggio della biodiversità e della deforestazione.

## 2.3.1 Previsioni meteorologiche basate su AI: una rivoluzione metodologica

Le previsioni meteorologiche hanno rappresentato per decenni uno dei trionfi della scienza computazionale applicata. I modelli numerici tradizionali – noti come Numerical Weather Prediction (NWP) systems – si basano sulla simulazione fisica dell'atmosfera: risolvono numericamente le equazioni differenziali che governano la dinamica dei fluidi atmosferici, la termodinamica, la radiazione solare e altri processi fisici. Questi modelli, come il sistema HRES (High RESolution) dell'European Centre for Medium-Range Weather Forecasts (ECMWF), rappresentano il gold standard delle previsioni meteorologiche globali.

Tuttavia, i modelli NWP tradizionali presentano limitazioni significative. Primo, sono computazionalmente estremamente costosi: una singola previsione globale a 10 giorni richiede ore di calcolo su supercomputer massivi, consumando enormi quantità di energia. Secondo, la loro risoluzione spaziale è inevitabilmente limitata dalle risorse computazionali disponibili: aumentare la risoluzione richiede un incremento esponenziale della potenza di calcolo necessaria. Terzo, la loro accuratezza tende a degradare rapidamente oltre i 7-10 giorni di anticipo a causa della natura caotica dell'atmosfera.

### Il paradigma dell'AI meteorologica: GraphCast e l'apprendimento dai dati storici

Negli ultimi anni, un approccio radicalmente diverso ha iniziato a emergere: invece di simulare esplicitamente la fisica dell'atmosfera, i modelli basati su machine learning *apprendono* le dinamiche atmosferiche direttamente dai dati storici. Questo cambio di paradigma – da modelli basati su equazioni fisiche a modelli basati su pattern appresi dai dati – sta producendo risultati sorprendenti.

Il caso più emblematico è **GraphCast**, un modello sviluppato da DeepMind e pubblicato su *Science* nel 2023 da Lam e colleghi. GraphCast rappresenta il primo sistema di machine learning a superare sistematicamente il modello HRES dell'ECMWF – considerato il sistema NWP più accurato al mondo – su un'ampia gamma di variabili meteorologiche e orizzonti temporali.

**Architettura e funzionamento tecnico.** GraphCast è un modello basato su Graph Neural Networks (GNN), una classe di reti neurali progettata per operare su dati strutturati come grafi. La superficie terrestre viene rappresentata come una griglia a risoluzione 0,25° di latitudine/longitudine (approssimativamente 28×28 km all'equatore), che corrisponde a circa 40.000 punti di griglia distribuiti sul pianeta. Ogni punto contiene informazioni su cinque variabili superficiali (temperatura a 2 metri, componenti del vento a 10 metri, pressione al livello del mare, precipitazione totale) e sei variabili atmosferiche misurate a 37 livelli di pressione verticali (temperatura, vento orizzontale e verticale, geopotenziale, umidità specifica).

Il modello prende come input lo stato corrente dell'atmosfera e lo stato di sei ore prima, e predice lo stato dell'atmosfera sei ore nel futuro. Questa previsione può poi essere iterata – usando le previsioni precedenti come nuovi input – per generare previsioni fino a 10 giorni di anticipo. Ciò che richiede ore di calcolo ai modelli NWP tradizionali, GraphCast lo produce in meno di un minuto su un singolo processore Google Cloud TPU v4.

**Training e validazione.** GraphCast è stato addestrato su 39 anni di dati storici (1979-2017) provenienti dal dataset di rianalisi ERA5 dell'ECMWF – essenzialmente la "migliore ricostruzione possibile" dello stato storico dell'atmosfera ottenuta combinando osservazioni e simulazioni fisiche. L'obiettivo di apprendimento era minimizzare l'errore tra le previsioni del modello e gli stati atmosferici realmente osservati.

La validazione è stata condotta sui dati degli anni 2018-2021, mai visti durante il training. GraphCast ha dimostrato accuratezza superiore a HRES su 90% delle 227 combinazioni variabile-livello-orizzonte temporale testate. Il vantaggio è particolarmente marcato per orizzonti temporali oltre le 36 ore e per variabili cruciali come la temperatura, il vento e l'umidità.

**Previsione di eventi estremi: il test dei cicloni tropicali.** Particolarmente impressionante è la capacità di GraphCast di prevedere fenomeni ad alto impatto come i cicloni tropicali. Lam e colleghi hanno testato sistematicamente la previsione delle traiettorie cicliche su tutti gli eventi del periodo 2018-2021. GraphCast ha mostrato errori mediani di traiettoria significativamente inferiori a HRES per orizzonti temporali da 18 ore fino a 4,75 giorni. Questo significa che GraphCast può identificare dove un uragano colpirà con maggiore anticipo e precisione – informazione cruciale per evacuazioni e preparazione d'emergenza.

Analogamente, per eventi di temperatura estrema (ondate di calore e freddo) e per fiumi atmosferici (stretti corridoi di intenso trasporto di vapore acqueo che causano precipitazioni estreme sulla costa occidentale degli Stati Uniti), GraphCast ha dimostrato capacità predittive superiori. Queste non sono variabili per cui il modello è stato esplicitamente ottimizzato durante il training – emerge spontaneamente dalla sua capacità di apprendere pattern atmosferici complessi dai dati storici.

### Pangu-Weather e l'ecosistema emergente di modelli AI

GraphCast non è un caso isolato. Quasi contemporaneamente, ricercatori di Huawei hanno sviluppato **Pangu-Weather**, un modello basato su architettura Transformer (la stessa famiglia usata per i grandi modelli linguistici come GPT) che ha dimostrato performance competitive o superiori ai modelli NWP tradizionali. Anche altri gruppi di ricerca stanno producendo modelli ML per previsioni meteorologiche con risultati promettenti.

Questa convergenza di risultati positivi da team indipendenti suggerisce che non si tratta di un artefatto metodologico ma di una genuina superiorità dell'approccio basato su ML, almeno per determinati compiti e orizzonti temporali. Si sta configurando un nuovo ecosistema di modelli meteorologici basati su AI che coesistono e in alcuni casi superano i sistemi tradizionali.

### Effetto di recency e adattamento ai cambiamenti climatici

Un aspetto particolarmente rilevante nel contesto del cambiamento climatico è la capacità di GraphCast di adattarsi a pattern meteorologici in evoluzione. Lam e colleghi hanno addestrato quattro varianti del modello usando dati che si fermavano rispettivamente al 2017, 2018, 2019 e 2020. Hanno scoperto che le performance su dati del 2021 miglioravano progressivamente: il modello addestrato fino al 2020 era più accurato di quello addestrato fino al 2018.

Questo "effetto di recency" suggerisce che GraphCast può catturare tendenze climatiche in atto – pattern meteorologici che stanno cambiando a causa del riscaldamento globale. Questa è una proprietà cruciale: mentre i modelli NWP tradizionali si basano su equazioni fisiche che assumono un sistema climatico stazionario, i modelli ML possono in linea di principio adattarsi a un clima che cambia semplicemente venendo riaddestrati periodicamente con dati recenti.

### Implicazioni per la governance informazionale

La rivoluzione delle previsioni meteorologiche basate su AI ha implicazioni profonde per la governance informazionale discussa nel framework della modernizzazione ecologica:

**Democratizzazione dell'accesso.** Mentre gestire un supercomputer per previsioni NWP richiede investimenti di decine o centinaia di milioni di dollari, eseguire un modello ML pre-addestrato come GraphCast richiede risorse computazionali relativamente modeste. Questo potrebbe permettere a paesi in via di sviluppo, istituzioni di ricerca minori, o anche organizzazioni non governative di accedere a previsioni meteorologiche di alta qualità senza dipendere da grandi centri meteorologici.

**Velocità e efficienza computazionale.** La differenza di velocità – minuti invece di ore – non è solo una curiosità tecnica. Significa che si possono generare molte più previsioni alternative (ensemble) per quantificare l'incertezza, o che si possono produrre previsioni aggiornate con maggiore frequenza incorporando le osservazioni più recenti. Nel contesto di eventi in rapida evoluzione come tempeste, questa velocità può fare la differenza tra un'evacuazione tempestiva e una tardiva.

**Efficienza energetica.** GraphCast consuma drasticamente meno energia di un modello NWP tradizionale per produrre una previsione equivalente. In un contesto dove ogni riduzione di consumo energetico contribuisce alla mitigazione climatica, questo è un beneficio aggiuntivo non trascurabile – benché, come vedremo nel Capitolo 3, debba essere bilanciato contro i costi energetici del training iniziale del modello.

### Limiti e complementarietà con modelli fisici

È importante sottolineare che i modelli ML meteorologici presentano anche limiti significativi. Primo, sono essenzialmente sistemi di interpolazione statistica: apprendono pattern dai dati storici e li proiettano nel futuro. Questo significa che possono avere difficoltà con eventi senza precedenti o situazioni al di fuori della distribuzione dei dati di training. Secondo, sono "scatole nere" opache: mentre un meteorologo può interpretare cosa sta "pensando" un modello NWP guardando le equazioni e le variabili intermedie, capire *perché* un modello ML fa una certa previsione è molto più difficile. Terzo, i modelli ML dipendono criticamente dalla qualità e completezza dei dati di training.

Per queste ragioni, il futuro più probabile non è la sostituzione completa dei modelli NWP con modelli ML, ma una loro integrazione complementare: modelli ML per previsioni rapide ed efficienti di routine, modelli NWP per situazioni critiche e per validare fisicamente le previsioni ML, e sistemi ibridi che combinano i punti di forza di entrambi gli approcci.

## 2.3.2 Sistemi di allerta precoce per alluvioni: proteggere le popolazioni vulnerabili

Se le previsioni meteorologiche accurate sono il primo anello della catena di protezione dalle catastrofi naturali, i sistemi di allerta precoce specifici per determinati rischi costituiscono l'ultimo miglio – il passaggio dall'informazione meteorologica generale all'azione protettiva concreta per popolazioni a rischio.

Le alluvioni rappresentano uno dei disastri naturali più devastanti e frequenti. Causano migliaia di vittime ogni anno, distruggono infrastrutture critiche, contaminano fonti idriche, e colpiscono in modo sproporzionato le comunità più vulnerabili. Il cambiamento climatico sta intensificando il ciclo idrologico globale: l'atmosfera più calda contiene più vapore acqueo, portando a precipitazioni più intense e concentrate. Molte regioni stanno sperimentando sia siccità più severe (quando non piove) sia alluvioni più devastanti (quando piove).

### Il divario dati globale e la sfida dei bacini non monitorati

Tradizionalmente, le previsioni di alluvioni fluviali si basano su reti di sensori idrometrici (misuratori di livello e flusso dei fiumi) combinati con modelli idrologici che simulano come la pioggia si trasforma in deflusso superficiale e scorre attraverso i bacini idrografici. Questi sistemi funzionano bene dove esistono – tipicamente nei paesi sviluppati con risorse adeguate per installare e mantenere reti di sensori dense.

Il problema è che la maggior parte dei bacini fluviali del mondo non ha alcun monitoraggio. Rolnick e colleghi stimano che oltre l'80% delle aree soggette a rischio alluvionale globale mancano di sistemi di allerta funzionanti. Questo divario dati riflette profonde disuguaglianze globali: i paesi che hanno maggiore bisogno di sistemi di allerta (paesi del Sud globale esposti a monsoni, cicloni tropicali, e con infrastrutture vulnerabili) sono spesso quelli che meno possono permettersi di installarli.

L'AI offre un percorso per colmare questo divario attraverso approcci che non dipendono da reti di sensori locali ma utilizzano dati globalmente disponibili come immagini satellitari, modelli di elevazione del terreno, e dati meteorologici.

### Google Flood Hub: un caso di studio di democratizzazione della protezione

Il sistema più ambizioso attualmente operativo è **Google Flood Hub**, lanciato nel 2018 e progressivamente espanso fino a coprire oltre 80 paesi e fornire previsioni per più di 460 milioni di persone. Flood Hub rappresenta un esempio paradigmatico di come l'AI possa essere usata per "colmare il divario dati tra Nord e Sud globale", come sottolineato nell'indice della presente tesi.

**Architettura tecnica.** Il sistema combina diversi componenti di machine learning in una pipeline integrata:

1. **Modelli idrologici guidati da ML.** Invece di richiedere dati idrometrici locali, il sistema usa modelli di machine learning addestrati su bacini monitorati per apprendere la relazione tra precipitazioni previste, caratteristiche del terreno (pendenza, permeabilità del suolo, copertura vegetale ricavata da satellite), e portata dei fiumi. Questi modelli vengono poi applicati a bacini non monitorati con caratteristiche simili.

2. **Modelli di inondazione basati su fisica e ML.** Una volta prevista la portata del fiume, un secondo set di modelli predice l'estensione spaziale dell'inondazione – quali aree verranno sommerse e a che profondità. Questi modelli combinano simulazioni fisiche del flusso dell'acqua con apprendimento automatico per accelerare i calcoli.

3. **Sistema di allerta a 5 giorni di anticipo.** Flood Hub può emettere previsioni di alluvione fino a 5 giorni prima dell'evento previsto. Questo orizzonte temporale è cruciale: permette evacuazioni ordinate, mobilitazione di risorse di emergenza, e comunicazioni preventive alle comunità a rischio.

**Impatto e validazione sul campo.** Nearing e colleghi (2024) hanno documentato l'accuratezza del sistema in diversi contesti geografici. Le previsioni sono state validate contro eventi alluvionali realmente osservati, mostrando tassi di rilevamento (capacità di identificare eventi che si sono effettivamente verificati) e precisione (capacità di non generare falsi allarmi) che rendono il sistema utilizzabile operativamente.

Particolarmente significativo è l'impatto in paesi come Bangladesh, India, e nazioni africane dove precedentemente non esistevano sistemi di allerta. Durante la stagione dei monsoni del 2022 in Bangladesh, Flood Hub ha emesso allerte che hanno permesso evacuazioni preventive di decine di migliaia di persone da aree che sono state successivamente sommerse.

**Interfaccia accessibile e localizzazione.** Flood Hub non è solo un sistema tecnico sofisticato ma anche uno strumento progettato per essere accessibile. Le previsioni sono visualizzate su mappe interattive disponibili pubblicamente online, con informazioni tradotte in lingue locali. Le allerte possono essere integrate con servizi di notifica via SMS o attraverso canali di comunicazione già usati dalle comunità locali.

### Giustizia climatica e riduzione delle disuguaglianze

Dal punto di vista della sociologia ambientale e della giustizia climatica, Flood Hub rappresenta un caso interessante di tecnologia che potenzialmente riduce anziché amplificare le disuguaglianze. Le comunità più vulnerabili alle alluvioni sono spesso quelle che hanno contribuito meno alle emissioni storiche di gas serra – un'ingiustizia fondamentale dell'antropocene. Un sistema di allerta accessibile gratuitamente, che non richiede investimenti locali in infrastrutture, rappresenta una forma di "trasferimento tecnologico" che avviene attraverso il cloud piuttosto che attraverso aiuti allo sviluppo tradizionali.

Tuttavia, rimangono sfide significative. L'efficacia di qualsiasi sistema di allerta dipende non solo dall'accuratezza tecnica ma dalla capacità istituzionale e sociale di agire sulle informazioni: esistono piani di evacuazione? Le comunità si fidano delle allerte? Esistono rifugi sicuri raggiungibili? La comunicazione raggiunge le popolazioni rurali senza accesso internet affidabile? Queste "last mile problems" – il passaggio dall'informazione all'azione – richiedono investimenti complementari in capacità istituzionale, infrastrutture di comunicazione, e costruzione di fiducia sociale.

### Altre applicazioni di ML per disastri naturali

Oltre alle alluvioni, il machine learning viene applicato a una crescente varietà di rischi naturali:

**Incendi boschivi.** Modelli ML analizzano immagini satellitari per rilevare focolai incendiari nelle fasi iniziali (quando sono ancora controllabili), predire la progressione spaziale del fuoco in base a vento e topografia, e ottimizzare l'allocazione di risorse di spegnimento. Durante la stagione degli incendi californiani, sistemi basati su ML hanno dimostrato capacità di rilevamento più rapide dei metodi tradizionali.

**Ondate di calore.** Deep learning su dati meteorologici storici può identificare pattern che precedono ondate di calore estreme, permettendo allerte con giorni di anticipo. Questo è particolarmente rilevante per proteggere popolazioni vulnerabili (anziani, lavoratori all'aperto) in contesti urbani dove l'effetto "isola di calore" amplifica le temperature.

**Tempeste e uragani.** Come documentato nella sezione su GraphCast, l'AI sta migliorando le previsioni di traiettoria e intensità dei cicloni tropicali, estendendo l'orizzonte temporale delle allerte e riducendo le "zone di incertezza" delle evacuazioni.

## 2.3.3 Monitoraggio della deforestazione e della biodiversità: "vedere" il pianeta vivente

Se le sezioni precedenti hanno documentato come l'AI permetta di "vedere" l'atmosfera e i suoi pericoli con accuratezza senza precedenti, questa sezione illustra come analoghe tecnologie stiano trasformando la nostra capacità di monitorare la biosfera terrestre – le foreste, gli ecosistemi, e la biodiversità che sostengono la vita sul pianeta.

La deforestazione contribuisce approssimativamente al 10% delle emissioni globali di gas serra quando la vegetazione viene bruciata o decade, rilasciando il carbonio precedentemente sequestrato. Oltre al contributo diretto al cambiamento climatico, la perdita di foreste distrugge habitat critici per la biodiversità, degrada servizi ecosistemici (regolazione idrica, prevenzione dell'erosione), e impatta i mezzi di sussistenza di comunità indigene e rurali. Circa l'80% della deforestazione globale è causata dall'espansione agricola (conversione di foreste in pascoli o coltivazioni), mentre cause secondarie includono estrazione mineraria, taglio legale e illegale del legname, e sviluppo urbano.

### Remote sensing e computer vision per la deforestazione

Le tecniche di **remote sensing** – l'acquisizione di informazioni sulla superficie terrestre tramite sensori su satelliti o aerei – hanno da tempo permesso di monitorare i cambiamenti nella copertura forestale. Satelliti come quelli della costellazione Landsat (operativa dal 1972) producono immagini multispettrali della superficie terrestre che possono essere analizzate per identificare diversi tipi di vegetazione.

Ciò che l'AI aggiunge è la capacità di automatizzare completamente questa analisi su scala planetaria e in tempo quasi-reale. Algoritmi di **computer vision** basati su reti neurali convoluzionali (CNN) possono essere addestrati a identificare cambiamenti nella copertura forestale confrontando immagini successive della stessa area. Questi sistemi apprendono a distinguere tra perdita di foresta dovuta a deforestazione vera e propria, perdita temporanea dovuta ad agricoltura rotazionale, perdita naturale dovuta a incendi spontanei o tempeste, e false rilevazioni dovute a copertura nuvolosa o ombre.

### Global Forest Watch: sorveglianza forestale partecipativa

**Global Forest Watch (GFW)** è una piattaforma online che combina dati satellitari, algoritmi di machine learning, e tecnologie cloud per fornire monitoraggio della deforestazione quasi in tempo reale a scala globale. Lanciata nel 2014 e gestita dal World Resources Institute in collaborazione con Google e altre organizzazioni, GFW analizza automaticamente immagini satellitari Landsat per rilevare perdita di copertura arborea con risoluzione di 30 metri e latenza di poche settimane.

**Funzionalità tecniche.** Il sistema si basa su algoritmi di classificazione supervisionata: il modello ML viene addestrato su esempi etichettati di "foresta", "non-foresta", e "perdita di foresta", e impara a identificare questi pattern in nuove immagini. La classificazione avviene automaticamente per ogni nuova immagine satellitare disponibile, coprendo l'intero pianeta. Gli utenti possono:

- Visualizzare mappe interattive della perdita di copertura forestale per qualsiasi regione del mondo
- Iscriversi ad allerte automatiche quando viene rilevata deforestazione in aree specifiche (ad esempio, riserve protette)
- Scaricare dati grezzi per analisi indipendenti
- Sovrapporre dati sulla deforestazione con altre informazioni geografiche (confini di concessioni minerarie, aree protette, territori indigeni)

**Impatto su enforcement e accountability.** GFW ha dimostrato impatti documentabili su policy e enforcement. In Indonesia, ONG ambientaliste hanno usato le allerte di GFW per identificare deforestazione illegale nelle concessioni di palma da olio e presentare esposti alle autorità di regolamentazione. In Brasile, i dati di GFW sono stati usati per monitorare l'efficacia (o inefficacia) delle politiche di protezione forestale, creando pressione pubblica su governi. A livello globale, investitori e aziende utilizzano GFW per monitorare le supply chain e verificare claim di "zero deforestazione" da parte di fornitori.

**Differenziazione tra taglio selettivo e deforestazione totale.** Sviluppi più recenti degli algoritmi permettono non solo di rilevare *se* c'è stata perdita di copertura, ma anche di che *tipo*: deforestazione completa (conversione permanente a uso non-forestale) versus taglio selettivo (rimozione di alcuni alberi mantenendo la struttura forestale). Questa distinzione è cruciale per policy: il taglio selettivo sostenibile è molto diverso dalla conversione permanente a pascolo o miniera.

### Monitoraggio acustico e biodiversità

Mentre il remote sensing ottico (immagini) si concentra sulla copertura vegetale, un filone emergente usa **remote sensing acustico** per monitorare la fauna. Sensori audio alimentati a energia solare vengono installati nelle foreste per registrare continuamente i suoni dell'ambiente. Algoritmi di machine learning analizzano queste registrazioni per:

- **Rilevare attività umane dannose.** Un progetto chiamato Rainforest Connection installa vecchi smartphone nelle foreste pluviali tropicali che registrano continuamente audio e usano ML per rilevare suoni di motoseghe entro un raggio di un chilometro. Quando viene rilevato un suono sospetto, viene inviata un'allerta in tempo reale ai ranger forestali che possono intervenire.

- **Identificare specie tramite vocalizzazioni.** Reti neurali addestrate su database di richiami di uccelli, mammiferi, anfibi possono identificare automaticamente quali specie sono presenti in un'area basandosi sulle registrazioni acustiche. Questo permette monitoraggio della biodiversità su vasta scala senza richiedere la presenza fisica di biologi.

### Citizen science e riconoscimento automatico di specie

Piattaforme come **iNaturalist** combinano crowdsourcing (citizen science) e machine learning per costruire database massicci di osservazioni di biodiversità. Gli utenti caricano foto di piante, animali, funghi osservati in natura; algoritmi di computer vision suggeriscono identificazioni automatiche; esperti umani validano le identificazioni; il sistema apprende continuamente migliorando le sue capacità di riconoscimento.

Al 2022, iNaturalist contava oltre 100 milioni di osservazioni verificate di più di 400.000 specie diverse. Questo database crowdsourced sta diventando una risorsa cruciale per la ricerca ecologica e la conservazione: permette di tracciare distribuzioni di specie, identificare trend popolazionali, rilevare specie invasive in espansione, e coinvolgere il pubblico nella scienza della biodiversità.

**Wildlife Insights** è una piattaforma analoga focalizzata su immagini da fototrappole – camere automatiche che si attivano quando rilevano movimento e che vengono installate nelle aree selvagge per monitorare fauna sfuggente. Tradizionalmente, analizzare migliaia di immagini da fototrappole richiedeva centinaia di ore di lavoro umano per identificare quali contenevano animali e di che specie. Algoritmi di deep learning riducono questo lavoro del 99%: identificano automaticamente se un'immagine contiene un animale, di che specie, quanti individui, che comportamento stanno mostrando.

### Dalla sorveglianza alla giustizia: questioni critiche

Il monitoraggio ambientale basato su AI solleva anche questioni critiche che verranno approfondite nel Capitolo 3. Chi controlla questi sistemi di sorveglianza? A chi appartengono i dati? Come vengono usati?

Nel contesto della deforestazione, c'è il rischio che la sorveglianza venga usata principalmente per criminalizzare piccoli agricoltori o comunità indigene che praticano agricoltura di sussistenza, mentre attori più potenti (grandi corporazioni agro-industriali, concessionari minerari con connessioni politiche) sfuggono alle conseguenze. La tecnologia di monitoraggio è neutrale rispetto al potere – può essere usata tanto per proteggere quanto per controllare.

Analogamente, nel monitoraggio della biodiversità emerge la questione di chi beneficia della conoscenza generata. Database globali di biodiversità costruiti tramite AI incorporano spesso conoscenza ecologica tradizionale di comunità indigene – ma queste comunità ricevono riconoscimento e benefici?

Nonostante queste legittime preoccupazioni, è innegabile che la capacità di "vedere il pianeta vivente" con la granularità e continuità rese possibili dall'AI rappresenta uno strumento potenzialmente potente per la governance ambientale. Come sottolineato dalla teoria della modernizzazione ecologica, la trasparenza informazionale è una precondizione necessaria (benché non sufficiente) per l'accountability ecologica.

## 2.3.4 Sintesi: l'AI come estensione radicale della governance informazionale

Le applicazioni documentate in questa sezione – dalle previsioni meteorologiche ai sistemi di allerta alluvioni, dal monitoraggio forestale al riconoscimento della biodiversità – condividono una logica comune che risuona profondamente con i principi della modernizzazione ecologica informazionale discussi nel Capitolo 1.

**Primo, trasformazione di dati grezzi in conoscenza utilizzabile.** In tutti i casi, l'AI agisce come intermediario che traduce enormi volumi di dati grezzi (pixel di immagini satellitari, misurazioni meteorologiche, registrazioni acustiche) in informazioni comprensibili e utilizzabili: "questa area sta per essere allagata", "questa foresta è stata abbattuta", "questa specie è in declino". Questa traduzione non è banale – richiede pattern recognition sofisticato che solo recentemente è diventato possibile grazie ai progressi del machine learning.

**Secondo, scalabilità globale e democratizzazione.** Queste applicazioni operano a scala planetaria, fornendo capacità di monitoraggio a regioni e comunità che non potrebbero mai permettersi sistemi tradizionali. Flood Hub serve 460 milioni di persone in 80+ paesi; Global Forest Watch copre tutte le foreste tropicali del mondo; GraphCast produce previsioni globali accessibili a chiunque abbia una connessione internet. Questa è governance informazionale distribuita e democratizzata.

**Terzo, velocità e tempestività.** La differenza tra una previsione prodotta in minuti invece che in ore, tra un'allerta di alluvione con 5 giorni invece di 1 giorno di anticipo, tra la rilevazione di deforestazione con settimane invece che mesi di latenza – queste differenze temporali si traducono in capacità concreta di azione preventiva.

**Quarto, colmare il divario Nord-Sud.** Un tema ricorrente è come l'AI permetta di estendere capacità di monitoraggio e previsione precedentemente disponibili solo ai paesi ricchi a regioni del Sud globale. Questo non risolve magicamente le disuguaglianze strutturali – come vedremo nel Capitolo 3, l'infrastruttura AI stessa riproduce e amplifica certe disuguaglianze – ma rappresenta un potenziale contrappeso.

Tuttavia, è cruciale mantenere una prospettiva equilibrata. Come sottolineato nell'introduzione al capitolo, queste applicazioni sono ancora una *nicchia* rispetto all'uso totale dell'AI globalmente. La loro efficacia dipende da fattori istituzionali, politici ed economici che vanno oltre la tecnologia: sistemi di allerta non salvano vite se non esistono piani di evacuazione o se le comunità non si fidano delle autorità; il monitoraggio della deforestazione non ferma il taglio illegale se non c'è volontà politica di enforcement.

E soprattutto, come documenteremo nel Capitolo 3, l'infrastruttura computazionale che rende possibili queste applicazioni benefiche ha essa stessa un'impronta ecologica considerevole. La promessa dell'AI come strumento di razionalità ecologica deve essere valutata insieme alla realtà dell'AI come sistema ad alta intensità energetica, idrica e materiale. Solo tenendo insieme entrambe le prospettive – l'AI for Green e l'AI come problema ambientale – possiamo sviluppare una comprensione sociologicamente informata del ruolo dell'intelligenza artificiale nell'Antropocene.